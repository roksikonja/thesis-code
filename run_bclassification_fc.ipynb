{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Following tutorial: https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bclassification.utils_base import print_class_weights\n",
    "from bclassification.utils_fc import (\n",
    "    print_dataset,\n",
    "    obs_to_vect_with_tc,\n",
    "    obs_vects_to_vect,\n",
    "    plot_metrics,\n",
    "    plot_cm,\n",
    "    plot_roc,\n",
    "    describe_results,\n",
    ")\n",
    "from experience import load_experience\n",
    "from lib.action_space import is_do_nothing_action\n",
    "from lib.constants import Constants as Const\n",
    "from lib.data_utils import make_dir, env_pf, extract_target_windows, moving_window\n",
    "from lib.dc_opf import TopologyConverter\n",
    "from lib.run_utils import create_logger\n",
    "from lib.tf_utils import (\n",
    "    ResidulaFCBlock,\n",
    "    MatthewsCorrelationCoefficient,\n",
    ")\n",
    "from lib.visualizer import Visualizer, pprint\n",
    "\n",
    "Visualizer()\n",
    "\n",
    "experience_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"performance-aug\"))\n",
    "results_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"bc-fc\"))\n",
    "\n",
    "agent_name = \"agent-mip\"\n",
    "case_name = \"l2rpn_2019_art\"\n",
    "env_dc = True\n",
    "verbose = False\n",
    "\n",
    "case_results_dir = make_dir(os.path.join(results_dir, f\"{case_name}-{env_pf(env_dc)}\"))\n",
    "create_logger(logger_name=f\"{case_name}-{env_pf(env_dc)}\", save_dir=case_results_dir)\n",
    "\n",
    "case, collector = load_experience(case_name, agent_name, experience_dir, env_dc=env_dc)\n",
    "obses, actions, rewards, dones = collector.aggregate_data()\n",
    "\n",
    "pprint(\"    - Number of chronics:\", dones.sum())\n",
    "pprint(\"    - Observations:\", len(obses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Parameters\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "model_type = \"fc\"  # \"fc\" or \"res\"\n",
    "\n",
    "n_window_targets = 0\n",
    "n_window_history = 1\n",
    "threshold = 0.5\n",
    "\n",
    "dropout_rate = 0.1\n",
    "n_hidden = 512\n",
    "\n",
    "n_batch = 512\n",
    "n_epochs = 1500\n",
    "\n",
    "downsampling_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Datasets\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "labels = is_do_nothing_action(actions, case.env).astype(float)\n",
    "pprint(\n",
    "    \"    - Labels:\",\n",
    "    f\"{int(labels.sum())}/{labels.size}\",\n",
    "    \"{:.2f} %\".format(100 * labels.mean()),\n",
    ")\n",
    "\n",
    "mask_positive = extract_target_windows(labels, mask=~dones, n_window=n_window_targets)\n",
    "mask_negative = np.logical_and(np.random.binomial(1, downsampling_rate, len(labels)), ~mask_positive)\n",
    "mask_targets = np.logical_or(mask_positive, mask_negative)\n",
    "\n",
    "pprint(\n",
    "    \"    - Mask (0):\",\n",
    "    mask_negative.sum(),\n",
    "    \"{:.2f} %\".format(100 * mask_negative.sum() / mask_targets.sum()),\n",
    ")\n",
    "pprint(\n",
    "    \"    - Mask (1):\",\n",
    "    mask_positive.sum(),\n",
    "    \"{:.2f} %\".format(100 * mask_positive.sum() / mask_targets.sum()),\n",
    ")\n",
    "pprint(\"    - Mask:\", mask_targets.sum())\n",
    "\n",
    "obs_to_vect = obs_to_vect_with_tc(TopologyConverter(case.env))\n",
    "\n",
    "X_all = moving_window(\n",
    "    obses,\n",
    "    n_window=n_window_history,\n",
    "    process_fn=obs_to_vect,\n",
    "    combine_fn=obs_vects_to_vect,\n",
    "    padding=np.zeros_like(obs_to_vect(obses[0])),\n",
    ")\n",
    "\n",
    "X_all = np.vstack(X_all)\n",
    "Y_all = np.array(labels)\n",
    "\n",
    "X = np.vstack(X_all[mask_targets, :])\n",
    "Y = Y_all[mask_targets]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.10, random_state=random_seed\n",
    ")\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, Y_train, test_size=0.10, random_state=random_seed\n",
    ")\n",
    "\n",
    "print_dataset(X, Y, \"Data\")\n",
    "print_dataset(X_train, Y_train, \"Train\")\n",
    "print_dataset(X_val, Y_val, \"Validation\")\n",
    "print_dataset(X_test, Y_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model\n",
    "\"\"\"\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.TruePositives(thresholds=threshold, name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(thresholds=threshold, name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(thresholds=threshold, name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(thresholds=threshold, name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(threshold=threshold, name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(thresholds=threshold, name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(thresholds=threshold, name=\"recall\"),\n",
    "    MatthewsCorrelationCoefficient(threshold=threshold, name=\"mcc\"),\n",
    "]\n",
    "\n",
    "n_negative, n_positive = np.bincount(Y.astype(int))\n",
    "n = n_negative + n_positive\n",
    "\n",
    "class_weight = {0: n / n_negative / 2.0, 1: n / n_positive / 2.0}\n",
    "initial_bias = np.log([n_positive / n_negative])\n",
    "\n",
    "print_class_weights(class_weight)\n",
    "pprint(\"Initial bias:\", \"{:.4f}\".format(float(initial_bias)))\n",
    "\n",
    "if model_type == \"fc\":\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(n_hidden, activation=\"relu\", input_shape=(X.shape[-1],)),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(n_hidden, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(n_hidden, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(n_hidden, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(n_hidden, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                n_hidden, activation=\"relu\", input_shape=(X.shape[-1],)\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            ResidulaFCBlock(n_hidden, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            ResidulaFCBlock(n_hidden, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            ResidulaFCBlock(n_hidden, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "model_dir = make_dir(os.path.join(case_results_dir, f\"model-000-{model_type}\"))\n",
    "checkpoint_path = os.path.join(model_dir, \"ckpts\")\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=model.optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "pprint(\"Model directory:\", model_dir)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    pprint(\"Restoring checkpoint from:\", ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Training\n",
    "\"\"\"\n",
    "tensorboard_path = os.path.join(model_dir, \"logs\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=tensorboard_path, write_graph=False, write_images=False, update_freq=\"epoch\"\n",
    ")\n",
    "pprint(\"    - TensorBoard cmd:\", f\"tensorboard --logdir={tensorboard_path}\")\n",
    "\n",
    "training = model.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=n_batch,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "ckpt_save_path = ckpt_manager.save()\n",
    "pprint(f\"    - Saving checkpoint to:\", ckpt_save_path)\n",
    "\n",
    "plot_metrics(training, Y_train, Y_val, save_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Results\n",
    "\"\"\"\n",
    "\n",
    "results_train = model.evaluate(X_train, Y_train, batch_size=n_batch, verbose=0)\n",
    "results_val = model.evaluate(X_val, Y_val, batch_size=n_batch, verbose=0)\n",
    "results_test = model.evaluate(X_test, Y_test, batch_size=n_batch, verbose=0)\n",
    "results_all = model.evaluate(X_all, Y_all, batch_size=n_batch, verbose=1)\n",
    "\n",
    "Y_train_pred = model.predict(X_train, batch_size=n_batch)\n",
    "Y_val_pred = model.predict(X_val, batch_size=n_batch)\n",
    "Y_test_pred = model.predict(X_test, batch_size=n_batch)\n",
    "Y_all_pred = model.predict(X_all, batch_size=n_batch, verbose=1)\n",
    "\n",
    "describe_results(model.metrics_names, results_train, Y_train, name=\"Train\")\n",
    "describe_results(model.metrics_names, results_val, Y_val, name=\"Validation\")\n",
    "describe_results(model.metrics_names, results_test, Y_test, name=\"Test\")\n",
    "describe_results(model.metrics_names, results_all, Y_all, name=\"All\")\n",
    "\n",
    "plot_cm(Y_train, Y_train_pred, \"Training\", save_dir=model_dir)\n",
    "plot_cm(Y_val, Y_val_pred, \"Validation\", save_dir=model_dir)\n",
    "plot_cm(Y_test, Y_test_pred, \"Test\", save_dir=model_dir)\n",
    "plot_cm(Y_all, Y_all_pred, \"All\", save_dir=model_dir)\n",
    "\n",
    "plot_roc(\n",
    "    [\n",
    "        (\"Training\", Y_train, Y_train_pred),\n",
    "        (\"Validation\", Y_val, Y_val_pred),\n",
    "        (\"Test\", Y_test, Y_test_pred),\n",
    "        (\"All\", Y_all, Y_all_pred),\n",
    "    ],\n",
    "    save_dir=model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
