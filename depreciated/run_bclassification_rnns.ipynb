{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2RPN_2019_ART (dc)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                                        Loading Experience\n",
      "--------------------------------------------------------------------------------\n",
      "    - Loading chronics:                 ./results/performance-aug/l2rpn_2019_art-dc/agent-mip-chronic-****\n",
      "    - Number of loaded chronics:        99\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bclassification.utils_base import (\n",
    "    print_class_weights,\n",
    "    TrainingHistory,\n",
    "    plot_metrics,\n",
    ")\n",
    "from bclassification.utils_fc import obs_to_vect_with_tc\n",
    "from bclassification.utils_rnns import print_dataset\n",
    "from experience import load_experience\n",
    "from lib.action_space import is_do_nothing_action\n",
    "from lib.constants import Constants as Const\n",
    "from lib.data_utils import extract_history_windows\n",
    "from lib.data_utils import make_dir, env_pf\n",
    "from lib.dc_opf import TopologyConverter\n",
    "from lib.tf_utils import (\n",
    "    print_variables,\n",
    "    MatthewsCorrelationCoefficient,\n",
    ")\n",
    "from lib.visualizer import Visualizer, pprint\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "Visualizer()\n",
    "\n",
    "experience_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"performance-aug\"))\n",
    "results_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"bc-fc\"))\n",
    "\n",
    "agent_name = \"agent-mip\"\n",
    "case_name = \"l2rpn_2019_art\"\n",
    "env_dc = True\n",
    "verbose = False\n",
    "\n",
    "case_results_dir = make_dir(os.path.join(results_dir, f\"{case_name}-{env_pf(env_dc)}\"))\n",
    "case, collector = load_experience(case_name, agent_name, experience_dir, env_dc=env_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Parameters\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "model_type = \"res\"  # \"fc\" or \"res\"\n",
    "\n",
    "n_window_targets = 10\n",
    "threshold = 0.5\n",
    "\n",
    "dropout_rate = 0.2\n",
    "n_hidden = 512\n",
    "n_state = n_hidden\n",
    "\n",
    "n_batch = 2\n",
    "n_epochs = 500\n",
    "\n",
    "downsampling_rate = 0.10\n",
    "\n",
    "test_frac = 0.1\n",
    "val_frac = 0.1 / (1 - test_frac)\n",
    "\n",
    "max_chronic_len = 8064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "0                                       (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "1                                       (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "3                                       (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "4                                       (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "7                                       (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "10                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "11                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "12                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "13                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "14                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "15                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "16                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "17                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "18                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "19                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "20                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "21                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "22                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "23                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "24                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "25                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "26                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "27                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "28                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "29                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "30                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "31                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "32                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "33                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "34                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "35                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "36                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "37                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "38                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "39                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "40                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "41                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "42                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "43                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "44                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "45                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "46                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "47                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "48                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "49                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "50                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "51                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "52                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "53                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "54                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "100\n",
      "100\n",
      "55                                      (100, 246)\t(7964, 246)\t(8064, 246)\t(8064,)\t(8064,)\t(8064,)\n",
      "89\n",
      "88\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (88) into shape (89)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7c1598f145a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mchronic_Y_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchronic_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mchronic_Y_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mchronic_len\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchronic_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[0mmask_positives\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_history_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchronic_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_window\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_window_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (88) into shape (89)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Dataset\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "obs_to_vect = obs_to_vect_with_tc(TopologyConverter(case.env))\n",
    "\n",
    "X_all = []\n",
    "Y_all = []\n",
    "mask_all = []\n",
    "mask_targets = []\n",
    "\n",
    "for chronic_idx, chronic_data in collector.data.items():\n",
    "    #     chronic_obses = chronic_data[\"obses\"][:-1]\n",
    "    #     chronic_labels = is_do_nothing_action(chronic_data[\"actions\"], case.env, dtype=np.bool)\n",
    "\n",
    "    chronic_obses = chronic_data[\"obses\"][][:100]\n",
    "    chronic_len = len(chronic_obses)\n",
    "    \n",
    "    chronic_labels = is_do_nothing_action(\n",
    "        chronic_data[\"actions\"][:chronic_len], case.env, dtype=np.bool\n",
    "    )\n",
    "    print(len(chronic_obses))\n",
    "    print(len(chronic_labels))\n",
    "\n",
    "    chronic_mask = np.array(\n",
    "        [True] * chronic_len + [False] * (max_chronic_len - chronic_len)\n",
    "    )\n",
    "\n",
    "    chronic_obses_vect = np.vstack([obs_to_vect(obs) for obs in chronic_obses])\n",
    "    chronic_padding_vect = np.zeros(\n",
    "        ((max_chronic_len - chronic_len), chronic_obses_vect.shape[-1])\n",
    "    )\n",
    "    chronic_X_all = np.concatenate((chronic_obses_vect, chronic_padding_vect), axis=0)\n",
    "\n",
    "    chronic_Y_all = np.zeros_like(chronic_mask, dtype=np.bool)\n",
    "    chronic_Y_all[:chronic_len] = chronic_labels\n",
    "\n",
    "    mask_positives = extract_history_windows(chronic_labels, n_window=n_window_targets)\n",
    "    mask_negatives = np.logical_and(\n",
    "        np.random.binomial(1, downsampling_rate, len(chronic_labels)).astype(np.bool),\n",
    "        ~mask_positives,\n",
    "    )\n",
    "    chronic_mask_targets = np.zeros_like(chronic_mask, dtype=np.bool)\n",
    "    chronic_mask_targets[:chronic_len] = np.logical_or(chronic_labels, mask_negatives)\n",
    "\n",
    "    pprint(\n",
    "        chronic_idx,\n",
    "        chronic_obses_vect.shape,\n",
    "        chronic_padding_vect.shape,\n",
    "        chronic_X_all.shape,\n",
    "        chronic_Y_all.shape,\n",
    "        chronic_mask.shape,\n",
    "        chronic_mask_targets.shape,\n",
    "    )\n",
    "\n",
    "    X_all.append(chronic_X_all)\n",
    "    Y_all.append(chronic_Y_all)\n",
    "    mask_all.append(chronic_mask)\n",
    "    mask_targets.append(chronic_mask_targets)\n",
    "\n",
    "X_all = np.stack(X_all).astype(np.float)\n",
    "Y_all = np.stack(Y_all).astype(np.float)\n",
    "mask_all = np.stack(mask_all).astype(np.bool)\n",
    "mask_targets = np.stack(mask_targets).astype(np.bool)\n",
    "\n",
    "X = X_all\n",
    "Y = Y_all\n",
    "mask = np.multiply(mask_all, mask_targets)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test, mask_train, mask_test = train_test_split(\n",
    "    X, Y, mask, test_size=test_frac, random_state=random_seed\n",
    ")\n",
    "X_train, X_val, Y_train, Y_val, mask_train, mask_val = train_test_split(\n",
    "    X_train, Y_train, mask_train, test_size=val_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "print_dataset(X_all, Y_all, mask_all, \"All data\")\n",
    "print_dataset(X, Y, mask, \"Data\")\n",
    "print_dataset(X_train, Y_train, mask_train, \"Train\")\n",
    "print_dataset(X_val, Y_val, mask_val, \"Validation\")\n",
    "print_dataset(X_test, Y_test, mask_test, \"Test\")\n",
    "\n",
    "n_batch = 1\n",
    "\n",
    "train = tf.data.Dataset.from_tensor_slices(((X_train, mask_train), Y_train)).batch(\n",
    "    n_batch\n",
    ")\n",
    "val = tf.data.Dataset.from_tensor_slices(((X_val, mask_val), Y_val)).batch(n_batch)\n",
    "test = tf.data.Dataset.from_tensor_slices(((X_test, mask_test), Y_test)).batch(n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model\n",
    "\"\"\"\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.TruePositives(thresholds=threshold, name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(thresholds=threshold, name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(thresholds=threshold, name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(thresholds=threshold, name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(threshold=threshold, name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(thresholds=threshold, name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(thresholds=threshold, name=\"recall\"),\n",
    "    MatthewsCorrelationCoefficient(threshold=threshold, name=\"mcc\"),\n",
    "]\n",
    "\n",
    "n = mask.sum()\n",
    "n_positive = Y.sum()\n",
    "n_negative = n - n_positive\n",
    "\n",
    "class_weight = {0: n / n_negative / 2.0, 1: n / n_positive / 2.0}\n",
    "initial_bias = np.log([n_positive / n_negative])\n",
    "\n",
    "print_class_weights(class_weight)\n",
    "pprint(\"Initial bias:\", \"{:.4f}\".format(float(initial_bias)))\n",
    "\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "n_input = X.shape[-1]\n",
    "\n",
    "\n",
    "class RNNetworkBinary(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, input_network, output_network, n_state,\n",
    "    ):\n",
    "        super(RNNetworkBinary, self).__init__()\n",
    "\n",
    "        self.n_state = n_state\n",
    "        self.initial_state = None\n",
    "\n",
    "        self.input_network = input_network\n",
    "        self.output_network = output_network\n",
    "\n",
    "        self.class_weight = None\n",
    "        if class_weight:\n",
    "            self.class_weight = dict()\n",
    "            for c, weight in class_weight.items():\n",
    "                self.class_weight[c] = tf.constant(weight, dtype=tf.float64)\n",
    "\n",
    "        self.rnn = tf.keras.layers.LSTM(\n",
    "            self.n_state, return_sequences=True, input_shape=(max_chronic_len, n_hidden)\n",
    "        )\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[\n",
    "            tf.TensorSpec(shape=[None, max_chronic_len, n_input], dtype=tf.float64),\n",
    "            tf.TensorSpec(shape=[None, max_chronic_len], dtype=tf.bool),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.bool),\n",
    "        ]\n",
    "    )\n",
    "    def call(self, x, mask, training=None):\n",
    "        outputs = self.input_network(\n",
    "            x, training=training\n",
    "        )  # (None, seq_length, n_input)\n",
    "        outputs = self.rnn(outputs, mask=mask, training=training, initial_state=None,)\n",
    "        outputs = self.output_network(\n",
    "            outputs, training=training\n",
    "        )  # (None, seq_length, n_output)\n",
    "        outputs = tf.reshape(outputs, [-1, max_chronic_len])\n",
    "        return outputs\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.float64)])\n",
    "    def compute_sample_weight(self, y_true):\n",
    "        if self.class_weight:\n",
    "            sample_weight = tf.multiply(\n",
    "                1.0 - y_true, self.class_weight[0]\n",
    "            ) + tf.multiply(y_true, self.class_weight[1])\n",
    "        else:\n",
    "            sample_weight = tf.ones_like(y_true)\n",
    "\n",
    "        sample_weight = tf.reshape(sample_weight, [1, -1])\n",
    "\n",
    "        return sample_weight\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[\n",
    "            tf.TensorSpec(shape=[None, max_chronic_len, n_input], dtype=tf.float64),\n",
    "            tf.TensorSpec(shape=[None, max_chronic_len], dtype=tf.bool),\n",
    "            tf.TensorSpec(shape=[None, max_chronic_len], dtype=tf.float64),\n",
    "        ]\n",
    "    )\n",
    "    def train_step(self, x, mask, y):\n",
    "        with tf.GradientTape() as gt:\n",
    "            y_pred = self(x, mask, training=True)  # (None, seq_length, n_input)\n",
    "\n",
    "            y = tf.reshape(y, [-1])  # (n_batch * seq_length, )\n",
    "            y_pred = tf.reshape(y_pred, [-1])  # (n_batch * seq_length, )\n",
    "            mask = tf.reshape(mask, [1, -1])  # (1, n_batch * seq_length)\n",
    "\n",
    "            sample_weight = self.compute_sample_weight(y)\n",
    "            sample_weight = tf.multiply(sample_weight, tf.cast(mask, tf.float64))\n",
    "\n",
    "            loss = self.compiled_loss(\n",
    "                y,\n",
    "                y_pred,\n",
    "                sample_weight=sample_weight,\n",
    "                regularization_losses=self.losses,\n",
    "            )\n",
    "\n",
    "        grads = gt.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "\n",
    "        self.compiled_metrics.update_state(y, y_pred, sample_weight=mask)\n",
    "        return loss, {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=[\n",
    "            tf.TensorSpec(shape=[None, max_chronic_len, n_input], dtype=tf.float64),\n",
    "            tf.TensorSpec(shape=[None, max_chronic_len], dtype=tf.bool),\n",
    "            tf.TensorSpec(shape=[None, max_chronic_len], dtype=tf.float64),\n",
    "        ]\n",
    "    )\n",
    "    def test_step(self, x, mask, y):\n",
    "        y_pred = self(x, mask, training=False)\n",
    "\n",
    "        y = tf.reshape(y, [-1])  # (n_batch * seq_length, )\n",
    "        y_pred = tf.reshape(y_pred, [-1])  # (n_batch * seq_length, )\n",
    "        mask = tf.reshape(mask, [1, -1])  # (1, n_batch * seq_length)\n",
    "\n",
    "        sample_weight = self.compute_sample_weight(y)\n",
    "        sample_weight = tf.multiply(sample_weight, tf.cast(mask, tf.float64))\n",
    "\n",
    "        self.compiled_loss(\n",
    "            y, y_pred, sample_weight=sample_weight, regularization_losses=self.losses\n",
    "        )\n",
    "        self.compiled_metrics.update_state(y, y_pred, sample_weight=mask)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def predict(self, data):\n",
    "        y_pred = []\n",
    "\n",
    "        for (x, mask), _ in data:\n",
    "            preds = self(x, mask, training=tf.constant(True))\n",
    "            y_pred.append(preds)\n",
    "\n",
    "        y_pred = tf.concat(y_pred, axis=0)\n",
    "        return y_pred\n",
    "\n",
    "    def evaluate(self, data):\n",
    "        self.reset_metrics()\n",
    "        test_metrics = None\n",
    "        for (x, mask), y in data:\n",
    "            test_metrics = self.test_step(x, mask, y)\n",
    "\n",
    "        return test_metrics\n",
    "\n",
    "    def fit(self, data, epochs, validation_data=None):\n",
    "        training = TrainingHistory()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "\n",
    "            self.reset_metrics()\n",
    "            train_metrics = None\n",
    "            for batch, ((x, mask), y) in enumerate(data):\n",
    "                loss, train_metrics = self.train_step(x, mask, y)\n",
    "                break\n",
    "\n",
    "            training.update_history(train_metrics, epoch)\n",
    "\n",
    "            if validation_data:\n",
    "                val_metrics = model.evaluate(validation_data)\n",
    "                training.update_history(val_metrics, epoch, \"val_\")\n",
    "\n",
    "            pprint(\n",
    "                \"Epoch: {}/{}   {:.3f} s\".format(epoch, epochs, time.time() - start),\n",
    "                \"loss: {:.8f} - val_loss: {:.4f}\".format(\n",
    "                    training[\"loss\"][-1], training[\"val_loss\"][-1]\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        return training\n",
    "    \n",
    "reg = None\n",
    "input_network = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            n_hidden, input_shape=(max_chronic_len, n_input), kernel_regularizer=reg\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_hidden, kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "    ],\n",
    "    name=\"input_network\",\n",
    ")\n",
    "\n",
    "output_network = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            n_hidden, input_shape=(max_chronic_len, 2 * n_state), kernel_regularizer=reg\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_hidden, kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(\n",
    "            1,\n",
    "            activation=\"sigmoid\",\n",
    "            bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "        ),\n",
    "    ],\n",
    "    name=\"output_network\",\n",
    ")\n",
    "\n",
    "model = RNNetworkBinary(\n",
    "    input_network=input_network, output_network=output_network, n_state=2 * n_state,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Training\n",
    "\"\"\"\n",
    "\n",
    "training = model.fit(train, epochs=2, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_variables(model.trainable_variables)\n",
    "plot_metrics(training, Y_train, Y_val, save_dir=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
