{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2RPN_2019_ART (dc)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                                        Loading Experience\n",
      "--------------------------------------------------------------------------------\n",
      "    - Loading chronics:                 ./experience/data-aug/l2rpn_2019_art-dc/agent-mip-chronic-****\n",
      "    - Number of loaded chronics:        4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import graph_nets as gns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bclassification.utils_base import (\n",
    "    print_class_weights,\n",
    "    compute_weight_bias,\n",
    "    print_dataset,\n",
    ")\n",
    "from bclassification.utils_gnsn import create_dataset\n",
    "from experience import load_experience\n",
    "from lib.constants import Constants as Const\n",
    "from lib.data_utils import (\n",
    "    make_dir,\n",
    "    env_pf,\n",
    "    create_results_dir,\n",
    ")\n",
    "from lib.gns import get_graph_feature_dimensions\n",
    "from lib.visualizer import Visualizer, pprint\n",
    "\n",
    "Visualizer()\n",
    "\n",
    "experience_dir = make_dir(os.path.join(Const.EXPERIENCE_DIR, \"data-aug\"))\n",
    "# experience_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"performance-aug\"))\n",
    "results_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"_bc-gnsn\"))\n",
    "\n",
    "agent_name = \"agent-mip\"\n",
    "case_name = \"l2rpn_2019_art\"\n",
    "env_dc = True\n",
    "verbose = False\n",
    "\n",
    "case_results_dir = make_dir(os.path.join(results_dir, f\"{case_name}-{env_pf(env_dc)}\"))\n",
    "case, collector = load_experience(case_name, agent_name, experience_dir, env_dc=env_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Parameters\n",
    "\"\"\"\n",
    "random_seed = 0\n",
    "\n",
    "mode = \"binary\"\n",
    "\n",
    "n_window_targets = 0\n",
    "n_window_history = 1\n",
    "downsampling_rate = 0.1\n",
    "feature_scaling = True\n",
    "val_frac = 0.10\n",
    "\n",
    "# Model\n",
    "model_type = \"gn\"\n",
    "dropout_rate = 0.0\n",
    "l2_reg = 0.0\n",
    "n_hidden = 256\n",
    "n_hidden_layers = 4\n",
    "threshold = 0.50\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-5\n",
    "n_batch = 512\n",
    "n_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Input structure:                  binary\n",
      "(20, 8)\n",
      "[[ 66   0   1   1   0   0   0   0]\n",
      " [ 49   1   1   1   0   0   0   0]\n",
      " [ 30   0   1   1   0   0   0   0]\n",
      " [ 49   1   1   1   0   0   0   0]\n",
      " [ 41   1   1   1   0   0   0   0]\n",
      " [ 16   0   1   1   0   0   0   0]\n",
      " [-39   1   1   1   0   0   0   0]\n",
      " [ 32   1   1   1   0   0   0   0]\n",
      " [ 18   1   1   1   0   0   0   0]\n",
      " [ 43   1   1   1   0   0   0   0]\n",
      " [ 18   1   1   1   0   0   0   0]\n",
      " [  8   0   1   1   0   0   0   0]\n",
      " [  6   0   1   1   0   0   0   0]\n",
      " [  0   0   1   1   0   0   0   0]\n",
      " [ 32   1   1   1   0   0   0   0]\n",
      " [ 11   0   1   1   0   0   0   0]\n",
      " [  7   0   1   1   0   0   0   0]\n",
      " [ -2   0   1   1   0   0   0   0]\n",
      " [  1   0   1   1   0   0   0   0]\n",
      " [  5   0   1   1   0   0   0   0]]\n",
      "(160,)\n",
      "(14, 48)\n",
      "[[  0   0   0   0 118   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 77   0   0   0   0  24   0   0   0   0   0   0   0   0   0   0   1   0\n",
      "    0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  80   0   0   0   0  94   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  54   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  12   0   0   0   0   0   0   0   0\n",
      "    1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  31   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   9   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   4   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   6   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  14   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "(672,)\n",
      "gen 5\n",
      "load 11\n",
      "line 20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lib.action_space import is_do_nothing_action\n",
    "from lib.data_utils import (\n",
    "    moving_window,\n",
    "    extract_history_windows,\n",
    ")\n",
    "from lib.dc_opf import TopologyConverter\n",
    "from lib.visualizer import pprint\n",
    "\n",
    "\n",
    "def obs_to_vects(obs, tc, mode):\n",
    "    lines_or_to_sub_bus = tc.lines_or_to_sub_bus(obs)\n",
    "    lines_ex_to_sub_bus = tc.lines_ex_to_sub_bus(obs)\n",
    "    gens_to_sub_bus = tc.gens_to_sub_bus(obs)\n",
    "    loads_to_sub_bus = tc.loads_to_sub_bus(obs)\n",
    "    \n",
    "    gen_to_sub_id = tc.gen_to_sub_id\n",
    "    load_to_sub_id = tc.load_to_sub_id\n",
    "    line_or_to_sub_id = tc.line_or_to_sub_id\n",
    "    line_ex_to_sub_id = tc.line_ex_to_sub_id\n",
    "    \n",
    "    if mode == \"binary\":\n",
    "        line_vect = list()\n",
    "        line_vect.append(np.atleast_2d(obs.p_or).T)\n",
    "        line_vect.append(np.atleast_2d(obs.rho).T)\n",
    "        for bus in [1, 2]:\n",
    "            mask_or = np.equal(lines_or_to_sub_bus, bus).astype(np.float)\n",
    "            mask_ex = np.equal(lines_ex_to_sub_bus, bus).astype(np.float)\n",
    "            mask_or = np.multiply(mask_or, obs.line_status.astype(np.float))\n",
    "            mask_ex = np.multiply(mask_ex, obs.line_status.astype(np.float))\n",
    "            \n",
    "            line_vect.append(np.atleast_2d(mask_or).T)\n",
    "            line_vect.append(np.atleast_2d(mask_ex).T)\n",
    "        \n",
    "        line_vect.append(np.atleast_2d(obs.time_before_cooldown_line.astype(np.float)).T)\n",
    "        line_vect.append(np.atleast_2d(obs.timestep_overflow.astype(np.float)).T)\n",
    "        # line_vect.append(np.atleast_2d(obs.time_next_maintenance.astype(np.float)).T)\n",
    "        # line_vect.append(np.atleast_2d(obs.duration_next_maintenance.astype(np.float)).T)\n",
    "        line_vect = np.nan_to_num(np.hstack(line_vect))\n",
    "        \n",
    "        sub_vect = list()\n",
    "        for sub_id in range(tc.n_sub):\n",
    "            vect = list()\n",
    "\n",
    "            mask_sub_gen = np.equal(gen_to_sub_id, sub_id).astype(np.float)\n",
    "            mask_sub_load = np.equal(load_to_sub_id, sub_id).astype(np.float)\n",
    "            \n",
    "            prods = np.multiply(mask_sub_gen, obs.prod_p)\n",
    "            loads = np.multiply(mask_sub_load, obs.load_p)            \n",
    "            \n",
    "            vect.append(prods)\n",
    "            vect.append(loads)\n",
    "            for bus in [1, 2]:\n",
    "                mask_bus_gen = np.equal(gens_to_sub_bus, bus).astype(np.float)\n",
    "                mask_gen = np.multiply(mask_bus_gen, mask_sub_gen)\n",
    "                \n",
    "                mask_bus_load = np.equal(loads_to_sub_bus, bus).astype(np.float)\n",
    "                mask_load = np.multiply(mask_bus_load, mask_sub_load)\n",
    "\n",
    "                vect.append(mask_gen)\n",
    "                vect.append(mask_load)\n",
    "                \n",
    "            vect = np.hstack(vect)\n",
    "            sub_vect.append(vect)\n",
    "                \n",
    "        sub_vect = np.nan_to_num(np.vstack(sub_vect))\n",
    "                \n",
    "        vects = (\n",
    "            line_vect.astype(np.float),\n",
    "            sub_vect.astype(np.float),\n",
    "        )\n",
    "    elif mode == \"structured\":\n",
    "        line_vect = list()\n",
    "        line_vect.append(np.atleast_2d(obs.p_or).T)\n",
    "        line_vect.append(np.atleast_2d(obs.rho).T)\n",
    "        for bus in [1, 2]:\n",
    "            mask_or = np.equal(lines_or_to_sub_bus, bus).astype(np.float)\n",
    "            mask_ex = np.equal(lines_ex_to_sub_bus, bus).astype(np.float)\n",
    "            mask_or = np.multiply(mask_or, obs.line_status.astype(np.float))\n",
    "            mask_ex = np.multiply(mask_ex, obs.line_status.astype(np.float))\n",
    "            \n",
    "            line_vect.append(np.atleast_2d(mask_or).T)\n",
    "            line_vect.append(np.atleast_2d(mask_ex).T)\n",
    "        \n",
    "        line_vect.append(np.atleast_2d(obs.time_before_cooldown_line.astype(np.float)).T)\n",
    "        line_vect.append(np.atleast_2d(obs.timestep_overflow.astype(np.float)).T)\n",
    "        # line_vect.append(np.atleast_2d(obs.time_next_maintenance.astype(np.float)).T)\n",
    "        # line_vect.append(np.atleast_2d(obs.duration_next_maintenance.astype(np.float)).T)\n",
    "        line_vect = np.nan_to_num(np.hstack(line_vect))\n",
    "        \n",
    "        sub_vect = list()\n",
    "        for sub_id in range(tc.n_sub):\n",
    "            mask_sub_gen = np.equal(gen_to_sub_id, sub_id).astype(np.float)\n",
    "            mask_sub_load = np.equal(load_to_sub_id, sub_id).astype(np.float)\n",
    "            \n",
    "            vect = list()\n",
    "            for bus in [1, 2]:\n",
    "                mask_bus_gen = np.equal(gens_to_sub_bus, bus).astype(np.float)\n",
    "                mask_gen = np.multiply(mask_bus_gen, mask_sub_gen)\n",
    "                prods = np.multiply(mask_gen, obs.prod_p)\n",
    "                \n",
    "                mask_bus_load = np.equal(loads_to_sub_bus, bus).astype(np.float)\n",
    "                mask_load = np.multiply(mask_bus_load, mask_sub_load)\n",
    "                loads = np.multiply(mask_load, obs.load_p)\n",
    "\n",
    "                vect.append(prods)\n",
    "                vect.append(loads)\n",
    "                \n",
    "            vect = np.hstack(vect)\n",
    "            sub_vect.append(vect)\n",
    "                \n",
    "        sub_vect = np.nan_to_num(np.vstack(sub_vect))\n",
    "                \n",
    "        vects = (\n",
    "            line_vect.astype(np.float),\n",
    "            sub_vect.astype(np.float),\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode.\")\n",
    "\n",
    "    return vects\n",
    "\n",
    "\n",
    "def create_dataset(\n",
    "    case,\n",
    "    collector,\n",
    "    mode,\n",
    "    n_window_targets=0,\n",
    "    n_window_history=0,\n",
    "    downsampling_rate=1.0,\n",
    "    feature_scaling=True,\n",
    "):\n",
    "    tc = TopologyConverter(case.env)\n",
    "    process_fn = lambda obs: obs_to_vects(obs, tc, mode)\n",
    "    combine_fn = lambda obs_vects: np.concatenate(obs_vects)\n",
    "\n",
    "    X_all = []\n",
    "    Y_all = []\n",
    "    mask_targets = []\n",
    "\n",
    "    obs_sample = None\n",
    "\n",
    "    pprint(\"    - Input structure:\", mode)\n",
    "\n",
    "    for chronic_idx, chronic_data in collector.data.items():\n",
    "        chronic_len = len(chronic_data[\"actions\"])\n",
    "        chronic_obses = chronic_data[\"obses\"][:chronic_len]\n",
    "        chronic_labels = is_do_nothing_action(\n",
    "            chronic_data[\"actions\"][:chronic_len], case.env, dtype=np.bool\n",
    "        )\n",
    "\n",
    "        # Mask\n",
    "        mask_positives = extract_history_windows(\n",
    "            chronic_labels, n_window=n_window_targets\n",
    "        )\n",
    "        mask_negatives = np.logical_and(\n",
    "            np.random.binomial(1, downsampling_rate, len(chronic_labels)).astype(\n",
    "                np.bool\n",
    "            ),\n",
    "            ~mask_positives,\n",
    "        )\n",
    "        chronic_mask_targets = np.logical_or(chronic_labels, mask_negatives)\n",
    "\n",
    "        # Observation\n",
    "        obs_sample = chronic_obses[0]\n",
    "        chronic_X = moving_window(\n",
    "            chronic_obses,\n",
    "            n_window=n_window_history,\n",
    "            process_fn=process_fn,\n",
    "            combine_fn=combine_fn,\n",
    "            padding=np.zeros_like(process_fn(obs_sample),\n",
    "        )\n",
    "        chronic_X = np.vstack(chronic_X)\n",
    "\n",
    "        X_all.append(chronic_X)\n",
    "        Y_all.extend(chronic_labels.astype(np.float))\n",
    "        mask_targets.extend(chronic_mask_targets)\n",
    "\n",
    "    X_all = np.vstack(X_all)\n",
    "    Y_all = np.array(Y_all)\n",
    "    mask_targets = np.array(mask_targets)\n",
    "        \n",
    "create_dataset(\n",
    "    case,\n",
    "    collector,\n",
    "    mode=mode,\n",
    "    n_window_history=n_window_history,\n",
    "    n_window_targets=n_window_targets,\n",
    "    downsampling_rate=downsampling_rate,\n",
    "    feature_scaling=feature_scaling,\n",
    ")\n",
    "\n",
    "print(\"gen\", case.env.n_gen)\n",
    "print(\"load\", case.env.n_load)\n",
    "print(\"line\", case.env.n_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Dataset\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "X, Y, mask_targets, X_all, Y_all = create_dataset(\n",
    "    case,\n",
    "    collector,\n",
    "    mode=mode,\n",
    "    n_window_history=n_window_history,\n",
    "    n_window_targets=n_window_targets,\n",
    "    downsampling_rate=downsampling_rate,\n",
    "    feature_scaling=feature_scaling,\n",
    ")\n",
    "\n",
    "class_weight, initial_bias = compute_weight_bias(Y)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X, Y, test_size=val_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "mask_test_neg = np.logical_and(\n",
    "    ~mask_targets, np.random.binomial(1, val_frac, mask_targets.size).astype(np.bool)\n",
    ")\n",
    "X_test = np.concatenate((X_val, X_all[mask_test_neg, :]))\n",
    "Y_test = np.concatenate((Y_val, Y_all[mask_test_neg]))\n",
    "\n",
    "print_dataset(X_all, Y_all, \"All data\")\n",
    "print_dataset(X, Y, \"Data\")\n",
    "print_dataset(X_train, Y_train, \"Train\")\n",
    "print_dataset(X_val, Y_val, \"Validation\")\n",
    "print_dataset(X_test, Y_test, \"Test\")\n",
    "print_class_weights(class_weight)\n",
    "pprint(\"Initial bias:\", \"{:.4f}\".format(float(initial_bias)))\n",
    "\n",
    "model_dir = create_results_dir(case_results_dir, model_name=model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
