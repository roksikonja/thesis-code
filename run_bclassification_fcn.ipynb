{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2RPN_2019_ART (dc)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                                        Loading Experience\n",
      "--------------------------------------------------------------------------------\n",
      "    - Loading chronics:                 ./results/performance-aug/l2rpn_2019_art-dc/agent-mip-chronic-****\n",
      "    - Number of loaded chronics:        117\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bclassification.utils_base import (\n",
    "    print_class_weights,\n",
    "    compute_weight_bias,\n",
    "    print_dataset,\n",
    "    plot_metrics,\n",
    "    plot_cm,\n",
    "    plot_roc,\n",
    "    describe_results,\n",
    ")\n",
    "from bclassification.utils_fcn import create_dataset\n",
    "from experience import load_experience\n",
    "from lib.constants import Constants as Const\n",
    "from lib.data_utils import (\n",
    "    make_dir,\n",
    "    env_pf,\n",
    "    create_results_dir,\n",
    "    save_dict_to_file,\n",
    ")\n",
    "from lib.tf_utils import (\n",
    "    print_variables,\n",
    "    ResidulaFCBlock,\n",
    "    MatthewsCorrelationCoefficient,\n",
    ")\n",
    "from lib.visualizer import Visualizer, pprint\n",
    "\n",
    "Visualizer()\n",
    "\n",
    "# experience_dir = make_dir(os.path.join(Const.EXPERIENCE_DIR, \"data-aug\"))\n",
    "experience_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"performance-aug\"))\n",
    "results_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"_bc-fcn\"))\n",
    "\n",
    "agent_name = \"agent-mip\"\n",
    "case_name = \"l2rpn_2019_art\"\n",
    "env_dc = True\n",
    "verbose = False\n",
    "\n",
    "case_results_dir = make_dir(os.path.join(results_dir, f\"{case_name}-{env_pf(env_dc)}\"))\n",
    "case, collector = load_experience(case_name, agent_name, experience_dir, env_dc=env_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Parameters\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "input_mode = \"structured\"\n",
    "# label_mode = \"sub-1\"\n",
    "label_mode = \"dn\"\n",
    "\n",
    "n_window_targets = 0\n",
    "n_window_history = 1\n",
    "downsampling_rate = 0.10\n",
    "n_window_forecasts = 1\n",
    "use_actions = True\n",
    "feature_scaling = True\n",
    "val_frac = 0.10\n",
    "\n",
    "# Model\n",
    "model_type = \"res\"  # \"fc\" or \"res\"\n",
    "dropout_rate = 0.4\n",
    "l2_reg = 1e-7\n",
    "n_hidden = 256\n",
    "n_hidden_layers = 4\n",
    "threshold = 0.50\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-6\n",
    "n_batch = 512\n",
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-bdbaffb3f3c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mn_window_forecasts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_window_forecasts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0muse_actions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_actions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mfeature_scaling\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_scaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - PG\\thesis-code\\bclassification\\utils_fcn.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[1;34m(case, collector, input_mode, label_mode, n_window_targets, n_window_history, downsampling_rate, n_window_forecasts, use_actions, feature_scaling)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mchronic_X_forecasts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_window_forecasts\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0mprods\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcollector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_forecasts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchronic_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m             chronic_X_forecasts = np.concatenate(\n\u001b[0;32m    237\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mprods\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mchronic_len\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mchronic_len\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - PG\\thesis-code\\experience\\collector.py\u001b[0m in \u001b[0;36mload_forecasts\u001b[1;34m(self, env, chronic_idx)\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mcase_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatasets_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mchronics_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchronics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchronics_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sorted_chronics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[0mcase_chronics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchronics_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - PG\\thesis-code\\lib\\chronics.py\u001b[0m in \u001b[0;36mget_sorted_chronics\u001b[1;34m(env)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_sorted_chronics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mchronics_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchronics_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mchronics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchronics_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Filter meta files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "\"\"\"\n",
    "    Dataset\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "X, Y, mask_targets, X_all, Y_all = create_dataset(\n",
    "    case,\n",
    "    collector,\n",
    "    input_mode=input_mode,\n",
    "    label_mode=label_mode,\n",
    "    n_window_history=n_window_history,\n",
    "    n_window_targets=n_window_targets,\n",
    "    downsampling_rate=downsampling_rate,\n",
    "    n_window_forecasts=n_window_forecasts,\n",
    "    use_actions=use_actions,\n",
    "    feature_scaling=feature_scaling\n",
    ")\n",
    "\n",
    "class_weight, initial_bias = compute_weight_bias(Y)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X, Y, test_size=val_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "mask_test_neg = np.logical_and(~mask_targets, np.random.binomial(1, val_frac, mask_targets.size).astype(np.bool))\n",
    "X_test = np.concatenate((X_val, X_all[mask_test_neg, :]))\n",
    "Y_test = np.concatenate((Y_val, Y_all[mask_test_neg]))\n",
    "\n",
    "print_dataset(X_all, Y_all, \"All data\")\n",
    "print_dataset(X, Y, \"Data\")\n",
    "print_dataset(X_train, Y_train, \"Train\")\n",
    "print_dataset(X_val, Y_val, \"Validation\")\n",
    "print_dataset(X_test, Y_test, \"Test\")\n",
    "print_class_weights(class_weight)\n",
    "pprint(\"Initial bias:\", \"{:.4f}\".format(float(initial_bias)))\n",
    "\n",
    "model_dir = create_results_dir(case_results_dir, model_name=model_type)\n",
    "\n",
    "del X_all\n",
    "del Y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model\n",
    "\"\"\"\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.TruePositives(thresholds=threshold, name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(thresholds=threshold, name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(thresholds=threshold, name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(thresholds=threshold, name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(threshold=threshold, name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(thresholds=threshold, name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(thresholds=threshold, name=\"recall\"),\n",
    "    MatthewsCorrelationCoefficient(threshold=threshold, name=\"mcc\"),\n",
    "    tf.keras.metrics.AUC(name=\"auc\"),\n",
    "]\n",
    "\n",
    "if l2_reg > 0:\n",
    "    kwargs_reg = {\n",
    "        \"kernel_regularizer\": tf.keras.regularizers.L2(l2=l2_reg),\n",
    "        \"bias_regularizer\": tf.keras.regularizers.L2(l2=l2_reg),\n",
    "    }\n",
    "else:\n",
    "    kwargs_reg = {}\n",
    "\n",
    "input_dim = X.shape[-1]\n",
    "\n",
    "tf.random.set_seed(random_seed)\n",
    "if model_type == \"fc\":\n",
    "    hidden_layers = [\n",
    "        (\n",
    "            tf.keras.layers.Dense(n_hidden, activation=\"relu\", **kwargs_reg),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "        )\n",
    "        for _ in range(n_hidden_layers)\n",
    "    ]\n",
    "    hidden_layers = list(itertools.chain(*hidden_layers))\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                n_hidden, activation=\"relu\", input_shape=(input_dim,), **kwargs_reg\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            *hidden_layers,\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "                **kwargs_reg,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    hidden_layers = [\n",
    "        (\n",
    "            ResidulaFCBlock(n_hidden, activation=\"relu\", **kwargs_reg),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "        )\n",
    "        for _ in range(n_hidden_layers // 2)\n",
    "    ]\n",
    "    hidden_layers = list(itertools.chain(*hidden_layers))\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                n_hidden, activation=\"relu\", input_shape=(input_dim,), **kwargs_reg\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            *hidden_layers,\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "                **kwargs_reg,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "checkpoint_path = os.path.join(model_dir, \"ckpts\")\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=model.optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "pprint(\"Model directory:\", model_dir)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    pprint(\"Restoring checkpoint from:\", ckpt_manager.latest_checkpoint)\n",
    "    \n",
    "    \n",
    "save_dict_to_file(\n",
    "    {\n",
    "        \"random_seed\": random_seed,\n",
    "        \"input_mode\": input_mode,\n",
    "        \"label_mode\": label_mode,\n",
    "        \"val_frac\": val_frac,\n",
    "        \"downsampling_rate\": downsampling_rate,\n",
    "        \"n_window_targets\": n_window_targets,\n",
    "        \"n_window_history\": n_window_history,\n",
    "        \"use_actions\": use_actions,\n",
    "        \"feature_scaling\": feature_scaling,\n",
    "        \"model_type\": model_type,\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"l2_reg\": l2_reg,\n",
    "        \"n_hidden\": n_hidden,\n",
    "        \"n_hidden_layers\": n_hidden_layers,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_batch\": n_batch,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"threshold\": threshold,\n",
    "    },\n",
    "    os.path.join(model_dir, \"params.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.show()\n",
    "\n",
    "with open(os.path.join(model_dir, \"log.txt\"), \"a\") as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Training\n",
    "\"\"\"\n",
    "tensorboard_path = os.path.join(model_dir, \"logs\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=tensorboard_path, write_graph=False, write_images=False, update_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "print(f\"tensorboard --logdir={tensorboard_path}\")\n",
    "\n",
    "\n",
    "training = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=n_batch,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=[tensorboard_callback],\n",
    "    verbose=4,\n",
    ")\n",
    "\n",
    "ckpt_save_path = ckpt_manager.save()\n",
    "pprint(f\"    - Saving checkpoint to:\", ckpt_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "\"\"\"\n",
    "    Results\n",
    "\"\"\"\n",
    "\n",
    "print_variables(model.trainable_variables)\n",
    "plot_metrics(training, Y_train, Y_val, save_dir=model_dir)\n",
    "\n",
    "results_train = model.evaluate(X_train, Y_train, batch_size=n_batch, verbose=0)\n",
    "results_val = model.evaluate(X_val, Y_val, batch_size=n_batch, verbose=0)\n",
    "results_test = model.evaluate(X_test, Y_test, batch_size=n_batch, verbose=0)\n",
    "\n",
    "Y_train_pred = model.predict(X_train, batch_size=n_batch)\n",
    "Y_val_pred = model.predict(X_val, batch_size=n_batch)\n",
    "Y_test_pred = model.predict(X_test, batch_size=n_batch)\n",
    "\n",
    "describe_results(model.metrics_names, results_train, Y_train, name=\"Train\")\n",
    "describe_results(model.metrics_names, results_val, Y_val, name=\"Validation\")\n",
    "describe_results(model.metrics_names, results_test, Y_test, name=\"Test\")\n",
    "\n",
    "plot_cm(Y_train, Y_train_pred, \"Training\", save_dir=model_dir)\n",
    "plot_cm(Y_val, Y_val_pred, \"Validation\", save_dir=model_dir)\n",
    "plot_cm(Y_test, Y_test_pred, \"Test\", save_dir=model_dir)\n",
    "\n",
    "plot_roc(\n",
    "    [\n",
    "        (\"Training\", Y_train, Y_train_pred),\n",
    "        (\"Validation\", Y_val, Y_val_pred),\n",
    "        (\"Test\", Y_test, Y_test_pred),\n",
    "    ],\n",
    "    save_dir=model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.show()\n",
    "\n",
    "with open(os.path.join(model_dir, \"log.txt\"), \"a\") as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
