{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "\n",
    "\n",
    "def print_class_weights(class_weight):\n",
    "    print(\"Class\", \"Weight\")\n",
    "    for c in class_weight:\n",
    "        print(f\"    - {c}\", \"{:.5f}\".format(class_weight[c]))\n",
    "\n",
    "\n",
    "def compute_weight_bias(y):\n",
    "    n_negative, n_positive = np.bincount(y.astype(int))\n",
    "    n = n_negative + n_positive\n",
    "\n",
    "    class_weight = {0: n / n_negative / 2.0, 1: n / n_positive / 2.0}\n",
    "    initial_bias = np.log([n_positive / n_negative])\n",
    "\n",
    "    return class_weight, initial_bias\n",
    "\n",
    "\n",
    "def plot_metrics(training, y_train, y_val, save_dir=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(training.epoch, training.history[\"loss\"], label=\"Training\", lw=0.5)\n",
    "    ax.plot(training.epoch, training.history[\"val_loss\"], label=\"Validation\", lw=0.5)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.legend()\n",
    "\n",
    "    if save_dir:\n",
    "        fig.savefig(os.path.join(save_dir, \"training-loss\"))\n",
    "\n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"fp\", \"fn\", \"mcc\"]\n",
    "    fig, _ = plt.subplots(3, 2, figsize=(16, 12))\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = plt.subplot(3, 2, i + 1)\n",
    "\n",
    "        epochs = training.epoch\n",
    "        train_metric = training.history[metric]\n",
    "        val_metric = training.history[\"val_\" + metric]\n",
    "\n",
    "        if metric == \"fn\":\n",
    "            metric = \"fnr\"\n",
    "            train_n_pos = np.sum(np.equal(y_train, 1))\n",
    "            val_n_pos = np.sum(np.equal(y_val, 1))\n",
    "\n",
    "            train_metric = np.divide(train_metric, train_n_pos)\n",
    "            val_metric = np.divide(val_metric, val_n_pos)\n",
    "        elif metric == \"fp\":\n",
    "            metric = \"fpr\"\n",
    "            train_n_neg = np.sum(np.equal(y_train, 0))\n",
    "            val_n_neg = np.sum(np.equal(y_val, 0))\n",
    "\n",
    "            train_metric = np.divide(train_metric, train_n_neg)\n",
    "            val_metric = np.divide(val_metric, val_n_neg)\n",
    "\n",
    "        name = metric.replace(\"_\", \" \").upper()\n",
    "        ax.plot(epochs, train_metric, label=\"Training\", lw=0.5)\n",
    "        ax.plot(epochs, val_metric, label=\"Validation\", lw=0.5)\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "        ax.set_ylabel(name)\n",
    "\n",
    "        if metric == \"mcc\":\n",
    "            # ax.set_ylim([-1.0, 1.0])\n",
    "            pass\n",
    "        else:\n",
    "            ax.set_ylim([0.0, 1.0])\n",
    "\n",
    "        ax.legend()\n",
    "\n",
    "    if save_dir:\n",
    "        fig.savefig(os.path.join(save_dir, \"training-metrics\"))\n",
    "\n",
    "\n",
    "def plot_cm(labels, predictions, name, p=0.5, save_dir=None):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", ax=ax)\n",
    "    fig.suptitle(\"Confusion matrix: Threshold at p = {:.2f}\".format(p))\n",
    "    ax.set_title(name)\n",
    "    ax.set_ylabel(\"Actual label\")\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "\n",
    "    if save_dir:\n",
    "        fig.savefig(os.path.join(save_dir, f\"{name.lower()}-cm\"))\n",
    "\n",
    "\n",
    "def describe_results(metrics, results, y, name=None):\n",
    "    print(\"\\n    - Dataset\", name)\n",
    "\n",
    "    for metric, value in zip(metrics, results):\n",
    "        if metric in [\"tp\", \"fn\", \"tn\", \"fp\"]:\n",
    "            if metric in [\"tp\", \"fn\"]:\n",
    "                c = 1\n",
    "            else:\n",
    "                c = 0\n",
    "\n",
    "            n = np.sum(np.equal(y, c))\n",
    "            rate = 100.0 * value / n\n",
    "\n",
    "            ratio_str = \"{}/{}\".format(int(value), int(n))\n",
    "            print(\n",
    "                f\"        - {metric.upper()}:\",\n",
    "                \"{:<15}{:>8.2f} %\".format(ratio_str, rate),\n",
    "            )\n",
    "        elif metric == \"mcc\":\n",
    "            mcc_tf = float(value)\n",
    "            print(f\"        - {metric.capitalize()}:\", \"{:.4f}\".format(mcc_tf))\n",
    "        else:\n",
    "            print(f\"        - {metric.capitalize()}:\", \"{:.4f}\".format(value))\n",
    "\n",
    "\n",
    "def plot_roc(triplets, save_dir=None):\n",
    "    fig, ax = plt.subplots(figsize=(16, 5))\n",
    "    for label, Y, Y_pred in triplets:\n",
    "        fp, tp, _ = roc_curve(Y, Y_pred)\n",
    "        ax.plot(fp, tp, label=label, lw=2)\n",
    "\n",
    "    ax.set_xlabel(\"False positives\")\n",
    "    ax.set_ylabel(\"True positives\")\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    if save_dir:\n",
    "        fig.savefig(os.path.join(save_dir, \"roc\"))\n",
    "\n",
    "\n",
    "def print_dataset(x, y, name):\n",
    "    print(f\"    - {name}:\", \"X, Y\", \"{:>20}, {}\".format(str(x.shape), str(y.shape)))\n",
    "    print(\"        - Positive labels:\", \"{:.2f} %\".format(100 * y.mean()))\n",
    "    print(\"        - Negative labels:\", \"{:.2f} %\".format(100 * (1 - y).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Parameters\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "# Data\n",
    "test_frac = 0.10\n",
    "val_frac = 0.10\n",
    "\n",
    "downsampling_rate = 0.20\n",
    "\n",
    "n_window_targets = 20\n",
    "n_window_history = 2\n",
    "n_window_forecasts = 1\n",
    "\n",
    "use_forecasts = True\n",
    "use_actions = True\n",
    "\n",
    "# Model\n",
    "model_type = \"res\"  # \"fc\" or \"res\"\n",
    "dropout_rate = 0.2\n",
    "l2_reg = 1e-4\n",
    "n_hidden = 512\n",
    "n_hidden_layers = 8\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-3\n",
    "n_batch = 512\n",
    "n_epochs = 200\n",
    "\n",
    "# Prediction\n",
    "threshold = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(f\"fc-data-h{n_window_history}-f{n_window_forecasts}\")\n",
    "X_all, Y_all = data[\"X_all\"], data[\"Y_all\"]\n",
    "X, Y, mask_targets = data[\"X\"], data[\"Y\"], data[\"mask_targets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X, Y, test_size=val_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "mask_test_neg = np.logical_and(~mask_targets, np.random.binomial(1, 0.08, mask_targets.size).astype(np.bool))\n",
    "X_test = np.concatenate((X_val, X_all[mask_test_neg, :]))\n",
    "Y_test = np.concatenate((Y_val, Y_all[mask_test_neg]))\n",
    "\n",
    "class_weight, initial_bias = compute_weight_bias(Y)\n",
    "\n",
    "print_dataset(X_all, Y_all, \"All data\")\n",
    "print_dataset(X, Y, \"Data\")\n",
    "print_dataset(X_train, Y_train, \"Train\")\n",
    "print_dataset(X_val, Y_val, \"Validation\")\n",
    "print_dataset(X_test, Y_test, \"Test\")\n",
    "print_class_weights(class_weight)\n",
    "pprint(\"Initial bias:\", \"{:.4f}\".format(float(initial_bias)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model\n",
    "\"\"\"\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.TruePositives(thresholds=threshold, name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(thresholds=threshold, name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(thresholds=threshold, name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(thresholds=threshold, name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(threshold=threshold, name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(thresholds=threshold, name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(thresholds=threshold, name=\"recall\"),\n",
    "    MatthewsCorrelationCoefficient(threshold=threshold, name=\"mcc\"),\n",
    "]\n",
    "\n",
    "if l2_reg > 0:\n",
    "    kwargs_reg = {\n",
    "        \"kernel_regularizer\": tf.keras.regularizers.L2(l2=l2_reg),\n",
    "        \"bias_regularizer\": tf.keras.regularizers.L2(l2=l2_reg),\n",
    "    }\n",
    "else:\n",
    "    kwargs_reg = {}\n",
    "\n",
    "input_dim = X.shape[-1]\n",
    "\n",
    "tf.random.set_seed(random_seed)\n",
    "if model_type == \"fc\":\n",
    "    hidden_layers = [\n",
    "        (\n",
    "            tf.keras.layers.Dense(n_hidden, activation=\"relu\", **kwargs_reg),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "        )\n",
    "        for _ in range(n_hidden_layers)\n",
    "    ]\n",
    "    hidden_layers = list(itertools.chain(*hidden_layers))\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                n_hidden, activation=\"relu\", input_shape=(input_dim,), **kwargs_reg\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            *hidden_layers,\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "                **kwargs_reg,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    hidden_layers = [\n",
    "        (\n",
    "            ResidulaFCBlock(n_hidden, activation=\"relu\", **kwargs_reg),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "        )\n",
    "        for _ in range(n_hidden_layers // 2)\n",
    "    ]\n",
    "    hidden_layers = list(itertools.chain(*hidden_layers))\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                n_hidden, activation=\"relu\", input_shape=(input_dim,), **kwargs_reg\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            *hidden_layers,\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "                **kwargs_reg,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Training\n",
    "\"\"\"\n",
    "\n",
    "training = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=n_batch,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "ckpt_save_path = ckpt_manager.save()\n",
    "pprint(f\"    - Saving checkpoint to:\", ckpt_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Results\n",
    "\"\"\"\n",
    "\n",
    "print_variables(model.trainable_variables)\n",
    "plot_metrics(training, Y_train, Y_val, save_dir=model_dir)\n",
    "\n",
    "results_train = model.evaluate(X_train, Y_train, batch_size=n_batch, verbose=0)\n",
    "results_val = model.evaluate(X_val, Y_val, batch_size=n_batch, verbose=0)\n",
    "results_test = model.evaluate(X_test, Y_test, batch_size=n_batch, verbose=0)\n",
    "results_all = model.evaluate(X_all, Y_all, batch_size=n_batch, verbose=0)\n",
    "\n",
    "Y_train_pred = model.predict(X_train, batch_size=n_batch)\n",
    "Y_val_pred = model.predict(X_val, batch_size=n_batch)\n",
    "Y_test_pred = model.predict(X_test, batch_size=n_batch)\n",
    "Y_all_pred = model.predict(X_all, batch_size=n_batch, verbose=0)\n",
    "\n",
    "describe_results(model.metrics_names, results_train, Y_train, name=\"Train\")\n",
    "describe_results(model.metrics_names, results_val, Y_val, name=\"Validation\")\n",
    "describe_results(model.metrics_names, results_test, Y_test, name=\"Test\")\n",
    "describe_results(model.metrics_names, results_all, Y_all, name=\"All\")\n",
    "\n",
    "plot_cm(Y_train, Y_train_pred, \"Training\", save_dir=model_dir)\n",
    "plot_cm(Y_val, Y_val_pred, \"Validation\", save_dir=model_dir)\n",
    "plot_cm(Y_test, Y_test_pred, \"Test\", save_dir=model_dir)\n",
    "plot_cm(Y_all, Y_all_pred, \"All\", save_dir=model_dir)\n",
    "\n",
    "plot_roc(\n",
    "    [\n",
    "        (\"Training\", Y_train, Y_train_pred),\n",
    "        (\"Validation\", Y_val, Y_val_pred),\n",
    "        (\"Test\", Y_test, Y_test_pred),\n",
    "        (\"All\", Y_all, Y_all_pred),\n",
    "    ],\n",
    "    save_dir=model_dir,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
