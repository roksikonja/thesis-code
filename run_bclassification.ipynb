{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from experience import load_experience\n",
    "from bclassification.utils_base import (\n",
    "    print_class_weights,\n",
    "    compute_weight_bias,\n",
    "    print_dataset,\n",
    "    plot_metrics,\n",
    "    plot_cm,\n",
    "    plot_roc,\n",
    "    describe_results,\n",
    ")\n",
    "from lib.constants import Constants as Const\n",
    "from lib.data_utils import (\n",
    "    make_dir,\n",
    "    env_pf,\n",
    "    create_results_dir,\n",
    "    save_dict_to_file,\n",
    ")\n",
    "from lib.tf_utils import (\n",
    "    print_variables,\n",
    "    ResidulaFCBlock,\n",
    "    MatthewsCorrelationCoefficient,\n",
    ")\n",
    "from lib.visualizer import Visualizer, pprint\n",
    "\n",
    "Visualizer()\n",
    "\n",
    "experience_dir = make_dir(os.path.join(Const.EXPERIENCE_DIR, \"data-aug\"))\n",
    "results_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"il\"))\n",
    "\n",
    "agent_name = \"agent-mip\"\n",
    "case_name = \"l2rpn_2019_art\"\n",
    "env_dc = True\n",
    "verbose = False\n",
    "\n",
    "case_results_dir = make_dir(os.path.join(results_dir, f\"{case_name}-{env_pf(env_dc)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Parameters\n",
    "\"\"\"\n",
    "\n",
    "random_seed = 1\n",
    "\n",
    "input_mode = \"structured\"\n",
    "label_mode = \"dn\"\n",
    "\n",
    "n_window_targets = 12  # 0 or 12\n",
    "n_window_history = 1\n",
    "downsampling_rate = 0.10\n",
    "n_window_forecasts = 1\n",
    "use_actions = True\n",
    "feature_scaling = True\n",
    "batch_normalization = False\n",
    "\n",
    "n_perturb = 0\n",
    "scale_perturb = 0.02\n",
    "\n",
    "val_frac = 0.10\n",
    "test_frac = 0.10\n",
    "\n",
    "# Model\n",
    "model_type = \"res\"  # \"fc\" or \"res\"\n",
    "dropout_rate = 0.1\n",
    "l1_reg = 0\n",
    "l2_reg = 0\n",
    "n_hidden = 512\n",
    "n_hidden_layers = 2\n",
    "threshold = 0.50\n",
    "pos_scaling = 1\n",
    "\n",
    "# Training\n",
    "learning_rate = 1e-5\n",
    "n_batch = 512\n",
    "n_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb(X, Y, scale, n):\n",
    "    n_gen = 5\n",
    "    n_load = 11\n",
    "    n_line = 20\n",
    "    n_sub = 14\n",
    "    \n",
    "    x_p = []\n",
    "    y_p = []\n",
    "    for _ in range(n):\n",
    "        if input_mode == \"binary\":\n",
    "            # Observation size\n",
    "            s = 3 * n_gen + n_load + 2 * n_line + (4 * n_line + 2 * n_gen + 2 * n_load) + n_sub + 2 * n_line\n",
    "\n",
    "            # Features to perturb\n",
    "            n_first = 3 * n_gen + n_load + 2 * n_line  # Flows and injections\n",
    "\n",
    "            x = X.copy()\n",
    "            for h in range(n_window_history + 1):\n",
    "                noise = np.random.normal(loc=0.0, scale=scale, size=(x.shape[0], n_first))\n",
    "                x[:, h * s : (h * s + n_first)] = x[:, h * s : (h * s + n_first)] + noise\n",
    "\n",
    "            # Forecast\n",
    "            if n_window_forecasts > 0:\n",
    "                n_last = n_window_forecasts * (n_gen + n_load)\n",
    "                noise = np.random.normal(loc=0.0, scale=scale, size=(x.shape[0], n_last))\n",
    "                x[:, -n_last:] = x[:, -n_last:] + noise\n",
    "\n",
    "        elif input_mode == \"structured\":\n",
    "            # Observation size\n",
    "            s = 2 * (n_gen + n_load) + 2 * n_gen + 5 * n_line + n_sub + 2 * n_line\n",
    "\n",
    "            # Features to perturb\n",
    "            n_first = 2 * (n_gen + n_load) + 2 * n_gen + 5 * n_line  # Flows and injections\n",
    "\n",
    "            x = X.copy()\n",
    "            for h in range(n_window_history + 1):\n",
    "                noise = np.random.normal(loc=0.0, scale=scale, size=(x.shape[0], n_first))\n",
    "                x[:, h * s : (h * s + n_first)] = x[:, h * s : (h * s + n_first)] + noise\n",
    "\n",
    "            # Forecasts\n",
    "            if n_window_forecasts > 0:\n",
    "                n_last = n_window_forecasts * (n_gen + n_load)\n",
    "                noise = np.random.normal(loc=0.0, scale=scale, size=(x.shape[0], n_last))\n",
    "                x[:, -n_last:] = x[:, -n_last:] + noise\n",
    "        \n",
    "        x_p.append(x)\n",
    "        y_p.append(Y)\n",
    "    \n",
    "    return np.vstack(x_p), np.hstack(y_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "\"\"\"\n",
    "    Dataset\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "tar_str = f\"w{n_window_targets}\"\n",
    "dr_str = str(int(100 * downsampling_rate))\n",
    "f_str = str(n_window_forecasts)\n",
    "h_str = str(n_window_history)\n",
    "\n",
    "file_name = f\"fc-d{dr_str}-h{h_str}-f{f_str}-{tar_str}-{input_mode}.npz\"\n",
    "file_path = os.path.join(experience_dir, file_name)\n",
    "\n",
    "data = np.load(file_path)\n",
    "X_all = data[\"X_all\"]\n",
    "Y_all = data[\"Y_all\"]\n",
    "mask_targets = data[\"mask_targets\"]\n",
    "X = X_all[mask_targets, :]\n",
    "Y = Y_all[mask_targets]\n",
    "\n",
    "class_weight, initial_bias = compute_weight_bias(Y)\n",
    "initial_bias = 0\n",
    "class_weight[1] = class_weight[1] * pos_scaling \n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X, Y, test_size=val_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_train, Y_train, test_size=test_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "# Augment by adding random noise and upsampling the positive class\n",
    "if scale_perturb > 0 and n_perturb > 0:\n",
    "    indices_pos = np.equal(Y_train, 1)\n",
    "    X_train_perturb, Y_train_perturb = perturb(X_train[indices_pos, :], Y_train[indices_pos], scale=scale_perturb, n=n_perturb)\n",
    "    X_train = np.vstack((X_train, X_train_perturb))    \n",
    "    Y_train = np.hstack((Y_train, Y_train_perturb))\n",
    "    \n",
    "mask_test_neg = np.logical_and(~mask_targets, np.random.binomial(1, val_frac, mask_targets.size).astype(np.bool))\n",
    "X_test_all = np.concatenate((X_test, X_all[mask_test_neg, :]))\n",
    "Y_test_all = np.concatenate((Y_test, Y_all[mask_test_neg]))\n",
    "\n",
    "print_dataset(X_all, Y_all, \"All data\")\n",
    "print_dataset(X, Y, \"Data\")\n",
    "print_dataset(X_train, Y_train, \"Train\")\n",
    "print_dataset(X_val, Y_val, \"Validation\")\n",
    "print_dataset(X_test, Y_test, \"Test\")\n",
    "print_dataset(X_test_all, Y_test_all, \"Test-All\")\n",
    "print_class_weights(class_weight)\n",
    "pprint(\"Initial bias:\", \"{:.4f}\".format(float(initial_bias)))\n",
    "\n",
    "model_dir = create_results_dir(case_results_dir, model_name=model_type)\n",
    "\n",
    "del data\n",
    "del X_all\n",
    "del Y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory:                        ./results\\il\\l2rpn_2019_art-dc\\2020-11-04_15-54-52_res\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Model\n",
    "\"\"\"\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.TruePositives(thresholds=threshold, name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(thresholds=threshold, name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(thresholds=threshold, name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(thresholds=threshold, name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(threshold=threshold, name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(thresholds=threshold, name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(thresholds=threshold, name=\"recall\"),\n",
    "    MatthewsCorrelationCoefficient(threshold=threshold, name=\"mcc\"),\n",
    "    tf.keras.metrics.AUC(name=\"auc\"),\n",
    "]\n",
    "\n",
    "if l1_reg > 0:\n",
    "    kwargs_reg = {\n",
    "        \"kernel_regularizer\": tf.keras.regularizers.L1(l1_reg),\n",
    "        \"bias_regularizer\": tf.keras.regularizers.L1(l1_reg),\n",
    "    }\n",
    "elif l2_reg > 0:\n",
    "    kwargs_reg = {\n",
    "        \"kernel_regularizer\": tf.keras.regularizers.L2(l2=l2_reg),\n",
    "        \"bias_regularizer\": tf.keras.regularizers.L2(l2=l2_reg),\n",
    "    }\n",
    "else:\n",
    "    kwargs_reg = {}\n",
    "\n",
    "input_dim = X.shape[-1]\n",
    "\n",
    "tf.random.set_seed(random_seed)\n",
    "if model_type == \"fc\":\n",
    "    hidden_layers = [\n",
    "        (\n",
    "            tf.keras.layers.Dense(n_hidden, activation=\"relu\", **kwargs_reg),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "        )\n",
    "        for _ in range(n_hidden_layers)\n",
    "    ]\n",
    "    hidden_layers = list(itertools.chain(*hidden_layers))\n",
    "\n",
    "    if batch_normalization:\n",
    "        hidden_layers = hidden_layers + [tf.keras.layers.BatchNormalization()]\n",
    "    \n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                n_hidden, activation=\"relu\", input_shape=(input_dim,), **kwargs_reg\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            *hidden_layers,\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "                **kwargs_reg,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "elif model_type == \"linear\":\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias), input_shape=(input_dim,),\n",
    "                **kwargs_reg,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    hidden_layers = [\n",
    "        (\n",
    "            ResidulaFCBlock(n_hidden, activation=\"relu\", **kwargs_reg),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "        )\n",
    "        for _ in range(n_hidden_layers // 2)\n",
    "    ]\n",
    "    \n",
    "    hidden_layers = list(itertools.chain(*hidden_layers))\n",
    "\n",
    "    if batch_normalization:\n",
    "        hidden_layers = hidden_layers + [tf.keras.layers.BatchNormalization()]\n",
    "    \n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Dense(\n",
    "                n_hidden, activation=\"relu\", input_shape=(input_dim,), **kwargs_reg\n",
    "            ),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            *hidden_layers,\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(\n",
    "                1,\n",
    "                activation=\"sigmoid\",\n",
    "                bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "                **kwargs_reg,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "checkpoint_path = os.path.join(model_dir, \"ckpts\")\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=model.optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "pprint(\"Model directory:\", model_dir)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    pprint(\"Restoring checkpoint from:\", ckpt_manager.latest_checkpoint)\n",
    "    \n",
    "    \n",
    "save_dict_to_file(\n",
    "    {\n",
    "        \"random_seed\": random_seed,\n",
    "        \"input_mode\": input_mode,\n",
    "        \"label_mode\": label_mode,\n",
    "        \"val_frac\": val_frac,\n",
    "        \"downsampling_rate\": downsampling_rate,\n",
    "        \"n_window_targets\": n_window_targets,\n",
    "        \"n_window_history\": n_window_history,\n",
    "        \"use_actions\": use_actions,\n",
    "        \"feature_scaling\": feature_scaling,\n",
    "        \"n_perturb\": n_perturb,\n",
    "        \"scale_perturb\": scale_perturb,\n",
    "        \"model_type\": model_type,\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"l1_reg\": l1_reg,\n",
    "        \"l2_reg\": l2_reg,\n",
    "        \"n_hidden\": n_hidden,\n",
    "        \"n_hidden_layers\": n_hidden_layers,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_batch\": n_batch,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"threshold\": threshold,\n",
    "        \"pos_scaling\": pos_scaling,\n",
    "        \"batch_normalization\": batch_normalization,\n",
    "    },\n",
    "    os.path.join(model_dir, \"params.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - All data:                         X, Y\t       (740873, 412), (740873,)\n",
      "        - Positive labels:              1.03 %\n",
      "        - Negative labels:              98.97 %\n",
      "\n",
      "    - Data:                             X, Y\t        (72947, 412), (72947,)\n",
      "        - Positive labels:              10.45 %\n",
      "        - Negative labels:              89.55 %\n",
      "\n",
      "    - Train:                            X, Y\t        (59086, 412), (59086,)\n",
      "        - Positive labels:              10.33 %\n",
      "        - Negative labels:              89.67 %\n",
      "\n",
      "    - Validation:                       X, Y\t         (7295, 412), (7295,)\n",
      "        - Positive labels:              11.60 %\n",
      "        - Negative labels:              88.40 %\n",
      "\n",
      "    - Test:                             X, Y\t         (6566, 412), (6566,)\n",
      "        - Positive labels:              10.31 %\n",
      "        - Negative labels:              89.69 %\n",
      "\n",
      "    - Test-All:                         X, Y\t        (73063, 412), (73063,)\n",
      "        - Positive labels:              0.93 %\n",
      "        - Negative labels:              99.07 %\n",
      "\n",
      "Class                                   Weight\n",
      "    - 0                                 0.55837\n",
      "    - 1                                 4.78278\n",
      "Initial bias:                           0.0000\n"
     ]
    }
   ],
   "source": [
    "cap.show()\n",
    "\n",
    "with open(os.path.join(model_dir, \"log.txt\"), \"a\") as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.6832 - tp: 3227.0000 - fp: 22595.0000 - tn: 30388.0000 - fn: 2876.0000 - accuracy: 0.5689 - precision: 0.1250 - recall: 0.5288 - mcc: 0.0628 - auc: 0.5739 - val_loss: 0.6255 - val_tp: 424.0000 - val_fp: 1392.0000 - val_tn: 5057.0000 - val_fn: 422.0000 - val_accuracy: 0.7513 - val_precision: 0.2335 - val_recall: 0.5012 - val_mcc: 0.2113 - val_auc: 0.7337\n",
      "Epoch 2/300\n",
      "116/116 [==============================] - 4s 38ms/step - loss: 0.6469 - tp: 3601.0000 - fp: 18280.0000 - tn: 34703.0000 - fn: 2502.0000 - accuracy: 0.6483 - precision: 0.1646 - recall: 0.5900 - mcc: 0.1544 - auc: 0.6680 - val_loss: 0.5887 - val_tp: 469.0000 - val_fp: 1465.0000 - val_tn: 4984.0000 - val_fn: 377.0000 - val_accuracy: 0.7475 - val_precision: 0.2425 - val_recall: 0.5544 - val_mcc: 0.2374 - val_auc: 0.7494\n",
      "Epoch 3/300\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 0.6250 - tp: 3780.0000 - fp: 16684.0000 - tn: 36299.0000 - fn: 2323.0000 - accuracy: 0.6783 - precision: 0.1847 - recall: 0.6194 - mcc: 0.1948 - auc: 0.7070 - val_loss: 0.5978 - val_tp: 544.0000 - val_fp: 1778.0000 - val_tn: 4671.0000 - val_fn: 302.0000 - val_accuracy: 0.7149 - val_precision: 0.2343 - val_recall: 0.6430 - val_mcc: 0.2525 - val_auc: 0.7573\n",
      "Epoch 4/300\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 0.6101 - tp: 3904.0000 - fp: 15848.0000 - tn: 37135.0000 - fn: 2199.0000 - accuracy: 0.6946 - precision: 0.1977 - recall: 0.6397 - mcc: 0.2197 - auc: 0.7292 - val_loss: 0.6024 - val_tp: 569.0000 - val_fp: 1886.0000 - val_tn: 4563.0000 - val_fn: 277.0000 - val_accuracy: 0.7035 - val_precision: 0.2318 - val_recall: 0.6726 - val_mcc: 0.2576 - val_auc: 0.76280 - fp: 6300.0000 - tn: 14827.0000 - fn: 878.0000 - accuracy: 0.6952 - precisio\n",
      "Epoch 5/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.6019 - tp: 3987.0000 - fp: 15755.0000 - tn: 37228.0000 - fn: 2116.0000 - accuracy: 0.6975 - precision: 0.2020 - recall: 0.6533 - mcc: 0.2296 - auc: 0.7402 - val_loss: 0.5735 - val_tp: 540.0000 - val_fp: 1734.0000 - val_tn: 4715.0000 - val_fn: 306.0000 - val_accuracy: 0.7204 - val_precision: 0.2375 - val_recall: 0.6383 - val_mcc: 0.2554 - val_auc: 0.7667\n",
      "Epoch 6/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.5957 - tp: 4012.0000 - fp: 15505.0000 - tn: 37478.0000 - fn: 2091.0000 - accuracy: 0.7022 - precision: 0.2056 - recall: 0.6574 - mcc: 0.2360 - auc: 0.7475 - val_loss: 0.5654 - val_tp: 548.0000 - val_fp: 1703.0000 - val_tn: 4746.0000 - val_fn: 298.0000 - val_accuracy: 0.7257 - val_precision: 0.2434 - val_recall: 0.6478 - val_mcc: 0.2660 - val_auc: 0.7701\n",
      "Epoch 7/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.5896 - tp: 4074.0000 - fp: 15631.0000 - tn: 37352.0000 - fn: 2029.0000 - accuracy: 0.7011 - precision: 0.2067 - recall: 0.6675 - mcc: 0.2405 - auc: 0.7548 - val_loss: 0.5772 - val_tp: 574.0000 - val_fp: 1806.0000 - val_tn: 4643.0000 - val_fn: 272.0000 - val_accuracy: 0.7151 - val_precision: 0.2412 - val_recall: 0.6785 - val_mcc: 0.2721 - val_auc: 0.7734\n",
      "Epoch 8/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.5862 - tp: 4108.0000 - fp: 15360.0000 - tn: 37623.0000 - fn: 1995.0000 - accuracy: 0.7063 - precision: 0.2110 - recall: 0.6731 - mcc: 0.2481 - auc: 0.7587 - val_loss: 0.5437 - val_tp: 551.0000 - val_fp: 1626.0000 - val_tn: 4823.0000 - val_fn: 295.0000 - val_accuracy: 0.7367 - val_precision: 0.2531 - val_recall: 0.6513 - val_mcc: 0.2793 - val_auc: 0.7760\n",
      "Epoch 9/300\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 0.5827 - tp: 4145.0000 - fp: 15465.0000 - tn: 37518.0000 - fn: 1958.0000 - accuracy: 0.7051 - precision: 0.2114 - recall: 0.6792 - mcc: 0.2503 - auc: 0.7617 - val_loss: 0.5340 - val_tp: 548.0000 - val_fp: 1587.0000 - val_tn: 4862.0000 - val_fn: 298.0000 - val_accuracy: 0.7416 - val_precision: 0.2567 - val_recall: 0.6478 - val_mcc: 0.2827 - val_auc: 0.7787\n",
      "Epoch 10/300\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 0.5799 - tp: 4165.0000 - fp: 15292.0000 - tn: 37691.0000 - fn: 1938.0000 - accuracy: 0.7084 - precision: 0.2141 - recall: 0.6825 - mcc: 0.2550 - auc: 0.7643 - val_loss: 0.5662 - val_tp: 584.0000 - val_fp: 1805.0000 - val_tn: 4644.0000 - val_fn: 262.0000 - val_accuracy: 0.7167 - val_precision: 0.2445 - val_recall: 0.6903 - val_mcc: 0.2800 - val_auc: 0.7811\n",
      "Epoch 11/300\n",
      "116/116 [==============================] - 5s 46ms/step - loss: 0.5755 - tp: 4241.0000 - fp: 15352.0000 - tn: 37631.0000 - fn: 1862.0000 - accuracy: 0.7087 - precision: 0.2165 - recall: 0.6949 - mcc: 0.2619 - auc: 0.7684 - val_loss: 0.5612 - val_tp: 592.0000 - val_fp: 1792.0000 - val_tn: 4657.0000 - val_fn: 254.0000 - val_accuracy: 0.7195 - val_precision: 0.2483 - val_recall: 0.6998 - val_mcc: 0.2880 - val_auc: 0.7837\n",
      "Epoch 12/300\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.5724 - tp: 4245.0000 - fp: 15338.0000 - tn: 37645.0000 - fn: 1858.0000 - accuracy: 0.7090 - precision: 0.2168 - recall: 0.6956 - mcc: 0.2625 - auc: 0.7712 - val_loss: 0.5684 - val_tp: 607.0000 - val_fp: 1846.0000 - val_tn: 4603.0000 - val_fn: 239.0000 - val_accuracy: 0.7142 - val_precision: 0.2475 - val_recall: 0.7175 - val_mcc: 0.2923 - val_auc: 0.7859\n",
      "Epoch 13/300\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 0.5686 - tp: 4268.0000 - fp: 15191.0000 - tn: 37792.0000 - fn: 1835.0000 - accuracy: 0.7118 - precision: 0.2193 - recall: 0.6993 - mcc: 0.2672 - auc: 0.7750 - val_loss: 0.5740 - val_tp: 613.0000 - val_fp: 1896.0000 - val_tn: 4553.0000 - val_fn: 233.0000 - val_accuracy: 0.7082 - val_precision: 0.2443 - val_recall: 0.7246 - val_mcc: 0.2902 - val_auc: 0.7881\n",
      "Epoch 14/300\n",
      "116/116 [==============================] - 5s 47ms/step - loss: 0.5665 - tp: 4312.0000 - fp: 15533.0000 - tn: 37450.0000 - fn: 1791.0000 - accuracy: 0.7068 - precision: 0.2173 - recall: 0.7065 - mcc: 0.2664 - auc: 0.7764 - val_loss: 0.5360 - val_tp: 588.0000 - val_fp: 1699.0000 - val_tn: 4750.0000 - val_fn: 258.0000 - val_accuracy: 0.7317 - val_precision: 0.2571 - val_recall: 0.6950 - val_mcc: 0.2979 - val_auc: 0.7900\n",
      "Epoch 15/300\n",
      "116/116 [==============================] - 7s 57ms/step - loss: 0.5622 - tp: 4334.0000 - fp: 15067.0000 - tn: 37916.0000 - fn: 1769.0000 - accuracy: 0.7151 - precision: 0.2234 - recall: 0.7101 - mcc: 0.2759 - auc: 0.7803 - val_loss: 0.5500 - val_tp: 605.0000 - val_fp: 1796.0000 - val_tn: 4653.0000 - val_fn: 241.0000 - val_accuracy: 0.7208 - val_precision: 0.2520 - val_recall: 0.7151 - val_mcc: 0.2975 - val_auc: 0.7919\n",
      "Epoch 16/300\n",
      "116/116 [==============================] - 7s 57ms/step - loss: 0.5616 - tp: 4340.0000 - fp: 15309.0000 - tn: 37674.0000 - fn: 1763.0000 - accuracy: 0.7111 - precision: 0.2209 - recall: 0.7111 - mcc: 0.2727 - auc: 0.7806 - val_loss: 0.5495 - val_tp: 609.0000 - val_fp: 1804.0000 - val_tn: 4645.0000 - val_fn: 237.0000 - val_accuracy: 0.7202 - val_precision: 0.2524 - val_recall: 0.7199 - val_mcc: 0.2995 - val_auc: 0.7939\n",
      "Epoch 17/300\n",
      "116/116 [==============================] - 6s 54ms/step - loss: 0.5578 - tp: 4384.0000 - fp: 15352.0000 - tn: 37631.0000 - fn: 1719.0000 - accuracy: 0.7111 - precision: 0.2221 - recall: 0.7183 - mcc: 0.2765 - auc: 0.7837 - val_loss: 0.5150 - val_tp: 579.0000 - val_fp: 1641.0000 - val_tn: 4808.0000 - val_fn: 267.0000 - val_accuracy: 0.7385 - val_precision: 0.2608 - val_recall: 0.6844 - val_mcc: 0.2992 - val_auc: 0.7955\n",
      "Epoch 18/300\n",
      "116/116 [==============================] - 5s 45ms/step - loss: 0.5554 - tp: 4392.0000 - fp: 15199.0000 - tn: 37784.0000 - fn: 1711.0000 - accuracy: 0.7138 - precision: 0.2242 - recall: 0.7196 - mcc: 0.2798 - auc: 0.7858 - val_loss: 0.5597 - val_tp: 636.0000 - val_fp: 1891.0000 - val_tn: 4558.0000 - val_fn: 210.0000 - val_accuracy: 0.7120 - val_precision: 0.2517 - val_recall: 0.7518 - val_mcc: 0.3086 - val_auc: 0.7977\n",
      "Epoch 19/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.5547 - tp: 4430.0000 - fp: 15336.0000 - tn: 37647.0000 - fn: 1673.0000 - accuracy: 0.7121 - precision: 0.2241 - recall: 0.7259 - mcc: 0.2815 - auc: 0.7860 - val_loss: 0.5223 - val_tp: 602.0000 - val_fp: 1708.0000 - val_tn: 4741.0000 - val_fn: 244.0000 - val_accuracy: 0.7324 - val_precision: 0.2606 - val_recall: 0.7116 - val_mcc: 0.3075 - val_auc: 0.7993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/300\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 0.5490 - tp: 4444.0000 - fp: 15139.0000 - tn: 37844.0000 - fn: 1659.0000 - accuracy: 0.7157 - precision: 0.2269 - recall: 0.7282 - mcc: 0.2860 - auc: 0.7911 - val_loss: 0.5372 - val_tp: 626.0000 - val_fp: 1804.0000 - val_tn: 4645.0000 - val_fn: 220.0000 - val_accuracy: 0.7225 - val_precision: 0.2576 - val_recall: 0.7400 - val_mcc: 0.3126 - val_auc: 0.8016\n",
      "Epoch 21/300\n",
      "116/116 [==============================] - 5s 39ms/step - loss: 0.5483 - tp: 4485.0000 - fp: 15380.0000 - tn: 37603.0000 - fn: 1618.0000 - accuracy: 0.7123 - precision: 0.2258 - recall: 0.7349 - mcc: 0.2864 - auc: 0.7915 - val_loss: 0.5221 - val_tp: 613.0000 - val_fp: 1727.0000 - val_tn: 4722.0000 - val_fn: 233.0000 - val_accuracy: 0.7313 - val_precision: 0.2620 - val_recall: 0.7246 - val_mcc: 0.3133 - val_auc: 0.8030\n",
      "Epoch 22/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.5451 - tp: 4431.0000 - fp: 14983.0000 - tn: 38000.0000 - fn: 1672.0000 - accuracy: 0.7181 - precision: 0.2282 - recall: 0.7260 - mcc: 0.2872 - auc: 0.7939 - val_loss: 0.5639 - val_tp: 656.0000 - val_fp: 1975.0000 - val_tn: 4474.0000 - val_fn: 190.0000 - val_accuracy: 0.7032 - val_precision: 0.2493 - val_recall: 0.7754 - val_mcc: 0.3128 - val_auc: 0.8053\n",
      "Epoch 23/300\n",
      "116/116 [==============================] - 5s 45ms/step - loss: 0.5425 - tp: 4536.0000 - fp: 15505.0000 - tn: 37478.0000 - fn: 1567.0000 - accuracy: 0.7111 - precision: 0.2263 - recall: 0.7432 - mcc: 0.2897 - auc: 0.7963 - val_loss: 0.5160 - val_tp: 616.0000 - val_fp: 1728.0000 - val_tn: 4721.0000 - val_fn: 230.0000 - val_accuracy: 0.7316 - val_precision: 0.2628 - val_recall: 0.7281 - val_mcc: 0.3155 - val_auc: 0.8070\n",
      "Epoch 24/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.5405 - tp: 4524.0000 - fp: 15239.0000 - tn: 37744.0000 - fn: 1579.0000 - accuracy: 0.7154 - precision: 0.2289 - recall: 0.7413 - mcc: 0.2926 - auc: 0.7978 - val_loss: 0.5343 - val_tp: 642.0000 - val_fp: 1836.0000 - val_tn: 4613.0000 - val_fn: 204.0000 - val_accuracy: 0.7204 - val_precision: 0.2591 - val_recall: 0.7589 - val_mcc: 0.3206 - val_auc: 0.8091\n",
      "Epoch 25/300\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 0.5358 - tp: 4571.0000 - fp: 15181.0000 - tn: 37802.0000 - fn: 1532.0000 - accuracy: 0.7171 - precision: 0.2314 - recall: 0.7490 - mcc: 0.2983 - auc: 0.8020 - val_loss: 0.5354 - val_tp: 648.0000 - val_fp: 1866.0000 - val_tn: 4583.0000 - val_fn: 198.0000 - val_accuracy: 0.7171 - val_precision: 0.2578 - val_recall: 0.7660 - val_mcc: 0.3211 - val_auc: 0.8106\n",
      "Epoch 26/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.5366 - tp: 4605.0000 - fp: 15297.0000 - tn: 37686.0000 - fn: 1498.0000 - accuracy: 0.7158 - precision: 0.2314 - recall: 0.7545 - mcc: 0.3000 - auc: 0.8009 - val_loss: 0.5216 - val_tp: 638.0000 - val_fp: 1802.0000 - val_tn: 4647.0000 - val_fn: 208.0000 - val_accuracy: 0.7245 - val_precision: 0.2615 - val_recall: 0.7541 - val_mcc: 0.3222 - val_auc: 0.8123\n",
      "Epoch 27/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.5343 - tp: 4564.0000 - fp: 15232.0000 - tn: 37751.0000 - fn: 1539.0000 - accuracy: 0.7162 - precision: 0.2306 - recall: 0.7478 - mcc: 0.2968 - auc: 0.8027 - val_loss: 0.5435 - val_tp: 661.0000 - val_fp: 1954.0000 - val_tn: 4495.0000 - val_fn: 185.0000 - val_accuracy: 0.7068 - val_precision: 0.2528 - val_recall: 0.7813 - val_mcc: 0.3194 - val_auc: 0.8144\n",
      "Epoch 28/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.5309 - tp: 4646.0000 - fp: 15459.0000 - tn: 37524.0000 - fn: 1457.0000 - accuracy: 0.7137 - precision: 0.2311 - recall: 0.7613 - mcc: 0.3016 - auc: 0.8058 - val_loss: 0.5120 - val_tp: 638.0000 - val_fp: 1772.0000 - val_tn: 4677.0000 - val_fn: 208.0000 - val_accuracy: 0.7286 - val_precision: 0.2647 - val_recall: 0.7541 - val_mcc: 0.3263 - val_auc: 0.8160\n",
      "Epoch 29/300\n",
      "116/116 [==============================] - 5s 45ms/step - loss: 0.5273 - tp: 4623.0000 - fp: 15071.0000 - tn: 37912.0000 - fn: 1480.0000 - accuracy: 0.7199 - precision: 0.2347 - recall: 0.7575 - mcc: 0.3054 - auc: 0.8086 - val_loss: 0.5278 - val_tp: 659.0000 - val_fp: 1866.0000 - val_tn: 4583.0000 - val_fn: 187.0000 - val_accuracy: 0.7186 - val_precision: 0.2610 - val_recall: 0.7790 - val_mcc: 0.3295 - val_auc: 0.8187\n",
      "Epoch 30/300\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.5255 - tp: 4622.0000 - fp: 15160.0000 - tn: 37823.0000 - fn: 1481.0000 - accuracy: 0.7184 - precision: 0.2336 - recall: 0.7573 - mcc: 0.3039 - auc: 0.8100 - val_loss: 0.5389 - val_tp: 670.0000 - val_fp: 1932.0000 - val_tn: 4517.0000 - val_fn: 176.0000 - val_accuracy: 0.7110 - val_precision: 0.2575 - val_recall: 0.7920 - val_mcc: 0.3291 - val_auc: 0.8196\n",
      "Epoch 31/300\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.5240 - tp: 4667.0000 - fp: 15289.0000 - tn: 37694.0000 - fn: 1436.0000 - accuracy: 0.7169 - precision: 0.2339 - recall: 0.7647 - mcc: 0.3064 - auc: 0.8110 - val_loss: 0.5134 - val_tp: 661.0000 - val_fp: 1809.0000 - val_tn: 4640.0000 - val_fn: 185.0000 - val_accuracy: 0.7267 - val_precision: 0.2676 - val_recall: 0.7813 - val_mcc: 0.3389 - val_auc: 0.8216\n",
      "Epoch 32/300\n",
      "116/116 [==============================] - 5s 47ms/step - loss: 0.5204 - tp: 4701.0000 - fp: 15219.0000 - tn: 37764.0000 - fn: 1402.0000 - accuracy: 0.7187 - precision: 0.2360 - recall: 0.7703 - mcc: 0.3110 - auc: 0.8143 - val_loss: 0.5218 - val_tp: 671.0000 - val_fp: 1857.0000 - val_tn: 4592.0000 - val_fn: 175.0000 - val_accuracy: 0.7215 - val_precision: 0.2654 - val_recall: 0.7931 - val_mcc: 0.3399 - val_auc: 0.8236\n",
      "Epoch 33/300\n",
      "116/116 [==============================] - 5s 46ms/step - loss: 0.5196 - tp: 4692.0000 - fp: 15047.0000 - tn: 37936.0000 - fn: 1411.0000 - accuracy: 0.7215 - precision: 0.2377 - recall: 0.7688 - mcc: 0.3128 - auc: 0.8150 - val_loss: 0.5189 - val_tp: 674.0000 - val_fp: 1836.0000 - val_tn: 4613.0000 - val_fn: 172.0000 - val_accuracy: 0.7247 - val_precision: 0.2685 - val_recall: 0.7967 - val_mcc: 0.3451 - val_auc: 0.8255\n",
      "Epoch 34/300\n",
      "116/116 [==============================] - 5s 46ms/step - loss: 0.5171 - tp: 4709.0000 - fp: 15092.0000 - tn: 37891.0000 - fn: 1394.0000 - accuracy: 0.7210 - precision: 0.2378 - recall: 0.7716 - mcc: 0.3138 - auc: 0.8170 - val_loss: 0.5373 - val_tp: 689.0000 - val_fp: 1939.0000 - val_tn: 4510.0000 - val_fn: 157.0000 - val_accuracy: 0.7127 - val_precision: 0.2622 - val_recall: 0.8144 - val_mcc: 0.3427 - val_auc: 0.8269\n",
      "Epoch 35/300\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.5126 - tp: 4753.0000 - fp: 15075.0000 - tn: 37908.0000 - fn: 1350.0000 - accuracy: 0.7220 - precision: 0.2397 - recall: 0.7788 - mcc: 0.3186 - auc: 0.8208 - val_loss: 0.4701 - val_tp: 626.0000 - val_fp: 1587.0000 - val_tn: 4862.0000 - val_fn: 220.0000 - val_accuracy: 0.7523 - val_precision: 0.2829 - val_recall: 0.7400 - val_mcc: 0.3440 - val_auc: 0.8282\n",
      "Epoch 36/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.5127 - tp: 4774.0000 - fp: 15252.0000 - tn: 37731.0000 - fn: 1329.0000 - accuracy: 0.7194 - precision: 0.2384 - recall: 0.7822 - mcc: 0.3179 - auc: 0.8201 - val_loss: 0.5173 - val_tp: 683.0000 - val_fp: 1842.0000 - val_tn: 4607.0000 - val_fn: 163.0000 - val_accuracy: 0.7252 - val_precision: 0.2705 - val_recall: 0.8073 - val_mcc: 0.3511 - val_auc: 0.8308\n",
      "Epoch 37/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.5104 - tp: 4734.0000 - fp: 14762.0000 - tn: 38221.0000 - fn: 1369.0000 - accuracy: 0.7270 - precision: 0.2428 - recall: 0.7757 - mcc: 0.3217 - auc: 0.8222 - val_loss: 0.5263 - val_tp: 690.0000 - val_fp: 1901.0000 - val_tn: 4548.0000 - val_fn: 156.0000 - val_accuracy: 0.7180 - val_precision: 0.2663 - val_recall: 0.8156 - val_mcc: 0.3485 - val_auc: 0.8325\n",
      "Epoch 38/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.5087 - tp: 4763.0000 - fp: 14952.0000 - tn: 38031.0000 - fn: 1340.0000 - accuracy: 0.7243 - precision: 0.2416 - recall: 0.7804 - mcc: 0.3216 - auc: 0.8236 - val_loss: 0.5409 - val_tp: 704.0000 - val_fp: 1992.0000 - val_tn: 4457.0000 - val_fn: 142.0000 - val_accuracy: 0.7075 - val_precision: 0.2611 - val_recall: 0.8322 - val_mcc: 0.3471 - val_auc: 0.8347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.5049 - tp: 4794.0000 - fp: 15002.0000 - tn: 37981.0000 - fn: 1309.0000 - accuracy: 0.7239 - precision: 0.2422 - recall: 0.7855 - mcc: 0.3239 - auc: 0.8270 - val_loss: 0.4799 - val_tp: 657.0000 - val_fp: 1654.0000 - val_tn: 4795.0000 - val_fn: 189.0000 - val_accuracy: 0.7474 - val_precision: 0.2843 - val_recall: 0.7766 - val_mcc: 0.3580 - val_auc: 0.8356\n",
      "Epoch 40/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.5029 - tp: 4811.0000 - fp: 14680.0000 - tn: 38303.0000 - fn: 1292.0000 - accuracy: 0.7297 - precision: 0.2468 - recall: 0.7883 - mcc: 0.3309 - auc: 0.8287 - val_loss: 0.5257 - val_tp: 703.0000 - val_fp: 1889.0000 - val_tn: 4560.0000 - val_fn: 143.0000 - val_accuracy: 0.7215 - val_precision: 0.2712 - val_recall: 0.8310 - val_mcc: 0.3600 - val_auc: 0.8378\n",
      "Epoch 41/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.5009 - tp: 4794.0000 - fp: 14672.0000 - tn: 38311.0000 - fn: 1309.0000 - accuracy: 0.7295 - precision: 0.2463 - recall: 0.7855 - mcc: 0.3293 - auc: 0.8300 - val_loss: 0.5334 - val_tp: 707.0000 - val_fp: 1940.0000 - val_tn: 4509.0000 - val_fn: 139.0000 - val_accuracy: 0.7150 - val_precision: 0.2671 - val_recall: 0.8357 - val_mcc: 0.3562 - val_auc: 0.8391\n",
      "Epoch 42/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.4983 - tp: 4831.0000 - fp: 14647.0000 - tn: 38336.0000 - fn: 1272.0000 - accuracy: 0.7306 - precision: 0.2480 - recall: 0.7916 - mcc: 0.3335 - auc: 0.8321 - val_loss: 0.5032 - val_tp: 689.0000 - val_fp: 1784.0000 - val_tn: 4665.0000 - val_fn: 157.0000 - val_accuracy: 0.7339 - val_precision: 0.2786 - val_recall: 0.8144 - val_mcc: 0.3638 - val_auc: 0.8404\n",
      "Epoch 43/300\n",
      "116/116 [==============================] - 5s 46ms/step - loss: 0.4978 - tp: 4806.0000 - fp: 14591.0000 - tn: 38392.0000 - fn: 1297.0000 - accuracy: 0.7311 - precision: 0.2478 - recall: 0.7875 - mcc: 0.3319 - auc: 0.8324 - val_loss: 0.5000 - val_tp: 693.0000 - val_fp: 1773.0000 - val_tn: 4676.0000 - val_fn: 153.0000 - val_accuracy: 0.7360 - val_precision: 0.2810 - val_recall: 0.8191 - val_mcc: 0.3684 - val_auc: 0.8420\n",
      "Epoch 44/300\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.4947 - tp: 4833.0000 - fp: 14655.0000 - tn: 38328.0000 - fn: 1270.0000 - accuracy: 0.7305 - precision: 0.2480 - recall: 0.7919 - mcc: 0.3336 - auc: 0.8345 - val_loss: 0.4983 - val_tp: 692.0000 - val_fp: 1776.0000 - val_tn: 4673.0000 - val_fn: 154.0000 - val_accuracy: 0.7354 - val_precision: 0.2804 - val_recall: 0.8180 - val_mcc: 0.3672 - val_auc: 0.8440\n",
      "Epoch 45/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.4940 - tp: 4809.0000 - fp: 14413.0000 - tn: 38570.0000 - fn: 1294.0000 - accuracy: 0.7342 - precision: 0.2502 - recall: 0.7880 - mcc: 0.3352 - auc: 0.8354 - val_loss: 0.4990 - val_tp: 694.0000 - val_fp: 1772.0000 - val_tn: 4677.0000 - val_fn: 152.0000 - val_accuracy: 0.7363 - val_precision: 0.2814 - val_recall: 0.8203 - val_mcc: 0.3693 - val_auc: 0.8453\n",
      "Epoch 46/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.4923 - tp: 4834.0000 - fp: 14544.0000 - tn: 38439.0000 - fn: 1269.0000 - accuracy: 0.7324 - precision: 0.2495 - recall: 0.7921 - mcc: 0.3355 - auc: 0.8367 - val_loss: 0.5136 - val_tp: 706.0000 - val_fp: 1849.0000 - val_tn: 4600.0000 - val_fn: 140.0000 - val_accuracy: 0.7273 - val_precision: 0.2763 - val_recall: 0.8345 - val_mcc: 0.3677 - val_auc: 0.8470\n",
      "Epoch 47/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.4885 - tp: 4861.0000 - fp: 14353.0000 - tn: 38630.0000 - fn: 1242.0000 - accuracy: 0.7361 - precision: 0.2530 - recall: 0.7965 - mcc: 0.3415 - auc: 0.8397 - val_loss: 0.5325 - val_tp: 718.0000 - val_fp: 1928.0000 - val_tn: 4521.0000 - val_fn: 128.0000 - val_accuracy: 0.7182 - val_precision: 0.2714 - val_recall: 0.8487 - val_mcc: 0.3661 - val_auc: 0.8486\n",
      "Epoch 48/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.4880 - tp: 4872.0000 - fp: 14427.0000 - tn: 38556.0000 - fn: 1231.0000 - accuracy: 0.7350 - precision: 0.2524 - recall: 0.7983 - mcc: 0.3413 - auc: 0.8400 - val_loss: 0.5099 - val_tp: 706.0000 - val_fp: 1833.0000 - val_tn: 4616.0000 - val_fn: 140.0000 - val_accuracy: 0.7295 - val_precision: 0.2781 - val_recall: 0.8345 - val_mcc: 0.3699 - val_auc: 0.8498\n",
      "Epoch 49/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4858 - tp: 4860.0000 - fp: 14239.0000 - tn: 38744.0000 - fn: 1243.0000 - accuracy: 0.7380 - precision: 0.2545 - recall: 0.7963 - mcc: 0.3433 - auc: 0.8421 - val_loss: 0.4931 - val_tp: 695.0000 - val_fp: 1750.0000 - val_tn: 4699.0000 - val_fn: 151.0000 - val_accuracy: 0.7394 - val_precision: 0.2843 - val_recall: 0.8215 - val_mcc: 0.3732 - val_auc: 0.8510\n",
      "Epoch 50/300\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 0.4851 - tp: 4885.0000 - fp: 14258.0000 - tn: 38725.0000 - fn: 1218.0000 - accuracy: 0.7381 - precision: 0.2552 - recall: 0.8004 - mcc: 0.3455 - auc: 0.8424 - val_loss: 0.4773 - val_tp: 684.0000 - val_fp: 1668.0000 - val_tn: 4781.0000 - val_fn: 162.0000 - val_accuracy: 0.7491 - val_precision: 0.2908 - val_recall: 0.8085 - val_mcc: 0.3767 - val_auc: 0.8525\n",
      "Epoch 51/300\n",
      "116/116 [==============================] - 6s 56ms/step - loss: 0.4809 - tp: 4889.0000 - fp: 14043.0000 - tn: 38940.0000 - fn: 1214.0000 - accuracy: 0.7418 - precision: 0.2582 - recall: 0.8011 - mcc: 0.3496 - auc: 0.8456 - val_loss: 0.4781 - val_tp: 689.0000 - val_fp: 1684.0000 - val_tn: 4765.0000 - val_fn: 157.0000 - val_accuracy: 0.7476 - val_precision: 0.2903 - val_recall: 0.8144 - val_mcc: 0.3782 - val_auc: 0.8535\n",
      "Epoch 52/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4807 - tp: 4898.0000 - fp: 14122.0000 - tn: 38861.0000 - fn: 1205.0000 - accuracy: 0.7406 - precision: 0.2575 - recall: 0.8026 - mcc: 0.3492 - auc: 0.8458 - val_loss: 0.4728 - val_tp: 689.0000 - val_fp: 1661.0000 - val_tn: 4788.0000 - val_fn: 157.0000 - val_accuracy: 0.7508 - val_precision: 0.2932 - val_recall: 0.8144 - val_mcc: 0.3816 - val_auc: 0.8548\n",
      "Epoch 53/300\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 0.4784 - tp: 4908.0000 - fp: 14027.0000 - tn: 38956.0000 - fn: 1195.0000 - accuracy: 0.7424 - precision: 0.2592 - recall: 0.8042 - mcc: 0.3518 - auc: 0.8474 - val_loss: 0.4943 - val_tp: 700.0000 - val_fp: 1756.0000 - val_tn: 4693.0000 - val_fn: 146.0000 - val_accuracy: 0.7393 - val_precision: 0.2850 - val_recall: 0.8274 - val_mcc: 0.3761 - val_auc: 0.8562\n",
      "Epoch 54/300\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.4775 - tp: 4928.0000 - fp: 13933.0000 - tn: 39050.0000 - fn: 1175.0000 - accuracy: 0.7443 - precision: 0.2613 - recall: 0.8075 - mcc: 0.3555 - auc: 0.8484 - val_loss: 0.4758 - val_tp: 689.0000 - val_fp: 1670.0000 - val_tn: 4779.0000 - val_fn: 157.0000 - val_accuracy: 0.7496 - val_precision: 0.2921 - val_recall: 0.8144 - val_mcc: 0.3802 - val_auc: 0.8570\n",
      "Epoch 55/300\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 0.4768 - tp: 4890.0000 - fp: 13870.0000 - tn: 39113.0000 - fn: 1213.0000 - accuracy: 0.7447 - precision: 0.2607 - recall: 0.8012 - mcc: 0.3527 - auc: 0.8488 - val_loss: 0.4914 - val_tp: 703.0000 - val_fp: 1763.0000 - val_tn: 4686.0000 - val_fn: 143.0000 - val_accuracy: 0.7387 - val_precision: 0.2851 - val_recall: 0.8310 - val_mcc: 0.3774 - val_auc: 0.8587\n",
      "Epoch 56/300\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 0.4742 - tp: 4945.0000 - fp: 14044.0000 - tn: 38939.0000 - fn: 1158.0000 - accuracy: 0.7427 - precision: 0.2604 - recall: 0.8103 - mcc: 0.3553 - auc: 0.8506 - val_loss: 0.4534 - val_tp: 678.0000 - val_fp: 1561.0000 - val_tn: 4888.0000 - val_fn: 168.0000 - val_accuracy: 0.7630 - val_precision: 0.3028 - val_recall: 0.8014 - val_mcc: 0.3883 - val_auc: 0.8592\n",
      "Epoch 57/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.4720 - tp: 4903.0000 - fp: 13771.0000 - tn: 39212.0000 - fn: 1200.0000 - accuracy: 0.7466 - precision: 0.2626 - recall: 0.8034 - mcc: 0.3557 - auc: 0.8520 - val_loss: 0.4852 - val_tp: 702.0000 - val_fp: 1724.0000 - val_tn: 4725.0000 - val_fn: 144.0000 - val_accuracy: 0.7439 - val_precision: 0.2894 - val_recall: 0.8298 - val_mcc: 0.3823 - val_auc: 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "116/116 [==============================] - 5s 46ms/step - loss: 0.4686 - tp: 4951.0000 - fp: 13778.0000 - tn: 39205.0000 - fn: 1152.0000 - accuracy: 0.7473 - precision: 0.2643 - recall: 0.8112 - mcc: 0.3605 - auc: 0.8545 - val_loss: 0.4801 - val_tp: 701.0000 - val_fp: 1706.0000 - val_tn: 4743.0000 - val_fn: 145.0000 - val_accuracy: 0.7463 - val_precision: 0.2912 - val_recall: 0.8286 - val_mcc: 0.3841 - val_auc: 0.8618\n",
      "Epoch 59/300\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.4711 - tp: 4905.0000 - fp: 13839.0000 - tn: 39144.0000 - fn: 1198.0000 - accuracy: 0.7455 - precision: 0.2617 - recall: 0.8037 - mcc: 0.3548 - auc: 0.8528 - val_loss: 0.4850 - val_tp: 706.0000 - val_fp: 1725.0000 - val_tn: 4724.0000 - val_fn: 140.0000 - val_accuracy: 0.7443 - val_precision: 0.2904 - val_recall: 0.8345 - val_mcc: 0.3852 - val_auc: 0.8628\n",
      "Epoch 60/300\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.4669 - tp: 4929.0000 - fp: 13506.0000 - tn: 39477.0000 - fn: 1174.0000 - accuracy: 0.7515 - precision: 0.2674 - recall: 0.8076 - mcc: 0.3631 - auc: 0.8560 - val_loss: 0.4984 - val_tp: 717.0000 - val_fp: 1782.0000 - val_tn: 4667.0000 - val_fn: 129.0000 - val_accuracy: 0.7380 - val_precision: 0.2869 - val_recall: 0.8475 - val_mcc: 0.3854 - val_auc: 0.8639\n",
      "Epoch 61/300\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.4668 - tp: 4937.0000 - fp: 13719.0000 - tn: 39264.0000 - fn: 1166.0000 - accuracy: 0.7481 - precision: 0.2646 - recall: 0.8089 - mcc: 0.3601 - auc: 0.8559 - val_loss: 0.4657 - val_tp: 695.0000 - val_fp: 1635.0000 - val_tn: 4814.0000 - val_fn: 151.0000 - val_accuracy: 0.7552 - val_precision: 0.2983 - val_recall: 0.8215 - val_mcc: 0.3901 - val_auc: 0.8641\n",
      "Epoch 62/300\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 0.4654 - tp: 4951.0000 - fp: 13550.0000 - tn: 39433.0000 - fn: 1152.0000 - accuracy: 0.7512 - precision: 0.2676 - recall: 0.8112 - mcc: 0.3645 - auc: 0.8565 - val_loss: 0.4768 - val_tp: 706.0000 - val_fp: 1692.0000 - val_tn: 4757.0000 - val_fn: 140.0000 - val_accuracy: 0.7489 - val_precision: 0.2944 - val_recall: 0.8345 - val_mcc: 0.3900 - val_auc: 0.8654\n",
      "Epoch 63/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4628 - tp: 4949.0000 - fp: 13500.0000 - tn: 39483.0000 - fn: 1154.0000 - accuracy: 0.7520 - precision: 0.2683 - recall: 0.8109 - mcc: 0.3652 - auc: 0.8589 - val_loss: 0.4496 - val_tp: 689.0000 - val_fp: 1550.0000 - val_tn: 4899.0000 - val_fn: 157.0000 - val_accuracy: 0.7660 - val_precision: 0.3077 - val_recall: 0.8144 - val_mcc: 0.3985 - val_auc: 0.8661\n",
      "Epoch 64/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4611 - tp: 4959.0000 - fp: 13561.0000 - tn: 39422.0000 - fn: 1144.0000 - accuracy: 0.7511 - precision: 0.2678 - recall: 0.8126 - mcc: 0.3652 - auc: 0.8596 - val_loss: 0.4395 - val_tp: 685.0000 - val_fp: 1518.0000 - val_tn: 4931.0000 - val_fn: 161.0000 - val_accuracy: 0.7698 - val_precision: 0.3109 - val_recall: 0.8097 - val_mcc: 0.4005 - val_auc: 0.8665\n",
      "Epoch 65/300\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 0.4604 - tp: 4962.0000 - fp: 13451.0000 - tn: 39532.0000 - fn: 1141.0000 - accuracy: 0.7530 - precision: 0.2695 - recall: 0.8130 - mcc: 0.3674 - auc: 0.8602 - val_loss: 0.4514 - val_tp: 697.0000 - val_fp: 1596.0000 - val_tn: 4853.0000 - val_fn: 149.0000 - val_accuracy: 0.7608 - val_precision: 0.3040 - val_recall: 0.8239 - val_mcc: 0.3975 - val_auc: 0.8679\n",
      "Epoch 66/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4591 - tp: 4994.0000 - fp: 13389.0000 - tn: 39594.0000 - fn: 1109.0000 - accuracy: 0.7546 - precision: 0.2717 - recall: 0.8183 - mcc: 0.3718 - auc: 0.8616 - val_loss: 0.4546 - val_tp: 699.0000 - val_fp: 1600.0000 - val_tn: 4849.0000 - val_fn: 147.0000 - val_accuracy: 0.7605 - val_precision: 0.3040 - val_recall: 0.8262 - val_mcc: 0.3985 - val_auc: 0.8689\n",
      "Epoch 67/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4596 - tp: 4984.0000 - fp: 13459.0000 - tn: 39524.0000 - fn: 1119.0000 - accuracy: 0.7533 - precision: 0.2702 - recall: 0.8166 - mcc: 0.3695 - auc: 0.8608 - val_loss: 0.4619 - val_tp: 704.0000 - val_fp: 1641.0000 - val_tn: 4808.0000 - val_fn: 142.0000 - val_accuracy: 0.7556 - val_precision: 0.3002 - val_recall: 0.8322 - val_mcc: 0.3961 - val_auc: 0.8697\n",
      "Epoch 68/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4573 - tp: 4956.0000 - fp: 13259.0000 - tn: 39724.0000 - fn: 1147.0000 - accuracy: 0.7562 - precision: 0.2721 - recall: 0.8121 - mcc: 0.3703 - auc: 0.8625 - val_loss: 0.4385 - val_tp: 692.0000 - val_fp: 1514.0000 - val_tn: 4935.0000 - val_fn: 154.0000 - val_accuracy: 0.7714 - val_precision: 0.3137 - val_recall: 0.8180 - val_mcc: 0.4066 - val_auc: 0.8702\n",
      "Epoch 69/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4579 - tp: 4985.0000 - fp: 13386.0000 - tn: 39597.0000 - fn: 1118.0000 - accuracy: 0.7545 - precision: 0.2714 - recall: 0.8168 - mcc: 0.3709 - auc: 0.8621 - val_loss: 0.4442 - val_tp: 695.0000 - val_fp: 1552.0000 - val_tn: 4897.0000 - val_fn: 151.0000 - val_accuracy: 0.7666 - val_precision: 0.3093 - val_recall: 0.8215 - val_mcc: 0.4028 - val_auc: 0.8709\n",
      "Epoch 70/300\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4535 - tp: 4981.0000 - fp: 13293.0000 - tn: 39690.0000 - fn: 1122.0000 - accuracy: 0.7560 - precision: 0.2726 - recall: 0.8162 - mcc: 0.3722 - auc: 0.8650ETA: 2s - loss: 0.4489 - tp: 1946.0000 - fp: 5152.0000 - tn: 16011.0000 - fn: 443.0000 - accuracy: 0.7624 - precision: 0.2742 -  - 5s 42ms/step - loss: 0.4535 - tp: 4981.0000 - fp: 13293.0000 - tn: 39690.0000 - fn: 1122.0000 - accuracy: 0.7560 - precision: 0.2726 - recall: 0.8162 - mcc: 0.3722 - auc: 0.8650 - val_loss: 0.4715 - val_tp: 705.0000 - val_fp: 1669.0000 - val_tn: 4780.0000 - val_fn: 141.0000 - val_accuracy: 0.7519 - val_precision: 0.2970 - val_recall: 0.8333 - val_mcc: 0.3926 - val_auc: 0.8712\n",
      "Epoch 71/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4540 - tp: 4992.0000 - fp: 13218.0000 - tn: 39765.0000 - fn: 1111.0000 - accuracy: 0.7575 - precision: 0.2741 - recall: 0.8180 - mcc: 0.3747 - auc: 0.8645 - val_loss: 0.4647 - val_tp: 710.0000 - val_fp: 1661.0000 - val_tn: 4788.0000 - val_fn: 136.0000 - val_accuracy: 0.7537 - val_precision: 0.2995 - val_recall: 0.8392 - val_mcc: 0.3976 - val_auc: 0.8729\n",
      "Epoch 72/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4517 - tp: 4992.0000 - fp: 13156.0000 - tn: 39827.0000 - fn: 1111.0000 - accuracy: 0.7585 - precision: 0.2751 - recall: 0.8180 - mcc: 0.3758 - auc: 0.8661 - val_loss: 0.4730 - val_tp: 711.0000 - val_fp: 1701.0000 - val_tn: 4748.0000 - val_fn: 135.0000 - val_accuracy: 0.7483 - val_precision: 0.2948 - val_recall: 0.8404 - val_mcc: 0.3925 - val_auc: 0.8732\n",
      "Epoch 73/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.4518 - tp: 4989.0000 - fp: 13191.0000 - tn: 39792.0000 - fn: 1114.0000 - accuracy: 0.7579 - precision: 0.2744 - recall: 0.8175 - mcc: 0.3749 - auc: 0.8661 - val_loss: 0.4549 - val_tp: 705.0000 - val_fp: 1609.0000 - val_tn: 4840.0000 - val_fn: 141.0000 - val_accuracy: 0.7601 - val_precision: 0.3047 - val_recall: 0.8333 - val_mcc: 0.4017 - val_auc: 0.8739\n",
      "Epoch 74/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4495 - tp: 5000.0000 - fp: 13091.0000 - tn: 39892.0000 - fn: 1103.0000 - accuracy: 0.7598 - precision: 0.2764 - recall: 0.8193 - mcc: 0.3778 - auc: 0.8680 - val_loss: 0.4874 - val_tp: 719.0000 - val_fp: 1748.0000 - val_tn: 4701.0000 - val_fn: 127.0000 - val_accuracy: 0.7430 - val_precision: 0.2914 - val_recall: 0.8499 - val_mcc: 0.3918 - val_auc: 0.8737\n",
      "Epoch 75/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4487 - tp: 5016.0000 - fp: 13119.0000 - tn: 39864.0000 - fn: 1087.0000 - accuracy: 0.7596 - precision: 0.2766 - recall: 0.8219 - mcc: 0.3789 - auc: 0.8685 - val_loss: 0.4356 - val_tp: 699.0000 - val_fp: 1496.0000 - val_tn: 4953.0000 - val_fn: 147.0000 - val_accuracy: 0.7748 - val_precision: 0.3185 - val_recall: 0.8262 - val_mcc: 0.4149 - val_auc: 0.8745\n",
      "Epoch 76/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 5s 40ms/step - loss: 0.4476 - tp: 5000.0000 - fp: 13056.0000 - tn: 39927.0000 - fn: 1103.0000 - accuracy: 0.7604 - precision: 0.2769 - recall: 0.8193 - mcc: 0.3785 - auc: 0.8691 - val_loss: 0.4612 - val_tp: 708.0000 - val_fp: 1637.0000 - val_tn: 4812.0000 - val_fn: 138.0000 - val_accuracy: 0.7567 - val_precision: 0.3019 - val_recall: 0.8369 - val_mcc: 0.3997 - val_auc: 0.8752\n",
      "Epoch 77/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4466 - tp: 5005.0000 - fp: 12984.0000 - tn: 39999.0000 - fn: 1098.0000 - accuracy: 0.7617 - precision: 0.2782 - recall: 0.8201 - mcc: 0.3803 - auc: 0.8697 - val_loss: 0.4419 - val_tp: 703.0000 - val_fp: 1535.0000 - val_tn: 4914.0000 - val_fn: 143.0000 - val_accuracy: 0.7700 - val_precision: 0.3141 - val_recall: 0.8310 - val_mcc: 0.4117 - val_auc: 0.8765\n",
      "Epoch 78/300\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 0.4454 - tp: 5016.0000 - fp: 13010.0000 - tn: 39973.0000 - fn: 1087.0000 - accuracy: 0.7614 - precision: 0.2783 - recall: 0.8219 - mcc: 0.3809 - auc: 0.8701 - val_loss: 0.4423 - val_tp: 703.0000 - val_fp: 1533.0000 - val_tn: 4916.0000 - val_fn: 143.0000 - val_accuracy: 0.7703 - val_precision: 0.3144 - val_recall: 0.8310 - val_mcc: 0.4120 - val_auc: 0.8770\n",
      "Epoch 79/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4448 - tp: 5026.0000 - fp: 13041.0000 - tn: 39942.0000 - fn: 1077.0000 - accuracy: 0.7611 - precision: 0.2782 - recall: 0.8235 - mcc: 0.3814 - auc: 0.8709 - val_loss: 0.4321 - val_tp: 696.0000 - val_fp: 1489.0000 - val_tn: 4960.0000 - val_fn: 150.0000 - val_accuracy: 0.7753 - val_precision: 0.3185 - val_recall: 0.8227 - val_mcc: 0.4137 - val_auc: 0.8777\n",
      "Epoch 80/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4454 - tp: 4995.0000 - fp: 12925.0000 - tn: 40058.0000 - fn: 1108.0000 - accuracy: 0.7625 - precision: 0.2787 - recall: 0.8184 - mcc: 0.3804 - auc: 0.8702 - val_loss: 0.4758 - val_tp: 717.0000 - val_fp: 1681.0000 - val_tn: 4768.0000 - val_fn: 129.0000 - val_accuracy: 0.7519 - val_precision: 0.2990 - val_recall: 0.8475 - val_mcc: 0.4000 - val_auc: 0.8775\n",
      "Epoch 81/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4413 - tp: 5013.0000 - fp: 12703.0000 - tn: 40280.0000 - fn: 1090.0000 - accuracy: 0.7666 - precision: 0.2830 - recall: 0.8214 - mcc: 0.3863 - auc: 0.8733 - val_loss: 0.4513 - val_tp: 712.0000 - val_fp: 1583.0000 - val_tn: 4866.0000 - val_fn: 134.0000 - val_accuracy: 0.7646 - val_precision: 0.3102 - val_recall: 0.8416 - val_mcc: 0.4111 - val_auc: 0.8790\n",
      "Epoch 82/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4407 - tp: 5048.0000 - fp: 12965.0000 - tn: 40018.0000 - fn: 1055.0000 - accuracy: 0.7627 - precision: 0.2802 - recall: 0.8271 - mcc: 0.3850 - auc: 0.8737 - val_loss: 0.4234 - val_tp: 690.0000 - val_fp: 1435.0000 - val_tn: 5014.0000 - val_fn: 156.0000 - val_accuracy: 0.7819 - val_precision: 0.3247 - val_recall: 0.8156 - val_mcc: 0.4180 - val_auc: 0.8786\n",
      "Epoch 83/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.4409 - tp: 5050.0000 - fp: 12747.0000 - tn: 40236.0000 - fn: 1053.0000 - accuracy: 0.7664 - precision: 0.2838 - recall: 0.8275 - mcc: 0.3893 - auc: 0.8736 - val_loss: 0.4525 - val_tp: 709.0000 - val_fp: 1581.0000 - val_tn: 4868.0000 - val_fn: 137.0000 - val_accuracy: 0.7645 - val_precision: 0.3096 - val_recall: 0.8381 - val_mcc: 0.4091 - val_auc: 0.879400 - fp: 9313.0000 - tn: 29253.0000 - fn: 759.0000 - accuracy: 0.7658 - precision: 0.2834 - recall: 0.8291 \n",
      "Epoch 84/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4409 - tp: 5023.0000 - fp: 12693.0000 - tn: 40290.0000 - fn: 1080.0000 - accuracy: 0.7669 - precision: 0.2835 - recall: 0.8230 - mcc: 0.3876 - auc: 0.8734 - val_loss: 0.4678 - val_tp: 721.0000 - val_fp: 1651.0000 - val_tn: 4798.0000 - val_fn: 125.0000 - val_accuracy: 0.7565 - val_precision: 0.3040 - val_recall: 0.8522 - val_mcc: 0.4075 - val_auc: 0.8812\n",
      "Epoch 85/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4401 - tp: 5043.0000 - fp: 12899.0000 - tn: 40084.0000 - fn: 1060.0000 - accuracy: 0.7638 - precision: 0.2811 - recall: 0.8263 - mcc: 0.3858 - auc: 0.8737 - val_loss: 0.4582 - val_tp: 715.0000 - val_fp: 1604.0000 - val_tn: 4845.0000 - val_fn: 131.0000 - val_accuracy: 0.7622 - val_precision: 0.3083 - val_recall: 0.8452 - val_mcc: 0.4101 - val_auc: 0.8805\n",
      "Epoch 86/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4364 - tp: 5057.0000 - fp: 12660.0000 - tn: 40323.0000 - fn: 1046.0000 - accuracy: 0.7680 - precision: 0.2854 - recall: 0.8286 - mcc: 0.3917 - auc: 0.8762 - val_loss: 0.4444 - val_tp: 710.0000 - val_fp: 1545.0000 - val_tn: 4904.0000 - val_fn: 136.0000 - val_accuracy: 0.7696 - val_precision: 0.3149 - val_recall: 0.8392 - val_mcc: 0.4155 - val_auc: 0.8811\n",
      "Epoch 87/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4356 - tp: 5069.0000 - fp: 12689.0000 - tn: 40294.0000 - fn: 1034.0000 - accuracy: 0.7677 - precision: 0.2854 - recall: 0.8306 - mcc: 0.3923 - auc: 0.8770 - val_loss: 0.4226 - val_tp: 702.0000 - val_fp: 1453.0000 - val_tn: 4996.0000 - val_fn: 144.0000 - val_accuracy: 0.7811 - val_precision: 0.3258 - val_recall: 0.8298 - val_mcc: 0.4242 - val_auc: 0.8821\n",
      "Epoch 88/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4356 - tp: 5054.0000 - fp: 12437.0000 - tn: 40546.0000 - fn: 1049.0000 - accuracy: 0.7718 - precision: 0.2889 - recall: 0.8281 - mcc: 0.3956 - auc: 0.8768 - val_loss: 0.4852 - val_tp: 735.0000 - val_fp: 1731.0000 - val_tn: 4718.0000 - val_fn: 111.0000 - val_accuracy: 0.7475 - val_precision: 0.2981 - val_recall: 0.8688 - val_mcc: 0.4064 - val_auc: 0.8822\n",
      "Epoch 89/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4345 - tp: 5072.0000 - fp: 12692.0000 - tn: 40291.0000 - fn: 1031.0000 - accuracy: 0.7677 - precision: 0.2855 - recall: 0.8311 - mcc: 0.3926 - auc: 0.8773 - val_loss: 0.4580 - val_tp: 721.0000 - val_fp: 1596.0000 - val_tn: 4853.0000 - val_fn: 125.0000 - val_accuracy: 0.7641 - val_precision: 0.3112 - val_recall: 0.8522 - val_mcc: 0.4159 - val_auc: 0.8825\n",
      "Epoch 90/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4323 - tp: 5084.0000 - fp: 12543.0000 - tn: 40440.0000 - fn: 1019.0000 - accuracy: 0.7705 - precision: 0.2884 - recall: 0.8330 - mcc: 0.3966 - auc: 0.8787 - val_loss: 0.4542 - val_tp: 719.0000 - val_fp: 1597.0000 - val_tn: 4852.0000 - val_fn: 127.0000 - val_accuracy: 0.7637 - val_precision: 0.3104 - val_recall: 0.8499 - val_mcc: 0.4143 - val_auc: 0.8834\n",
      "Epoch 91/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4324 - tp: 5070.0000 - fp: 12568.0000 - tn: 40415.0000 - fn: 1033.0000 - accuracy: 0.7698 - precision: 0.2874 - recall: 0.8307 - mcc: 0.3947 - auc: 0.8785 - val_loss: 0.4621 - val_tp: 726.0000 - val_fp: 1630.0000 - val_tn: 4819.0000 - val_fn: 120.0000 - val_accuracy: 0.7601 - val_precision: 0.3081 - val_recall: 0.8582 - val_mcc: 0.4145 - val_auc: 0.8834\n",
      "Epoch 92/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4293 - tp: 5069.0000 - fp: 12248.0000 - tn: 40735.0000 - fn: 1034.0000 - accuracy: 0.7752 - precision: 0.2927 - recall: 0.8306 - mcc: 0.4008 - auc: 0.8807 - val_loss: 0.4686 - val_tp: 730.0000 - val_fp: 1664.0000 - val_tn: 4785.0000 - val_fn: 116.0000 - val_accuracy: 0.7560 - val_precision: 0.3049 - val_recall: 0.8629 - val_mcc: 0.4125 - val_auc: 0.8840\n",
      "Epoch 93/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4302 - tp: 5069.0000 - fp: 12538.0000 - tn: 40445.0000 - fn: 1034.0000 - accuracy: 0.7703 - precision: 0.2879 - recall: 0.8306 - mcc: 0.3952 - auc: 0.8798 - val_loss: 0.4629 - val_tp: 731.0000 - val_fp: 1634.0000 - val_tn: 4815.0000 - val_fn: 115.0000 - val_accuracy: 0.7602 - val_precision: 0.3091 - val_recall: 0.8641 - val_mcc: 0.4177 - val_auc: 0.8846\n",
      "Epoch 94/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4287 - tp: 5054.0000 - fp: 12456.0000 - tn: 40527.0000 - fn: 1049.0000 - accuracy: 0.7714 - precision: 0.2886 - recall: 0.8281 - mcc: 0.3952 - auc: 0.8809 - val_loss: 0.4467 - val_tp: 719.0000 - val_fp: 1555.0000 - val_tn: 4894.0000 - val_fn: 127.0000 - val_accuracy: 0.7694 - val_precision: 0.3162 - val_recall: 0.8499 - val_mcc: 0.4208 - val_auc: 0.8852\n",
      "Epoch 95/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4273 - tp: 5081.0000 - fp: 12395.0000 - tn: 40588.0000 - fn: 1022.0000 - accuracy: 0.7729 - precision: 0.2907 - recall: 0.8325 - mcc: 0.3992 - auc: 0.8815 - val_loss: 0.4554 - val_tp: 729.0000 - val_fp: 1604.0000 - val_tn: 4845.0000 - val_fn: 117.0000 - val_accuracy: 0.7641 - val_precision: 0.3125 - val_recall: 0.8617 - val_mcc: 0.4208 - val_auc: 0.8859\n",
      "Epoch 96/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4253 - tp: 5090.0000 - fp: 12355.0000 - tn: 40628.0000 - fn: 1013.0000 - accuracy: 0.7738 - precision: 0.2918 - recall: 0.8340 - mcc: 0.4009 - auc: 0.8831 - val_loss: 0.4490 - val_tp: 721.0000 - val_fp: 1559.0000 - val_tn: 4890.0000 - val_fn: 125.0000 - val_accuracy: 0.7692 - val_precision: 0.3162 - val_recall: 0.8522 - val_mcc: 0.4217 - val_auc: 0.8860\n",
      "Epoch 97/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4271 - tp: 5089.0000 - fp: 12483.0000 - tn: 40500.0000 - fn: 1014.0000 - accuracy: 0.7716 - precision: 0.2896 - recall: 0.8339 - mcc: 0.3983 - auc: 0.8817 - val_loss: 0.4384 - val_tp: 718.0000 - val_fp: 1519.0000 - val_tn: 4930.0000 - val_fn: 128.0000 - val_accuracy: 0.7742 - val_precision: 0.3210 - val_recall: 0.8487 - val_mcc: 0.4258 - val_auc: 0.8862\n",
      "Epoch 98/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4240 - tp: 5098.0000 - fp: 12129.0000 - tn: 40854.0000 - fn: 1005.0000 - accuracy: 0.7777 - precision: 0.2959 - recall: 0.8353 - mcc: 0.4061 - auc: 0.8837 - val_loss: 0.4379 - val_tp: 718.0000 - val_fp: 1542.0000 - val_tn: 4907.0000 - val_fn: 128.0000 - val_accuracy: 0.7711 - val_precision: 0.3177 - val_recall: 0.8487 - val_mcc: 0.4221 - val_auc: 0.8872\n",
      "Epoch 99/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.4247 - tp: 5065.0000 - fp: 12285.0000 - tn: 40698.0000 - fn: 1038.0000 - accuracy: 0.7745 - precision: 0.2919 - recall: 0.8299 - mcc: 0.3996 - auc: 0.8833 - val_loss: 0.4410 - val_tp: 721.0000 - val_fp: 1542.0000 - val_tn: 4907.0000 - val_fn: 125.0000 - val_accuracy: 0.7715 - val_precision: 0.3186 - val_recall: 0.8522 - val_mcc: 0.4244 - val_auc: 0.8876\n",
      "Epoch 100/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.4215 - tp: 5099.0000 - fp: 12127.0000 - tn: 40856.0000 - fn: 1004.0000 - accuracy: 0.7778 - precision: 0.2960 - recall: 0.8355 - mcc: 0.4062 - auc: 0.8852 - val_loss: 0.4302 - val_tp: 719.0000 - val_fp: 1500.0000 - val_tn: 4949.0000 - val_fn: 127.0000 - val_accuracy: 0.7770 - val_precision: 0.3240 - val_recall: 0.8499 - val_mcc: 0.4296 - val_auc: 0.8881\n",
      "Epoch 101/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4229 - tp: 5097.0000 - fp: 12179.0000 - tn: 40804.0000 - fn: 1006.0000 - accuracy: 0.7769 - precision: 0.2950 - recall: 0.8352 - mcc: 0.4050 - auc: 0.8842 - val_loss: 0.4510 - val_tp: 729.0000 - val_fp: 1580.0000 - val_tn: 4869.0000 - val_fn: 117.0000 - val_accuracy: 0.7674 - val_precision: 0.3157 - val_recall: 0.8617 - val_mcc: 0.4245 - val_auc: 0.8880\n",
      "Epoch 102/300\n",
      "116/116 [==============================] - 5s 45ms/step - loss: 0.4234 - tp: 5085.0000 - fp: 12186.0000 - tn: 40797.0000 - fn: 1018.0000 - accuracy: 0.7765 - precision: 0.2944 - recall: 0.8332 - mcc: 0.4036 - auc: 0.8840 - val_loss: 0.4508 - val_tp: 729.0000 - val_fp: 1575.0000 - val_tn: 4874.0000 - val_fn: 117.0000 - val_accuracy: 0.7681 - val_precision: 0.3164 - val_recall: 0.8617 - val_mcc: 0.4253 - val_auc: 0.8882\n",
      "Epoch 103/300\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 0.4203 - tp: 5103.0000 - fp: 12159.0000 - tn: 40824.0000 - fn: 1000.0000 - accuracy: 0.7773 - precision: 0.2956 - recall: 0.8361 - mcc: 0.4060 - auc: 0.8860 - val_loss: 0.4168 - val_tp: 710.0000 - val_fp: 1423.0000 - val_tn: 5026.0000 - val_fn: 136.0000 - val_accuracy: 0.7863 - val_precision: 0.3329 - val_recall: 0.8392 - val_mcc: 0.4354 - val_auc: 0.8894\n",
      "Epoch 104/300\n",
      "116/116 [==============================] - 5s 46ms/step - loss: 0.4178 - tp: 5112.0000 - fp: 12016.0000 - tn: 40967.0000 - fn: 991.0000 - accuracy: 0.7799 - precision: 0.2985 - recall: 0.8376 - mcc: 0.4097 - auc: 0.8877 - val_loss: 0.4192 - val_tp: 712.0000 - val_fp: 1447.0000 - val_tn: 5002.0000 - val_fn: 134.0000 - val_accuracy: 0.7833 - val_precision: 0.3298 - val_recall: 0.8416 - val_mcc: 0.4330 - val_auc: 0.8898\n",
      "Epoch 105/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4196 - tp: 5084.0000 - fp: 12010.0000 - tn: 40973.0000 - fn: 1019.0000 - accuracy: 0.7795 - precision: 0.2974 - recall: 0.8330 - mcc: 0.4070 - auc: 0.8861 - val_loss: 0.4463 - val_tp: 728.0000 - val_fp: 1564.0000 - val_tn: 4885.0000 - val_fn: 118.0000 - val_accuracy: 0.7694 - val_precision: 0.3176 - val_recall: 0.8605 - val_mcc: 0.4263 - val_auc: 0.8900\n",
      "Epoch 106/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4169 - tp: 5115.0000 - fp: 12011.0000 - tn: 40972.0000 - fn: 988.0000 - accuracy: 0.7800 - precision: 0.2987 - recall: 0.8381 - mcc: 0.4101 - auc: 0.8879 - val_loss: 0.4213 - val_tp: 715.0000 - val_fp: 1453.0000 - val_tn: 4996.0000 - val_fn: 131.0000 - val_accuracy: 0.7829 - val_precision: 0.3298 - val_recall: 0.8452 - val_mcc: 0.4343 - val_auc: 0.8907\n",
      "Epoch 107/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4154 - tp: 5127.0000 - fp: 11966.0000 - tn: 41017.0000 - fn: 976.0000 - accuracy: 0.7810 - precision: 0.2999 - recall: 0.8401 - mcc: 0.4123 - auc: 0.8889 - val_loss: 0.4404 - val_tp: 727.0000 - val_fp: 1547.0000 - val_tn: 4902.0000 - val_fn: 119.0000 - val_accuracy: 0.7716 - val_precision: 0.3197 - val_recall: 0.8593 - val_mcc: 0.4282 - val_auc: 0.8910\n",
      "Epoch 108/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4157 - tp: 5112.0000 - fp: 11859.0000 - tn: 41124.0000 - fn: 991.0000 - accuracy: 0.7825 - precision: 0.3012 - recall: 0.8376 - mcc: 0.4128 - auc: 0.8885 - val_loss: 0.4304 - val_tp: 723.0000 - val_fp: 1505.0000 - val_tn: 4944.0000 - val_fn: 123.0000 - val_accuracy: 0.7768 - val_precision: 0.3245 - val_recall: 0.8546 - val_mcc: 0.4319 - val_auc: 0.8914\n",
      "Epoch 109/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4151 - tp: 5140.0000 - fp: 11972.0000 - tn: 41011.0000 - fn: 963.0000 - accuracy: 0.7811 - precision: 0.3004 - recall: 0.8422 - mcc: 0.4135 - auc: 0.8889 - val_loss: 0.4191 - val_tp: 714.0000 - val_fp: 1443.0000 - val_tn: 5006.0000 - val_fn: 132.0000 - val_accuracy: 0.7841 - val_precision: 0.3310 - val_recall: 0.8440 - val_mcc: 0.4352 - val_auc: 0.8916\n",
      "Epoch 110/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4138 - tp: 5112.0000 - fp: 11822.0000 - tn: 41161.0000 - fn: 991.0000 - accuracy: 0.7831 - precision: 0.3019 - recall: 0.8376 - mcc: 0.4136 - auc: 0.8898 - val_loss: 0.3966 - val_tp: 705.0000 - val_fp: 1339.0000 - val_tn: 5110.0000 - val_fn: 141.0000 - val_accuracy: 0.7971 - val_precision: 0.3449 - val_recall: 0.8333 - val_mcc: 0.4461 - val_auc: 0.8922\n",
      "Epoch 111/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4146 - tp: 5114.0000 - fp: 11847.0000 - tn: 41136.0000 - fn: 989.0000 - accuracy: 0.7828 - precision: 0.3015 - recall: 0.8379 - mcc: 0.4133 - auc: 0.8894 - val_loss: 0.4478 - val_tp: 733.0000 - val_fp: 1565.0000 - val_tn: 4884.0000 - val_fn: 113.0000 - val_accuracy: 0.7700 - val_precision: 0.3190 - val_recall: 0.8664 - val_mcc: 0.4299 - val_auc: 0.8917\n",
      "Epoch 112/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4120 - tp: 5127.0000 - fp: 11752.0000 - tn: 41231.0000 - fn: 976.0000 - accuracy: 0.7846 - precision: 0.3038 - recall: 0.8401 - mcc: 0.4165 - auc: 0.8907 - val_loss: 0.4255 - val_tp: 720.0000 - val_fp: 1472.0000 - val_tn: 4977.0000 - val_fn: 126.0000 - val_accuracy: 0.7809 - val_precision: 0.3285 - val_recall: 0.8511 - val_mcc: 0.4350 - val_auc: 0.8932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4144 - tp: 5117.0000 - fp: 11778.0000 - tn: 41205.0000 - fn: 986.0000 - accuracy: 0.7840 - precision: 0.3029 - recall: 0.8384 - mcc: 0.4150 - auc: 0.8895 - val_loss: 0.4302 - val_tp: 723.0000 - val_fp: 1485.0000 - val_tn: 4964.0000 - val_fn: 123.0000 - val_accuracy: 0.7796 - val_precision: 0.3274 - val_recall: 0.8546 - val_mcc: 0.4351 - val_auc: 0.8933\n",
      "Epoch 114/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4115 - tp: 5125.0000 - fp: 11879.0000 - tn: 41104.0000 - fn: 978.0000 - accuracy: 0.7824 - precision: 0.3014 - recall: 0.8398 - mcc: 0.4138 - auc: 0.8910 - val_loss: 0.4295 - val_tp: 722.0000 - val_fp: 1481.0000 - val_tn: 4968.0000 - val_fn: 124.0000 - val_accuracy: 0.7800 - val_precision: 0.3277 - val_recall: 0.8534 - val_mcc: 0.4350 - val_auc: 0.8940\n",
      "Epoch 115/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4104 - tp: 5139.0000 - fp: 11749.0000 - tn: 41234.0000 - fn: 964.0000 - accuracy: 0.7848 - precision: 0.3043 - recall: 0.8420 - mcc: 0.4178 - auc: 0.8913 - val_loss: 0.4052 - val_tp: 712.0000 - val_fp: 1385.0000 - val_tn: 5064.0000 - val_fn: 134.0000 - val_accuracy: 0.7918 - val_precision: 0.3395 - val_recall: 0.8416 - val_mcc: 0.4435 - val_auc: 0.8941\n",
      "Epoch 116/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4103 - tp: 5150.0000 - fp: 11812.0000 - tn: 41171.0000 - fn: 953.0000 - accuracy: 0.7840 - precision: 0.3036 - recall: 0.8438 - mcc: 0.4177 - auc: 0.8920 - val_loss: 0.4138 - val_tp: 715.0000 - val_fp: 1398.0000 - val_tn: 5051.0000 - val_fn: 131.0000 - val_accuracy: 0.7904 - val_precision: 0.3384 - val_recall: 0.8452 - val_mcc: 0.4436 - val_auc: 0.8942\n",
      "Epoch 117/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4093 - tp: 5129.0000 - fp: 11628.0000 - tn: 41355.0000 - fn: 974.0000 - accuracy: 0.7867 - precision: 0.3061 - recall: 0.8404 - mcc: 0.4192 - auc: 0.8924 - val_loss: 0.4180 - val_tp: 719.0000 - val_fp: 1429.0000 - val_tn: 5020.0000 - val_fn: 127.0000 - val_accuracy: 0.7867 - val_precision: 0.3347 - val_recall: 0.8499 - val_mcc: 0.4414 - val_auc: 0.8946\n",
      "Epoch 118/300\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 0.4081 - tp: 5126.0000 - fp: 11591.0000 - tn: 41392.0000 - fn: 977.0000 - accuracy: 0.7873 - precision: 0.3066 - recall: 0.8399 - mcc: 0.4197 - auc: 0.8932 - val_loss: 0.4365 - val_tp: 730.0000 - val_fp: 1516.0000 - val_tn: 4933.0000 - val_fn: 116.0000 - val_accuracy: 0.7763 - val_precision: 0.3250 - val_recall: 0.8629 - val_mcc: 0.4355 - val_auc: 0.8951\n",
      "Epoch 119/300\n",
      "116/116 [==============================] - 5s 45ms/step - loss: 0.4056 - tp: 5164.0000 - fp: 11521.0000 - tn: 41462.0000 - fn: 939.0000 - accuracy: 0.7891 - precision: 0.3095 - recall: 0.8461 - mcc: 0.4250 - auc: 0.8945 - val_loss: 0.4249 - val_tp: 726.0000 - val_fp: 1455.0000 - val_tn: 4994.0000 - val_fn: 120.0000 - val_accuracy: 0.7841 - val_precision: 0.3329 - val_recall: 0.8582 - val_mcc: 0.4424 - val_auc: 0.8958\n",
      "Epoch 120/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4077 - tp: 5124.0000 - fp: 11753.0000 - tn: 41230.0000 - fn: 979.0000 - accuracy: 0.7845 - precision: 0.3036 - recall: 0.8396 - mcc: 0.4162 - auc: 0.8928 - val_loss: 0.4231 - val_tp: 727.0000 - val_fp: 1459.0000 - val_tn: 4990.0000 - val_fn: 119.0000 - val_accuracy: 0.7837 - val_precision: 0.3326 - val_recall: 0.8593 - val_mcc: 0.4425 - val_auc: 0.8960\n",
      "Epoch 121/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.4051 - tp: 5120.0000 - fp: 11441.0000 - tn: 41542.0000 - fn: 983.0000 - accuracy: 0.7897 - precision: 0.3092 - recall: 0.8389 - mcc: 0.4221 - auc: 0.8946 - val_loss: 0.4372 - val_tp: 735.0000 - val_fp: 1515.0000 - val_tn: 4934.0000 - val_fn: 111.0000 - val_accuracy: 0.7771 - val_precision: 0.3267 - val_recall: 0.8688 - val_mcc: 0.4395 - val_auc: 0.8959\n",
      "Epoch 122/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.4037 - tp: 5159.0000 - fp: 11600.0000 - tn: 41383.0000 - fn: 944.0000 - accuracy: 0.7877 - precision: 0.3078 - recall: 0.8453 - mcc: 0.4229 - auc: 0.8955 - val_loss: 0.4244 - val_tp: 730.0000 - val_fp: 1477.0000 - val_tn: 4972.0000 - val_fn: 116.0000 - val_accuracy: 0.7816 - val_precision: 0.3308 - val_recall: 0.8629 - val_mcc: 0.4418 - val_auc: 0.8971\n",
      "Epoch 123/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.4023 - tp: 5151.0000 - fp: 11471.0000 - tn: 41512.0000 - fn: 952.0000 - accuracy: 0.7897 - precision: 0.3099 - recall: 0.8440 - mcc: 0.4247 - auc: 0.8965 - val_loss: 0.3938 - val_tp: 708.0000 - val_fp: 1310.0000 - val_tn: 5139.0000 - val_fn: 138.0000 - val_accuracy: 0.8015 - val_precision: 0.3508 - val_recall: 0.8369 - val_mcc: 0.4536 - val_auc: 0.8969\n",
      "Epoch 124/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4027 - tp: 5158.0000 - fp: 11472.0000 - tn: 41511.0000 - fn: 945.0000 - accuracy: 0.7898 - precision: 0.3102 - recall: 0.8452 - mcc: 0.4254 - auc: 0.8959 - val_loss: 0.4448 - val_tp: 740.0000 - val_fp: 1539.0000 - val_tn: 4910.0000 - val_fn: 106.0000 - val_accuracy: 0.7745 - val_precision: 0.3247 - val_recall: 0.8747 - val_mcc: 0.4394 - val_auc: 0.8971\n",
      "Epoch 125/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4000 - tp: 5163.0000 - fp: 11324.0000 - tn: 41659.0000 - fn: 940.0000 - accuracy: 0.7924 - precision: 0.3132 - recall: 0.8460 - mcc: 0.4290 - auc: 0.8974 - val_loss: 0.4462 - val_tp: 740.0000 - val_fp: 1553.0000 - val_tn: 4896.0000 - val_fn: 106.0000 - val_accuracy: 0.7726 - val_precision: 0.3227 - val_recall: 0.8747 - val_mcc: 0.4372 - val_auc: 0.8979\n",
      "Epoch 126/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4038 - tp: 5157.0000 - fp: 11517.0000 - tn: 41466.0000 - fn: 946.0000 - accuracy: 0.7891 - precision: 0.3093 - recall: 0.8450 - mcc: 0.4244 - auc: 0.8953 - val_loss: 0.4397 - val_tp: 736.0000 - val_fp: 1515.0000 - val_tn: 4934.0000 - val_fn: 110.0000 - val_accuracy: 0.7772 - val_precision: 0.3270 - val_recall: 0.8700 - val_mcc: 0.4402 - val_auc: 0.8982\n",
      "Epoch 127/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.4019 - tp: 5140.0000 - fp: 11405.0000 - tn: 41578.0000 - fn: 963.0000 - accuracy: 0.7907 - precision: 0.3107 - recall: 0.8422 - mcc: 0.4249 - auc: 0.8964 - val_loss: 0.4207 - val_tp: 730.0000 - val_fp: 1457.0000 - val_tn: 4992.0000 - val_fn: 116.0000 - val_accuracy: 0.7844 - val_precision: 0.3338 - val_recall: 0.8629 - val_mcc: 0.4451 - val_auc: 0.8989\n",
      "Epoch 128/300\n",
      "116/116 [==============================] - 5s 46ms/step - loss: 0.3994 - tp: 5179.0000 - fp: 11377.0000 - tn: 41606.0000 - fn: 924.0000 - accuracy: 0.7918 - precision: 0.3128 - recall: 0.8486 - mcc: 0.4296 - auc: 0.8981 - val_loss: 0.4008 - val_tp: 718.0000 - val_fp: 1338.0000 - val_tn: 5111.0000 - val_fn: 128.0000 - val_accuracy: 0.7990 - val_precision: 0.3492 - val_recall: 0.8487 - val_mcc: 0.4564 - val_auc: 0.8989\n",
      "Epoch 129/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.4006 - tp: 5147.0000 - fp: 11309.0000 - tn: 41674.0000 - fn: 956.0000 - accuracy: 0.7924 - precision: 0.3128 - recall: 0.8434 - mcc: 0.4277 - auc: 0.8973 - val_loss: 0.4218 - val_tp: 734.0000 - val_fp: 1437.0000 - val_tn: 5012.0000 - val_fn: 112.0000 - val_accuracy: 0.7877 - val_precision: 0.3381 - val_recall: 0.8676 - val_mcc: 0.4516 - val_auc: 0.8992\n",
      "Epoch 130/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.3998 - tp: 5144.0000 - fp: 11363.0000 - tn: 41620.0000 - fn: 959.0000 - accuracy: 0.7915 - precision: 0.3116 - recall: 0.8429 - mcc: 0.4262 - auc: 0.8977 - val_loss: 0.4218 - val_tp: 728.0000 - val_fp: 1435.0000 - val_tn: 5014.0000 - val_fn: 118.0000 - val_accuracy: 0.7871 - val_precision: 0.3366 - val_recall: 0.8605 - val_mcc: 0.4473 - val_auc: 0.8996\n",
      "Epoch 131/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3968 - tp: 5178.0000 - fp: 11194.0000 - tn: 41789.0000 - fn: 925.0000 - accuracy: 0.7949 - precision: 0.3163 - recall: 0.8484 - mcc: 0.4333 - auc: 0.8994 - val_loss: 0.4112 - val_tp: 723.0000 - val_fp: 1368.0000 - val_tn: 5081.0000 - val_fn: 123.0000 - val_accuracy: 0.7956 - val_precision: 0.3458 - val_recall: 0.8546 - val_mcc: 0.4549 - val_auc: 0.8998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3980 - tp: 5162.0000 - fp: 11364.0000 - tn: 41619.0000 - fn: 941.0000 - accuracy: 0.7917 - precision: 0.3124 - recall: 0.8458 - mcc: 0.4281 - auc: 0.8983 - val_loss: 0.4173 - val_tp: 730.0000 - val_fp: 1422.0000 - val_tn: 5027.0000 - val_fn: 116.0000 - val_accuracy: 0.7892 - val_precision: 0.3392 - val_recall: 0.8629 - val_mcc: 0.4510 - val_auc: 0.9004\n",
      "Epoch 133/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3950 - tp: 5154.0000 - fp: 11252.0000 - tn: 41731.0000 - fn: 949.0000 - accuracy: 0.7935 - precision: 0.3142 - recall: 0.8445 - mcc: 0.4296 - auc: 0.9002 - val_loss: 0.4440 - val_tp: 741.0000 - val_fp: 1550.0000 - val_tn: 4899.0000 - val_fn: 105.0000 - val_accuracy: 0.7731 - val_precision: 0.3234 - val_recall: 0.8759 - val_mcc: 0.4384 - val_auc: 0.9009\n",
      "Epoch 134/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3938 - tp: 5184.0000 - fp: 11159.0000 - tn: 41824.0000 - fn: 919.0000 - accuracy: 0.7956 - precision: 0.3172 - recall: 0.8494 - mcc: 0.4346 - auc: 0.9008 - val_loss: 0.3727 - val_tp: 696.0000 - val_fp: 1179.0000 - val_tn: 5270.0000 - val_fn: 150.0000 - val_accuracy: 0.8178 - val_precision: 0.3712 - val_recall: 0.8227 - val_mcc: 0.4688 - val_auc: 0.9010\n",
      "Epoch 135/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3941 - tp: 5159.0000 - fp: 11154.0000 - tn: 41829.0000 - fn: 944.0000 - accuracy: 0.7952 - precision: 0.3163 - recall: 0.8453 - mcc: 0.4321 - auc: 0.9005 - val_loss: 0.3846 - val_tp: 707.0000 - val_fp: 1237.0000 - val_tn: 5212.0000 - val_fn: 139.0000 - val_accuracy: 0.8114 - val_precision: 0.3637 - val_recall: 0.8357 - val_mcc: 0.4663 - val_auc: 0.9012\n",
      "Epoch 136/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3944 - tp: 5173.0000 - fp: 11069.0000 - tn: 41914.0000 - fn: 930.0000 - accuracy: 0.7969 - precision: 0.3185 - recall: 0.8476 - mcc: 0.4354 - auc: 0.9003 - val_loss: 0.4241 - val_tp: 733.0000 - val_fp: 1445.0000 - val_tn: 5004.0000 - val_fn: 113.0000 - val_accuracy: 0.7864 - val_precision: 0.3365 - val_recall: 0.8664 - val_mcc: 0.4494 - val_auc: 0.9017\n",
      "Epoch 137/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3933 - tp: 5163.0000 - fp: 11072.0000 - tn: 41911.0000 - fn: 940.0000 - accuracy: 0.7967 - precision: 0.3180 - recall: 0.8460 - mcc: 0.4343 - auc: 0.9013 - val_loss: 0.3994 - val_tp: 722.0000 - val_fp: 1322.0000 - val_tn: 5127.0000 - val_fn: 124.0000 - val_accuracy: 0.8018 - val_precision: 0.3532 - val_recall: 0.8534 - val_mcc: 0.4623 - val_auc: 0.9022\n",
      "Epoch 138/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3936 - tp: 5192.0000 - fp: 11135.0000 - tn: 41848.0000 - fn: 911.0000 - accuracy: 0.7961 - precision: 0.3180 - recall: 0.8507 - mcc: 0.4360 - auc: 0.9008 - val_loss: 0.3781 - val_tp: 698.0000 - val_fp: 1190.0000 - val_tn: 5259.0000 - val_fn: 148.0000 - val_accuracy: 0.8166 - val_precision: 0.3697 - val_recall: 0.8251 - val_mcc: 0.4683 - val_auc: 0.9017\n",
      "Epoch 139/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3909 - tp: 5203.0000 - fp: 10997.0000 - tn: 41986.0000 - fn: 900.0000 - accuracy: 0.7986 - precision: 0.3212 - recall: 0.8525 - mcc: 0.4400 - auc: 0.9024 - val_loss: 0.4196 - val_tp: 735.0000 - val_fp: 1421.0000 - val_tn: 5028.0000 - val_fn: 111.0000 - val_accuracy: 0.7900 - val_precision: 0.3409 - val_recall: 0.8688 - val_mcc: 0.4550 - val_auc: 0.9025\n",
      "Epoch 140/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.3898 - tp: 5187.0000 - fp: 10869.0000 - tn: 42114.0000 - fn: 916.0000 - accuracy: 0.8005 - precision: 0.3231 - recall: 0.8499 - mcc: 0.4411 - auc: 0.9031 - val_loss: 0.4115 - val_tp: 732.0000 - val_fp: 1387.0000 - val_tn: 5062.0000 - val_fn: 114.0000 - val_accuracy: 0.7942 - val_precision: 0.3454 - val_recall: 0.8652 - val_mcc: 0.4586 - val_auc: 0.9034\n",
      "Epoch 141/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3908 - tp: 5182.0000 - fp: 10885.0000 - tn: 42098.0000 - fn: 921.0000 - accuracy: 0.8002 - precision: 0.3225 - recall: 0.8491 - mcc: 0.4402 - auc: 0.9023 - val_loss: 0.4183 - val_tp: 734.0000 - val_fp: 1399.0000 - val_tn: 5050.0000 - val_fn: 112.0000 - val_accuracy: 0.7929 - val_precision: 0.3441 - val_recall: 0.8676 - val_mcc: 0.4580 - val_auc: 0.9029\n",
      "Epoch 142/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3910 - tp: 5202.0000 - fp: 11120.0000 - tn: 41863.0000 - fn: 901.0000 - accuracy: 0.7966 - precision: 0.3187 - recall: 0.8524 - mcc: 0.4373 - auc: 0.9024 - val_loss: 0.3730 - val_tp: 706.0000 - val_fp: 1177.0000 - val_tn: 5272.0000 - val_fn: 140.0000 - val_accuracy: 0.8195 - val_precision: 0.3749 - val_recall: 0.8345 - val_mcc: 0.4771 - val_auc: 0.9037\n",
      "Epoch 143/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3899 - tp: 5170.0000 - fp: 10820.0000 - tn: 42163.0000 - fn: 933.0000 - accuracy: 0.8011 - precision: 0.3233 - recall: 0.8471 - mcc: 0.4404 - auc: 0.9029 - val_loss: 0.4204 - val_tp: 741.0000 - val_fp: 1417.0000 - val_tn: 5032.0000 - val_fn: 105.0000 - val_accuracy: 0.7914 - val_precision: 0.3434 - val_recall: 0.8759 - val_mcc: 0.4603 - val_auc: 0.9035\n",
      "Epoch 144/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3883 - tp: 5169.0000 - fp: 10928.0000 - tn: 42055.0000 - fn: 934.0000 - accuracy: 0.7992 - precision: 0.3211 - recall: 0.8470 - mcc: 0.4380 - auc: 0.9037 - val_loss: 0.4251 - val_tp: 736.0000 - val_fp: 1427.0000 - val_tn: 5022.0000 - val_fn: 110.0000 - val_accuracy: 0.7893 - val_precision: 0.3403 - val_recall: 0.8700 - val_mcc: 0.4548 - val_auc: 0.9039\n",
      "Epoch 145/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3882 - tp: 5187.0000 - fp: 10926.0000 - tn: 42057.0000 - fn: 916.0000 - accuracy: 0.7996 - precision: 0.3219 - recall: 0.8499 - mcc: 0.4399 - auc: 0.9036 - val_loss: 0.4168 - val_tp: 743.0000 - val_fp: 1410.0000 - val_tn: 5039.0000 - val_fn: 103.0000 - val_accuracy: 0.7926 - val_precision: 0.3451 - val_recall: 0.8783 - val_mcc: 0.4631 - val_auc: 0.9047\n",
      "Epoch 146/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3870 - tp: 5199.0000 - fp: 10805.0000 - tn: 42178.0000 - fn: 904.0000 - accuracy: 0.8018 - precision: 0.3249 - recall: 0.8519 - mcc: 0.4437 - auc: 0.9048 - val_loss: 0.4312 - val_tp: 750.0000 - val_fp: 1473.0000 - val_tn: 4976.0000 - val_fn: 96.0000 - val_accuracy: 0.7849 - val_precision: 0.3374 - val_recall: 0.8865 - val_mcc: 0.4578 - val_auc: 0.9048\n",
      "Epoch 147/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3891 - tp: 5178.0000 - fp: 10930.0000 - tn: 42053.0000 - fn: 925.0000 - accuracy: 0.7994 - precision: 0.3215 - recall: 0.8484 - mcc: 0.4389 - auc: 0.9031 - val_loss: 0.4250 - val_tp: 746.0000 - val_fp: 1441.0000 - val_tn: 5008.0000 - val_fn: 100.0000 - val_accuracy: 0.7888 - val_precision: 0.3411 - val_recall: 0.8818 - val_mcc: 0.4601 - val_auc: 0.9051\n",
      "Epoch 148/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3839 - tp: 5190.0000 - fp: 10776.0000 - tn: 42207.0000 - fn: 913.0000 - accuracy: 0.8022 - precision: 0.3251 - recall: 0.8504 - mcc: 0.4434 - auc: 0.9062 - val_loss: 0.4119 - val_tp: 738.0000 - val_fp: 1379.0000 - val_tn: 5070.0000 - val_fn: 108.0000 - val_accuracy: 0.7962 - val_precision: 0.3486 - val_recall: 0.8723 - val_mcc: 0.4646 - val_auc: 0.9054\n",
      "Epoch 149/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3840 - tp: 5198.0000 - fp: 10719.0000 - tn: 42264.0000 - fn: 905.0000 - accuracy: 0.8033 - precision: 0.3266 - recall: 0.8517 - mcc: 0.4455 - auc: 0.9059 - val_loss: 0.4165 - val_tp: 744.0000 - val_fp: 1387.0000 - val_tn: 5062.0000 - val_fn: 102.0000 - val_accuracy: 0.7959 - val_precision: 0.3491 - val_recall: 0.8794 - val_mcc: 0.4678 - val_auc: 0.9056\n",
      "Epoch 150/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3834 - tp: 5245.0000 - fp: 10724.0000 - tn: 42259.0000 - fn: 858.0000 - accuracy: 0.8040 - precision: 0.3284 - recall: 0.8594 - mcc: 0.4502 - auc: 0.9064 - val_loss: 0.3745 - val_tp: 705.0000 - val_fp: 1179.0000 - val_tn: 5270.0000 - val_fn: 141.0000 - val_accuracy: 0.8191 - val_precision: 0.3742 - val_recall: 0.8333 - val_mcc: 0.4759 - val_auc: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3840 - tp: 5202.0000 - fp: 10766.0000 - tn: 42217.0000 - fn: 901.0000 - accuracy: 0.8025 - precision: 0.3258 - recall: 0.8524 - mcc: 0.4449 - auc: 0.9058 - val_loss: 0.3957 - val_tp: 725.0000 - val_fp: 1282.0000 - val_tn: 5167.0000 - val_fn: 121.0000 - val_accuracy: 0.8077 - val_precision: 0.3612 - val_recall: 0.8570 - val_mcc: 0.4719 - val_auc: 0.9060\n",
      "Epoch 152/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3830 - tp: 5210.0000 - fp: 10578.0000 - tn: 42405.0000 - fn: 893.0000 - accuracy: 0.8059 - precision: 0.3300 - recall: 0.8537 - mcc: 0.4498 - auc: 0.9064 - val_loss: 0.4243 - val_tp: 751.0000 - val_fp: 1443.0000 - val_tn: 5006.0000 - val_fn: 95.0000 - val_accuracy: 0.7892 - val_precision: 0.3423 - val_recall: 0.8877 - val_mcc: 0.4636 - val_auc: 0.9066\n",
      "Epoch 153/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3815 - tp: 5223.0000 - fp: 10610.0000 - tn: 42373.0000 - fn: 880.0000 - accuracy: 0.8055 - precision: 0.3299 - recall: 0.8558 - mcc: 0.4505 - auc: 0.9074 - val_loss: 0.3828 - val_tp: 715.0000 - val_fp: 1213.0000 - val_tn: 5236.0000 - val_fn: 131.0000 - val_accuracy: 0.8158 - val_precision: 0.3709 - val_recall: 0.8452 - val_mcc: 0.4771 - val_auc: 0.9066\n",
      "Epoch 154/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3799 - tp: 5213.0000 - fp: 10455.0000 - tn: 42528.0000 - fn: 890.0000 - accuracy: 0.8080 - precision: 0.3327 - recall: 0.8542 - mcc: 0.4529 - auc: 0.9083 - val_loss: 0.3881 - val_tp: 724.0000 - val_fp: 1231.0000 - val_tn: 5218.0000 - val_fn: 122.0000 - val_accuracy: 0.8145 - val_precision: 0.3703 - val_recall: 0.8558 - val_mcc: 0.4807 - val_auc: 0.9071\n",
      "Epoch 155/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3811 - tp: 5208.0000 - fp: 10498.0000 - tn: 42485.0000 - fn: 895.0000 - accuracy: 0.8072 - precision: 0.3316 - recall: 0.8534 - mcc: 0.4514 - auc: 0.9078 - val_loss: 0.4169 - val_tp: 749.0000 - val_fp: 1384.0000 - val_tn: 5065.0000 - val_fn: 97.0000 - val_accuracy: 0.7970 - val_precision: 0.3511 - val_recall: 0.8853 - val_mcc: 0.4721 - val_auc: 0.9073\n",
      "Epoch 156/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3799 - tp: 5217.0000 - fp: 10598.0000 - tn: 42385.0000 - fn: 886.0000 - accuracy: 0.8056 - precision: 0.3299 - recall: 0.8548 - mcc: 0.4501 - auc: 0.9080 - val_loss: 0.3873 - val_tp: 724.0000 - val_fp: 1241.0000 - val_tn: 5208.0000 - val_fn: 122.0000 - val_accuracy: 0.8132 - val_precision: 0.3684 - val_recall: 0.8558 - val_mcc: 0.4788 - val_auc: 0.9078\n",
      "Epoch 157/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3811 - tp: 5216.0000 - fp: 10639.0000 - tn: 42344.0000 - fn: 887.0000 - accuracy: 0.8049 - precision: 0.3290 - recall: 0.8547 - mcc: 0.4491 - auc: 0.9075 - val_loss: 0.3638 - val_tp: 699.0000 - val_fp: 1125.0000 - val_tn: 5324.0000 - val_fn: 147.0000 - val_accuracy: 0.8256 - val_precision: 0.3832 - val_recall: 0.8262 - val_mcc: 0.4819 - val_auc: 0.9082\n",
      "Epoch 158/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3792 - tp: 5205.0000 - fp: 10443.0000 - tn: 42540.0000 - fn: 898.0000 - accuracy: 0.8081 - precision: 0.3326 - recall: 0.8529 - mcc: 0.4523 - auc: 0.9082 - val_loss: 0.4071 - val_tp: 742.0000 - val_fp: 1343.0000 - val_tn: 5106.0000 - val_fn: 104.0000 - val_accuracy: 0.8016 - val_precision: 0.3559 - val_recall: 0.8771 - val_mcc: 0.4740 - val_auc: 0.9082\n",
      "Epoch 159/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.3789 - tp: 5210.0000 - fp: 10522.0000 - tn: 42461.0000 - fn: 893.0000 - accuracy: 0.8068 - precision: 0.3312 - recall: 0.8537 - mcc: 0.4511 - auc: 0.9085 - val_loss: 0.4087 - val_tp: 747.0000 - val_fp: 1339.0000 - val_tn: 5110.0000 - val_fn: 99.0000 - val_accuracy: 0.8029 - val_precision: 0.3581 - val_recall: 0.8830 - val_mcc: 0.4785 - val_auc: 0.9091\n",
      "Epoch 160/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3784 - tp: 5202.0000 - fp: 10549.0000 - tn: 42434.0000 - fn: 901.0000 - accuracy: 0.8062 - precision: 0.3303 - recall: 0.8524 - mcc: 0.4496 - auc: 0.9087 - val_loss: 0.3893 - val_tp: 732.0000 - val_fp: 1259.0000 - val_tn: 5190.0000 - val_fn: 114.0000 - val_accuracy: 0.8118 - val_precision: 0.3677 - val_recall: 0.8652 - val_mcc: 0.4816 - val_auc: 0.9089\n",
      "Epoch 161/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3774 - tp: 5207.0000 - fp: 10383.0000 - tn: 42600.0000 - fn: 896.0000 - accuracy: 0.8091 - precision: 0.3340 - recall: 0.8532 - mcc: 0.4538 - auc: 0.9095 - val_loss: 0.3921 - val_tp: 730.0000 - val_fp: 1260.0000 - val_tn: 5189.0000 - val_fn: 116.0000 - val_accuracy: 0.8114 - val_precision: 0.3668 - val_recall: 0.8629 - val_mcc: 0.4799 - val_auc: 0.9090\n",
      "Epoch 162/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3771 - tp: 5211.0000 - fp: 10408.0000 - tn: 42575.0000 - fn: 892.0000 - accuracy: 0.8088 - precision: 0.3336 - recall: 0.8538 - mcc: 0.4537 - auc: 0.9097 - val_loss: 0.4060 - val_tp: 747.0000 - val_fp: 1343.0000 - val_tn: 5106.0000 - val_fn: 99.0000 - val_accuracy: 0.8023 - val_precision: 0.3574 - val_recall: 0.8830 - val_mcc: 0.4778 - val_auc: 0.9090\n",
      "Epoch 163/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3734 - tp: 5237.0000 - fp: 10401.0000 - tn: 42582.0000 - fn: 866.0000 - accuracy: 0.8093 - precision: 0.3349 - recall: 0.8581 - mcc: 0.4565 - auc: 0.9114 - val_loss: 0.3639 - val_tp: 708.0000 - val_fp: 1108.0000 - val_tn: 5341.0000 - val_fn: 138.0000 - val_accuracy: 0.8292 - val_precision: 0.3899 - val_recall: 0.8369 - val_mcc: 0.4925 - val_auc: 0.9093\n",
      "Epoch 164/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3744 - tp: 5240.0000 - fp: 10349.0000 - tn: 42634.0000 - fn: 863.0000 - accuracy: 0.8102 - precision: 0.3361 - recall: 0.8586 - mcc: 0.4580 - auc: 0.9108 - val_loss: 0.3939 - val_tp: 739.0000 - val_fp: 1273.0000 - val_tn: 5176.0000 - val_fn: 107.0000 - val_accuracy: 0.8108 - val_precision: 0.3673 - val_recall: 0.8735 - val_mcc: 0.4844 - val_auc: 0.9102\n",
      "Epoch 165/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3750 - tp: 5209.0000 - fp: 10267.0000 - tn: 42716.0000 - fn: 894.0000 - accuracy: 0.8111 - precision: 0.3366 - recall: 0.8535 - mcc: 0.4567 - auc: 0.9107 - val_loss: 0.4181 - val_tp: 750.0000 - val_fp: 1397.0000 - val_tn: 5052.0000 - val_fn: 96.0000 - val_accuracy: 0.7953 - val_precision: 0.3493 - val_recall: 0.8865 - val_mcc: 0.4707 - val_auc: 0.9101\n",
      "Epoch 166/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3732 - tp: 5224.0000 - fp: 10305.0000 - tn: 42678.0000 - fn: 879.0000 - accuracy: 0.8107 - precision: 0.3364 - recall: 0.8560 - mcc: 0.4574 - auc: 0.9116 - val_loss: 0.3949 - val_tp: 739.0000 - val_fp: 1274.0000 - val_tn: 5175.0000 - val_fn: 107.0000 - val_accuracy: 0.8107 - val_precision: 0.3671 - val_recall: 0.8735 - val_mcc: 0.4842 - val_auc: 0.9106\n",
      "Epoch 167/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3723 - tp: 5215.0000 - fp: 10214.0000 - tn: 42769.0000 - fn: 888.0000 - accuracy: 0.8121 - precision: 0.3380 - recall: 0.8545 - mcc: 0.4585 - auc: 0.9120 - val_loss: 0.3959 - val_tp: 742.0000 - val_fp: 1285.0000 - val_tn: 5164.0000 - val_fn: 104.0000 - val_accuracy: 0.8096 - val_precision: 0.3661 - val_recall: 0.8771 - val_mcc: 0.4845 - val_auc: 0.9108\n",
      "Epoch 168/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3718 - tp: 5234.0000 - fp: 10233.0000 - tn: 42750.0000 - fn: 869.0000 - accuracy: 0.8121 - precision: 0.3384 - recall: 0.8576 - mcc: 0.4600 - auc: 0.9121 - val_loss: 0.3998 - val_tp: 744.0000 - val_fp: 1292.0000 - val_tn: 5157.0000 - val_fn: 102.0000 - val_accuracy: 0.8089 - val_precision: 0.3654 - val_recall: 0.8794 - val_mcc: 0.4848 - val_auc: 0.9109\n",
      "Epoch 169/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3716 - tp: 5233.0000 - fp: 10204.0000 - tn: 42779.0000 - fn: 870.0000 - accuracy: 0.8126 - precision: 0.3390 - recall: 0.8574 - mcc: 0.4606 - auc: 0.9122 - val_loss: 0.3965 - val_tp: 744.0000 - val_fp: 1272.0000 - val_tn: 5177.0000 - val_fn: 102.0000 - val_accuracy: 0.8117 - val_precision: 0.3690 - val_recall: 0.8794 - val_mcc: 0.4884 - val_auc: 0.9115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3705 - tp: 5242.0000 - fp: 10139.0000 - tn: 42844.0000 - fn: 861.0000 - accuracy: 0.8138 - precision: 0.3408 - recall: 0.8589 - mcc: 0.4630 - auc: 0.9130 - val_loss: 0.3946 - val_tp: 738.0000 - val_fp: 1273.0000 - val_tn: 5176.0000 - val_fn: 108.0000 - val_accuracy: 0.8107 - val_precision: 0.3670 - val_recall: 0.8723 - val_mcc: 0.4836 - val_auc: 0.9111\n",
      "Epoch 171/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3697 - tp: 5262.0000 - fp: 10200.0000 - tn: 42783.0000 - fn: 841.0000 - accuracy: 0.8131 - precision: 0.3403 - recall: 0.8622 - mcc: 0.4637 - auc: 0.9133 - val_loss: 0.3728 - val_tp: 727.0000 - val_fp: 1137.0000 - val_tn: 5312.0000 - val_fn: 119.0000 - val_accuracy: 0.8278 - val_precision: 0.3900 - val_recall: 0.8593 - val_mcc: 0.5014 - val_auc: 0.9118\n",
      "Epoch 172/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.3708 - tp: 5230.0000 - fp: 10188.0000 - tn: 42795.0000 - fn: 873.0000 - accuracy: 0.8128 - precision: 0.3392 - recall: 0.8570 - mcc: 0.4606 - auc: 0.9125 - val_loss: 0.3980 - val_tp: 740.0000 - val_fp: 1278.0000 - val_tn: 5171.0000 - val_fn: 106.0000 - val_accuracy: 0.8103 - val_precision: 0.3667 - val_recall: 0.8747 - val_mcc: 0.4842 - val_auc: 0.9116\n",
      "Epoch 173/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.3694 - tp: 5235.0000 - fp: 10158.0000 - tn: 42825.0000 - fn: 868.0000 - accuracy: 0.8134 - precision: 0.3401 - recall: 0.8578 - mcc: 0.4618 - auc: 0.9134 - val_loss: 0.3758 - val_tp: 730.0000 - val_fp: 1174.0000 - val_tn: 5275.0000 - val_fn: 116.0000 - val_accuracy: 0.8232 - val_precision: 0.3834 - val_recall: 0.8629 - val_mcc: 0.4964 - val_auc: 0.9125\n",
      "Epoch 174/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3695 - tp: 5242.0000 - fp: 10046.0000 - tn: 42937.0000 - fn: 861.0000 - accuracy: 0.8154 - precision: 0.3429 - recall: 0.8589 - mcc: 0.4651 - auc: 0.9134 - val_loss: 0.3704 - val_tp: 728.0000 - val_fp: 1131.0000 - val_tn: 5318.0000 - val_fn: 118.0000 - val_accuracy: 0.8288 - val_precision: 0.3916 - val_recall: 0.8605 - val_mcc: 0.5034 - val_auc: 0.9126\n",
      "Epoch 175/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3659 - tp: 5222.0000 - fp: 9993.0000 - tn: 42990.0000 - fn: 881.0000 - accuracy: 0.8160 - precision: 0.3432 - recall: 0.8556 - mcc: 0.4643 - auc: 0.9150 - val_loss: 0.4072 - val_tp: 745.0000 - val_fp: 1319.0000 - val_tn: 5130.0000 - val_fn: 101.0000 - val_accuracy: 0.8053 - val_precision: 0.3609 - val_recall: 0.8806 - val_mcc: 0.4806 - val_auc: 0.9131\n",
      "Epoch 176/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.3640 - tp: 5231.0000 - fp: 9955.0000 - tn: 43028.0000 - fn: 872.0000 - accuracy: 0.8168 - precision: 0.3445 - recall: 0.8571 - mcc: 0.4661 - auc: 0.9160 - val_loss: 0.3807 - val_tp: 737.0000 - val_fp: 1192.0000 - val_tn: 5257.0000 - val_fn: 109.0000 - val_accuracy: 0.8217 - val_precision: 0.3821 - val_recall: 0.8712 - val_mcc: 0.4983 - val_auc: 0.9133\n",
      "Epoch 177/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3684 - tp: 5243.0000 - fp: 10097.0000 - tn: 42886.0000 - fn: 860.0000 - accuracy: 0.8146 - precision: 0.3418 - recall: 0.8591 - mcc: 0.4641 - auc: 0.9138 - val_loss: 0.4469 - val_tp: 767.0000 - val_fp: 1515.0000 - val_tn: 4934.0000 - val_fn: 79.0000 - val_accuracy: 0.7815 - val_precision: 0.3361 - val_recall: 0.9066 - val_mcc: 0.4639 - val_auc: 0.9130\n",
      "Epoch 178/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3647 - tp: 5245.0000 - fp: 9918.0000 - tn: 43065.0000 - fn: 858.0000 - accuracy: 0.8176 - precision: 0.3459 - recall: 0.8594 - mcc: 0.4684 - auc: 0.9157 - val_loss: 0.3980 - val_tp: 741.0000 - val_fp: 1264.0000 - val_tn: 5185.0000 - val_fn: 105.0000 - val_accuracy: 0.8123 - val_precision: 0.3696 - val_recall: 0.8759 - val_mcc: 0.4876 - val_auc: 0.9123\n",
      "Epoch 179/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3659 - tp: 5241.0000 - fp: 9913.0000 - tn: 43070.0000 - fn: 862.0000 - accuracy: 0.8176 - precision: 0.3458 - recall: 0.8588 - mcc: 0.4681 - auc: 0.9150 - val_loss: 0.4154 - val_tp: 755.0000 - val_fp: 1362.0000 - val_tn: 5087.0000 - val_fn: 91.0000 - val_accuracy: 0.8008 - val_precision: 0.3566 - val_recall: 0.8924 - val_mcc: 0.4806 - val_auc: 0.9136\n",
      "Epoch 180/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3644 - tp: 5222.0000 - fp: 9942.0000 - tn: 43041.0000 - fn: 881.0000 - accuracy: 0.8168 - precision: 0.3444 - recall: 0.8556 - mcc: 0.4654 - auc: 0.9157 - val_loss: 0.3989 - val_tp: 747.0000 - val_fp: 1278.0000 - val_tn: 5171.0000 - val_fn: 99.0000 - val_accuracy: 0.8112 - val_precision: 0.3689 - val_recall: 0.8830 - val_mcc: 0.4896 - val_auc: 0.9141\n",
      "Epoch 181/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3630 - tp: 5284.0000 - fp: 9930.0000 - tn: 43053.0000 - fn: 819.0000 - accuracy: 0.8181 - precision: 0.3473 - recall: 0.8658 - mcc: 0.4722 - auc: 0.9164 - val_loss: 0.3903 - val_tp: 739.0000 - val_fp: 1227.0000 - val_tn: 5222.0000 - val_fn: 107.0000 - val_accuracy: 0.8171 - val_precision: 0.3759 - val_recall: 0.8735 - val_mcc: 0.4931 - val_auc: 0.9137\n",
      "Epoch 182/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3634 - tp: 5230.0000 - fp: 9738.0000 - tn: 43245.0000 - fn: 873.0000 - accuracy: 0.8204 - precision: 0.3494 - recall: 0.8570 - mcc: 0.4711 - auc: 0.9165 - val_loss: 0.3903 - val_tp: 745.0000 - val_fp: 1249.0000 - val_tn: 5200.0000 - val_fn: 101.0000 - val_accuracy: 0.8149 - val_precision: 0.3736 - val_recall: 0.8806 - val_mcc: 0.4935 - val_auc: 0.9144\n",
      "Epoch 183/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3646 - tp: 5268.0000 - fp: 10073.0000 - tn: 42910.0000 - fn: 835.0000 - accuracy: 0.8154 - precision: 0.3434 - recall: 0.8632 - mcc: 0.4672 - auc: 0.9158 - val_loss: 0.4026 - val_tp: 750.0000 - val_fp: 1296.0000 - val_tn: 5153.0000 - val_fn: 96.0000 - val_accuracy: 0.8092 - val_precision: 0.3666 - val_recall: 0.8865 - val_mcc: 0.4886 - val_auc: 0.9149\n",
      "Epoch 184/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3631 - tp: 5254.0000 - fp: 9889.0000 - tn: 43094.0000 - fn: 849.0000 - accuracy: 0.8183 - precision: 0.3470 - recall: 0.8609 - mcc: 0.4700 - auc: 0.9164 - val_loss: 0.3724 - val_tp: 734.0000 - val_fp: 1151.0000 - val_tn: 5298.0000 - val_fn: 112.0000 - val_accuracy: 0.8269 - val_precision: 0.3894 - val_recall: 0.8676 - val_mcc: 0.5041 - val_auc: 0.9152\n",
      "Epoch 185/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3626 - tp: 5281.0000 - fp: 9826.0000 - tn: 43157.0000 - fn: 822.0000 - accuracy: 0.8198 - precision: 0.3496 - recall: 0.8653 - mcc: 0.4743 - auc: 0.9166 - val_loss: 0.3815 - val_tp: 739.0000 - val_fp: 1186.0000 - val_tn: 5263.0000 - val_fn: 107.0000 - val_accuracy: 0.8228 - val_precision: 0.3839 - val_recall: 0.8735 - val_mcc: 0.5010 - val_auc: 0.9152\n",
      "Epoch 186/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3595 - tp: 5269.0000 - fp: 9695.0000 - tn: 43288.0000 - fn: 834.0000 - accuracy: 0.8218 - precision: 0.3521 - recall: 0.8633 - mcc: 0.4761 - auc: 0.9181 - val_loss: 0.3931 - val_tp: 750.0000 - val_fp: 1230.0000 - val_tn: 5219.0000 - val_fn: 96.0000 - val_accuracy: 0.8182 - val_precision: 0.3788 - val_recall: 0.8865 - val_mcc: 0.5010 - val_auc: 0.9157\n",
      "Epoch 187/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3592 - tp: 5251.0000 - fp: 9712.0000 - tn: 43271.0000 - fn: 852.0000 - accuracy: 0.8212 - precision: 0.3509 - recall: 0.8604 - mcc: 0.4739 - auc: 0.9183 - val_loss: 0.3774 - val_tp: 738.0000 - val_fp: 1172.0000 - val_tn: 5277.0000 - val_fn: 108.0000 - val_accuracy: 0.8245 - val_precision: 0.3864 - val_recall: 0.8723 - val_mcc: 0.5030 - val_auc: 0.9161\n",
      "Epoch 188/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3618 - tp: 5222.0000 - fp: 9860.0000 - tn: 43123.0000 - fn: 881.0000 - accuracy: 0.8182 - precision: 0.3462 - recall: 0.8556 - mcc: 0.4674 - auc: 0.9168 - val_loss: 0.3628 - val_tp: 727.0000 - val_fp: 1103.0000 - val_tn: 5346.0000 - val_fn: 119.0000 - val_accuracy: 0.8325 - val_precision: 0.3973 - val_recall: 0.8593 - val_mcc: 0.5084 - val_auc: 0.9152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3577 - tp: 5260.0000 - fp: 9703.0000 - tn: 43280.0000 - fn: 843.0000 - accuracy: 0.8215 - precision: 0.3515 - recall: 0.8619 - mcc: 0.4750 - auc: 0.9189 - val_loss: 0.3997 - val_tp: 749.0000 - val_fp: 1274.0000 - val_tn: 5175.0000 - val_fn: 97.0000 - val_accuracy: 0.8121 - val_precision: 0.3702 - val_recall: 0.8853 - val_mcc: 0.4919 - val_auc: 0.9162\n",
      "Epoch 190/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3589 - tp: 5261.0000 - fp: 9636.0000 - tn: 43347.0000 - fn: 842.0000 - accuracy: 0.8227 - precision: 0.3532 - recall: 0.8620 - mcc: 0.4767 - auc: 0.9186 - val_loss: 0.3517 - val_tp: 723.0000 - val_fp: 1051.0000 - val_tn: 5398.0000 - val_fn: 123.0000 - val_accuracy: 0.8391 - val_precision: 0.4076 - val_recall: 0.8546 - val_mcc: 0.5162 - val_auc: 0.9161\n",
      "Epoch 191/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3587 - tp: 5263.0000 - fp: 9610.0000 - tn: 43373.0000 - fn: 840.0000 - accuracy: 0.8231 - precision: 0.3539 - recall: 0.8624 - mcc: 0.4775 - auc: 0.9184 - val_loss: 0.3899 - val_tp: 747.0000 - val_fp: 1248.0000 - val_tn: 5201.0000 - val_fn: 99.0000 - val_accuracy: 0.8154 - val_precision: 0.3744 - val_recall: 0.8830 - val_mcc: 0.4953 - val_auc: 0.9164\n",
      "Epoch 192/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3576 - tp: 5268.0000 - fp: 9789.0000 - tn: 43194.0000 - fn: 835.0000 - accuracy: 0.8202 - precision: 0.3499 - recall: 0.8632 - mcc: 0.4738 - auc: 0.9188 - val_loss: 0.4086 - val_tp: 755.0000 - val_fp: 1304.0000 - val_tn: 5145.0000 - val_fn: 91.0000 - val_accuracy: 0.8088 - val_precision: 0.3667 - val_recall: 0.8924 - val_mcc: 0.4910 - val_auc: 0.9161\n",
      "Epoch 193/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3550 - tp: 5270.0000 - fp: 9496.0000 - tn: 43487.0000 - fn: 833.0000 - accuracy: 0.8252 - precision: 0.3569 - recall: 0.8635 - mcc: 0.4810 - auc: 0.9203 - val_loss: 0.3884 - val_tp: 747.0000 - val_fp: 1213.0000 - val_tn: 5236.0000 - val_fn: 99.0000 - val_accuracy: 0.8202 - val_precision: 0.3811 - val_recall: 0.8830 - val_mcc: 0.5019 - val_auc: 0.9168\n",
      "Epoch 194/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3563 - tp: 5251.0000 - fp: 9643.0000 - tn: 43340.0000 - fn: 852.0000 - accuracy: 0.8224 - precision: 0.3526 - recall: 0.8604 - mcc: 0.4755 - auc: 0.9195 - val_loss: 0.3998 - val_tp: 750.0000 - val_fp: 1265.0000 - val_tn: 5184.0000 - val_fn: 96.0000 - val_accuracy: 0.8134 - val_precision: 0.3722 - val_recall: 0.8865 - val_mcc: 0.4944 - val_auc: 0.9170\n",
      "Epoch 195/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3549 - tp: 5283.0000 - fp: 9514.0000 - tn: 43469.0000 - fn: 820.0000 - accuracy: 0.8251 - precision: 0.3570 - recall: 0.8656 - mcc: 0.4819 - auc: 0.9203 - val_loss: 0.3921 - val_tp: 753.0000 - val_fp: 1228.0000 - val_tn: 5221.0000 - val_fn: 93.0000 - val_accuracy: 0.8189 - val_precision: 0.3801 - val_recall: 0.8901 - val_mcc: 0.5037 - val_auc: 0.9175\n",
      "Epoch 196/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3562 - tp: 5279.0000 - fp: 9570.0000 - tn: 43413.0000 - fn: 824.0000 - accuracy: 0.8241 - precision: 0.3555 - recall: 0.8650 - mcc: 0.4802 - auc: 0.9198 - val_loss: 0.3743 - val_tp: 735.0000 - val_fp: 1154.0000 - val_tn: 5295.0000 - val_fn: 111.0000 - val_accuracy: 0.8266 - val_precision: 0.3891 - val_recall: 0.8688 - val_mcc: 0.5042 - val_auc: 0.9180\n",
      "Epoch 197/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3555 - tp: 5263.0000 - fp: 9574.0000 - tn: 43409.0000 - fn: 840.0000 - accuracy: 0.8237 - precision: 0.3547 - recall: 0.8624 - mcc: 0.4784 - auc: 0.9200 - val_loss: 0.3913 - val_tp: 750.0000 - val_fp: 1232.0000 - val_tn: 5217.0000 - val_fn: 96.0000 - val_accuracy: 0.8180 - val_precision: 0.3784 - val_recall: 0.8865 - val_mcc: 0.5006 - val_auc: 0.9175\n",
      "Epoch 198/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3508 - tp: 5293.0000 - fp: 9390.0000 - tn: 43593.0000 - fn: 810.0000 - accuracy: 0.8274 - precision: 0.3605 - recall: 0.8673 - mcc: 0.4860 - auc: 0.9222 - val_loss: 0.4032 - val_tp: 757.0000 - val_fp: 1287.0000 - val_tn: 5162.0000 - val_fn: 89.0000 - val_accuracy: 0.8114 - val_precision: 0.3704 - val_recall: 0.8948 - val_mcc: 0.4957 - val_auc: 0.9179\n",
      "Epoch 199/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3527 - tp: 5286.0000 - fp: 9525.0000 - tn: 43458.0000 - fn: 817.0000 - accuracy: 0.8250 - precision: 0.3569 - recall: 0.8661 - mcc: 0.4820 - auc: 0.9211 - val_loss: 0.3684 - val_tp: 734.0000 - val_fp: 1128.0000 - val_tn: 5321.0000 - val_fn: 112.0000 - val_accuracy: 0.8300 - val_precision: 0.3942 - val_recall: 0.8676 - val_mcc: 0.5087 - val_auc: 0.9178\n",
      "Epoch 200/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3507 - tp: 5310.0000 - fp: 9503.0000 - tn: 43480.0000 - fn: 793.0000 - accuracy: 0.8257 - precision: 0.3585 - recall: 0.8701 - mcc: 0.4850 - auc: 0.9225 - val_loss: 0.3847 - val_tp: 747.0000 - val_fp: 1180.0000 - val_tn: 5269.0000 - val_fn: 99.0000 - val_accuracy: 0.8247 - val_precision: 0.3876 - val_recall: 0.8830 - val_mcc: 0.5084 - val_auc: 0.9181\n",
      "Epoch 201/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3517 - tp: 5279.0000 - fp: 9427.0000 - tn: 43556.0000 - fn: 824.0000 - accuracy: 0.8265 - precision: 0.3590 - recall: 0.8650 - mcc: 0.4836 - auc: 0.9218 - val_loss: 0.4008 - val_tp: 756.0000 - val_fp: 1256.0000 - val_tn: 5193.0000 - val_fn: 90.0000 - val_accuracy: 0.8155 - val_precision: 0.3757 - val_recall: 0.8936 - val_mcc: 0.5007 - val_auc: 0.9189\n",
      "Epoch 202/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3506 - tp: 5312.0000 - fp: 9415.0000 - tn: 43568.0000 - fn: 791.0000 - accuracy: 0.8273 - precision: 0.3607 - recall: 0.8704 - mcc: 0.4873 - auc: 0.9223 - val_loss: 0.3551 - val_tp: 728.0000 - val_fp: 1039.0000 - val_tn: 5410.0000 - val_fn: 118.0000 - val_accuracy: 0.8414 - val_precision: 0.4120 - val_recall: 0.8605 - val_mcc: 0.5227 - val_auc: 0.9189\n",
      "Epoch 203/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3522 - tp: 5267.0000 - fp: 9438.0000 - tn: 43545.0000 - fn: 836.0000 - accuracy: 0.8261 - precision: 0.3582 - recall: 0.8630 - mcc: 0.4821 - auc: 0.9217 - val_loss: 0.3842 - val_tp: 746.0000 - val_fp: 1179.0000 - val_tn: 5270.0000 - val_fn: 100.0000 - val_accuracy: 0.8247 - val_precision: 0.3875 - val_recall: 0.8818 - val_mcc: 0.5078 - val_auc: 0.9191\n",
      "Epoch 204/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3502 - tp: 5291.0000 - fp: 9318.0000 - tn: 43665.0000 - fn: 812.0000 - accuracy: 0.8286 - precision: 0.3622 - recall: 0.8670 - mcc: 0.4875 - auc: 0.9225 - val_loss: 0.3738 - val_tp: 742.0000 - val_fp: 1149.0000 - val_tn: 5300.0000 - val_fn: 104.0000 - val_accuracy: 0.8282 - val_precision: 0.3924 - val_recall: 0.8771 - val_mcc: 0.5107 - val_auc: 0.9193\n",
      "Epoch 205/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3509 - tp: 5295.0000 - fp: 9435.0000 - tn: 43548.0000 - fn: 808.0000 - accuracy: 0.8266 - precision: 0.3595 - recall: 0.8676 - mcc: 0.4851 - auc: 0.9221 - val_loss: 0.3671 - val_tp: 742.0000 - val_fp: 1104.0000 - val_tn: 5345.0000 - val_fn: 104.0000 - val_accuracy: 0.8344 - val_precision: 0.4020 - val_recall: 0.8771 - val_mcc: 0.5199 - val_auc: 0.9195\n",
      "Epoch 206/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3499 - tp: 5312.0000 - fp: 9439.0000 - tn: 43544.0000 - fn: 791.0000 - accuracy: 0.8269 - precision: 0.3601 - recall: 0.8704 - mcc: 0.4868 - auc: 0.9225 - val_loss: 0.3718 - val_tp: 742.0000 - val_fp: 1142.0000 - val_tn: 5307.0000 - val_fn: 104.0000 - val_accuracy: 0.8292 - val_precision: 0.3938 - val_recall: 0.8771 - val_mcc: 0.5121 - val_auc: 0.9198\n",
      "Epoch 207/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3493 - tp: 5274.0000 - fp: 9341.0000 - tn: 43642.0000 - fn: 829.0000 - accuracy: 0.8279 - precision: 0.3609 - recall: 0.8642 - mcc: 0.4852 - auc: 0.9227 - val_loss: 0.3840 - val_tp: 748.0000 - val_fp: 1185.0000 - val_tn: 5264.0000 - val_fn: 98.0000 - val_accuracy: 0.8241 - val_precision: 0.3870 - val_recall: 0.8842 - val_mcc: 0.5082 - val_auc: 0.9199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3468 - tp: 5307.0000 - fp: 9104.0000 - tn: 43879.0000 - fn: 796.0000 - accuracy: 0.8324 - precision: 0.3683 - recall: 0.8696 - mcc: 0.4945 - auc: 0.9241 - val_loss: 0.3964 - val_tp: 754.0000 - val_fp: 1239.0000 - val_tn: 5210.0000 - val_fn: 92.0000 - val_accuracy: 0.8175 - val_precision: 0.3783 - val_recall: 0.8913 - val_mcc: 0.5024 - val_auc: 0.9202\n",
      "Epoch 209/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3462 - tp: 5308.0000 - fp: 9374.0000 - tn: 43609.0000 - fn: 795.0000 - accuracy: 0.8279 - precision: 0.3615 - recall: 0.8697 - mcc: 0.4879 - auc: 0.9244 - val_loss: 0.3453 - val_tp: 726.0000 - val_fp: 1014.0000 - val_tn: 5435.0000 - val_fn: 120.0000 - val_accuracy: 0.8446 - val_precision: 0.4172 - val_recall: 0.8582 - val_mcc: 0.5266 - val_auc: 0.9204\n",
      "Epoch 210/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3465 - tp: 5264.0000 - fp: 9143.0000 - tn: 43840.0000 - fn: 839.0000 - accuracy: 0.8311 - precision: 0.3654 - recall: 0.8625 - mcc: 0.4890 - auc: 0.9241 - val_loss: 0.4135 - val_tp: 762.0000 - val_fp: 1301.0000 - val_tn: 5148.0000 - val_fn: 84.0000 - val_accuracy: 0.8101 - val_precision: 0.3694 - val_recall: 0.9007 - val_mcc: 0.4969 - val_auc: 0.9203\n",
      "Epoch 211/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3475 - tp: 5289.0000 - fp: 9297.0000 - tn: 43686.0000 - fn: 814.0000 - accuracy: 0.8289 - precision: 0.3626 - recall: 0.8666 - mcc: 0.4878 - auc: 0.9237 - val_loss: 0.3744 - val_tp: 747.0000 - val_fp: 1125.0000 - val_tn: 5324.0000 - val_fn: 99.0000 - val_accuracy: 0.8322 - val_precision: 0.3990 - val_recall: 0.8830 - val_mcc: 0.5194 - val_auc: 0.9210\n",
      "Epoch 212/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3475 - tp: 5265.0000 - fp: 9290.0000 - tn: 43693.0000 - fn: 838.0000 - accuracy: 0.8286 - precision: 0.3617 - recall: 0.8627 - mcc: 0.4855 - auc: 0.9235 - val_loss: 0.3751 - val_tp: 745.0000 - val_fp: 1144.0000 - val_tn: 5305.0000 - val_fn: 101.0000 - val_accuracy: 0.8293 - val_precision: 0.3944 - val_recall: 0.8806 - val_mcc: 0.5140 - val_auc: 0.9204\n",
      "Epoch 213/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3452 - tp: 5302.0000 - fp: 9217.0000 - tn: 43766.0000 - fn: 801.0000 - accuracy: 0.8305 - precision: 0.3652 - recall: 0.8688 - mcc: 0.4912 - auc: 0.9247 - val_loss: 0.3779 - val_tp: 749.0000 - val_fp: 1155.0000 - val_tn: 5294.0000 - val_fn: 97.0000 - val_accuracy: 0.8284 - val_precision: 0.3934 - val_recall: 0.8853 - val_mcc: 0.5149 - val_auc: 0.9213\n",
      "Epoch 214/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3460 - tp: 5296.0000 - fp: 9213.0000 - tn: 43770.0000 - fn: 807.0000 - accuracy: 0.8304 - precision: 0.3650 - recall: 0.8678 - mcc: 0.4906 - auc: 0.9243 - val_loss: 0.3809 - val_tp: 749.0000 - val_fp: 1168.0000 - val_tn: 5281.0000 - val_fn: 97.0000 - val_accuracy: 0.8266 - val_precision: 0.3907 - val_recall: 0.8853 - val_mcc: 0.5123 - val_auc: 0.9210\n",
      "Epoch 215/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3426 - tp: 5302.0000 - fp: 9106.0000 - tn: 43877.0000 - fn: 801.0000 - accuracy: 0.8323 - precision: 0.3680 - recall: 0.8688 - mcc: 0.4939 - auc: 0.9258 - val_loss: 0.3682 - val_tp: 740.0000 - val_fp: 1099.0000 - val_tn: 5350.0000 - val_fn: 106.0000 - val_accuracy: 0.8348 - val_precision: 0.4024 - val_recall: 0.8747 - val_mcc: 0.5193 - val_auc: 0.9210\n",
      "Epoch 216/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3454 - tp: 5295.0000 - fp: 9158.0000 - tn: 43825.0000 - fn: 808.0000 - accuracy: 0.8313 - precision: 0.3664 - recall: 0.8676 - mcc: 0.4919 - auc: 0.9245 - val_loss: 0.3633 - val_tp: 742.0000 - val_fp: 1094.0000 - val_tn: 5355.0000 - val_fn: 104.0000 - val_accuracy: 0.8358 - val_precision: 0.4041 - val_recall: 0.8771 - val_mcc: 0.5219 - val_auc: 0.9219\n",
      "Epoch 217/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3438 - tp: 5303.0000 - fp: 9165.0000 - tn: 43818.0000 - fn: 800.0000 - accuracy: 0.8313 - precision: 0.3665 - recall: 0.8689 - mcc: 0.4926 - auc: 0.9252 - val_loss: 0.3557 - val_tp: 739.0000 - val_fp: 1071.0000 - val_tn: 5378.0000 - val_fn: 107.0000 - val_accuracy: 0.8385 - val_precision: 0.4083 - val_recall: 0.8735 - val_mcc: 0.5244 - val_auc: 0.9215\n",
      "Epoch 218/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3427 - tp: 5303.0000 - fp: 9049.0000 - tn: 43934.0000 - fn: 800.0000 - accuracy: 0.8333 - precision: 0.3695 - recall: 0.8689 - mcc: 0.4954 - auc: 0.9259 - val_loss: 0.3548 - val_tp: 741.0000 - val_fp: 1054.0000 - val_tn: 5395.0000 - val_fn: 105.0000 - val_accuracy: 0.8411 - val_precision: 0.4128 - val_recall: 0.8759 - val_mcc: 0.5296 - val_auc: 0.9220\n",
      "Epoch 219/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3416 - tp: 5316.0000 - fp: 9127.0000 - tn: 43856.0000 - fn: 787.0000 - accuracy: 0.8322 - precision: 0.3681 - recall: 0.8710 - mcc: 0.4949 - auc: 0.9262 - val_loss: 0.3610 - val_tp: 742.0000 - val_fp: 1072.0000 - val_tn: 5377.0000 - val_fn: 104.0000 - val_accuracy: 0.8388 - val_precision: 0.4090 - val_recall: 0.8771 - val_mcc: 0.5266 - val_auc: 0.9224\n",
      "Epoch 220/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3415 - tp: 5296.0000 - fp: 9045.0000 - tn: 43938.0000 - fn: 807.0000 - accuracy: 0.8333 - precision: 0.3693 - recall: 0.8678 - mcc: 0.4948 - auc: 0.9263 - val_loss: 0.3308 - val_tp: 714.0000 - val_fp: 929.0000 - val_tn: 5520.0000 - val_fn: 132.0000 - val_accuracy: 0.8546 - val_precision: 0.4346 - val_recall: 0.8440 - val_mcc: 0.5365 - val_auc: 0.9219\n",
      "Epoch 221/300\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.3411 - tp: 5323.0000 - fp: 9028.0000 - tn: 43955.0000 - fn: 780.0000 - accuracy: 0.8340 - precision: 0.3709 - recall: 0.8722 - mcc: 0.4981 - auc: 0.9266 - val_loss: 0.3684 - val_tp: 742.0000 - val_fp: 1104.0000 - val_tn: 5345.0000 - val_fn: 104.0000 - val_accuracy: 0.8344 - val_precision: 0.4020 - val_recall: 0.8771 - val_mcc: 0.5199 - val_auc: 0.9225000 - accuracy: 0.8349 - precision: 0.3753 - recall: 0.8764\n",
      "Epoch 222/300\n",
      "116/116 [==============================] - 5s 45ms/step - loss: 0.3396 - tp: 5327.0000 - fp: 8971.0000 - tn: 44012.0000 - fn: 776.0000 - accuracy: 0.8350 - precision: 0.3726 - recall: 0.8728 - mcc: 0.4999 - auc: 0.9273 - val_loss: 0.3662 - val_tp: 741.0000 - val_fp: 1102.0000 - val_tn: 5347.0000 - val_fn: 105.0000 - val_accuracy: 0.8345 - val_precision: 0.4021 - val_recall: 0.8759 - val_mcc: 0.5195 - val_auc: 0.9225\n",
      "Epoch 223/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.3403 - tp: 5306.0000 - fp: 9060.0000 - tn: 43923.0000 - fn: 797.0000 - accuracy: 0.8332 - precision: 0.3693 - recall: 0.8694 - mcc: 0.4955 - auc: 0.9270 - val_loss: 0.3770 - val_tp: 750.0000 - val_fp: 1137.0000 - val_tn: 5312.0000 - val_fn: 96.0000 - val_accuracy: 0.8310 - val_precision: 0.3975 - val_recall: 0.8865 - val_mcc: 0.5193 - val_auc: 0.9225\n",
      "Epoch 224/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.3395 - tp: 5333.0000 - fp: 9020.0000 - tn: 43963.0000 - fn: 770.0000 - accuracy: 0.8343 - precision: 0.3716 - recall: 0.8738 - mcc: 0.4993 - auc: 0.9272 - val_loss: 0.3352 - val_tp: 725.0000 - val_fp: 963.0000 - val_tn: 5486.0000 - val_fn: 121.0000 - val_accuracy: 0.8514 - val_precision: 0.4295 - val_recall: 0.8570 - val_mcc: 0.5373 - val_auc: 0.9230\n",
      "Epoch 225/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3398 - tp: 5332.0000 - fp: 8920.0000 - tn: 44063.0000 - fn: 771.0000 - accuracy: 0.8360 - precision: 0.3741 - recall: 0.8737 - mcc: 0.5017 - auc: 0.9270 - val_loss: 0.3582 - val_tp: 740.0000 - val_fp: 1071.0000 - val_tn: 5378.0000 - val_fn: 106.0000 - val_accuracy: 0.8387 - val_precision: 0.4086 - val_recall: 0.8747 - val_mcc: 0.5252 - val_auc: 0.9234\n",
      "Epoch 226/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.3399 - tp: 5315.0000 - fp: 9030.0000 - tn: 43953.0000 - fn: 788.0000 - accuracy: 0.8338 - precision: 0.3705 - recall: 0.8709 - mcc: 0.4972 - auc: 0.9269 - val_loss: 0.3800 - val_tp: 752.0000 - val_fp: 1162.0000 - val_tn: 5287.0000 - val_fn: 94.0000 - val_accuracy: 0.8278 - val_precision: 0.3929 - val_recall: 0.8889 - val_mcc: 0.5158 - val_auc: 0.9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/300\n",
      "116/116 [==============================] - 5s 45ms/step - loss: 0.3359 - tp: 5323.0000 - fp: 8953.0000 - tn: 44030.0000 - fn: 780.0000 - accuracy: 0.8353 - precision: 0.3729 - recall: 0.8722 - mcc: 0.5000 - auc: 0.9286 - val_loss: 0.3625 - val_tp: 735.0000 - val_fp: 1060.0000 - val_tn: 5389.0000 - val_fn: 111.0000 - val_accuracy: 0.8395 - val_precision: 0.4095 - val_recall: 0.8688 - val_mcc: 0.5237 - val_auc: 0.9230\n",
      "Epoch 228/300\n",
      "116/116 [==============================] - 5s 41ms/step - loss: 0.3373 - tp: 5291.0000 - fp: 8952.0000 - tn: 44031.0000 - fn: 812.0000 - accuracy: 0.8347 - precision: 0.3715 - recall: 0.8670 - mcc: 0.4966 - auc: 0.9281 - val_loss: 0.3769 - val_tp: 750.0000 - val_fp: 1145.0000 - val_tn: 5304.0000 - val_fn: 96.0000 - val_accuracy: 0.8299 - val_precision: 0.3958 - val_recall: 0.8865 - val_mcc: 0.5177 - val_auc: 0.9230\n",
      "Epoch 229/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3374 - tp: 5317.0000 - fp: 9050.0000 - tn: 43933.0000 - fn: 786.0000 - accuracy: 0.8335 - precision: 0.3701 - recall: 0.8712 - mcc: 0.4969 - auc: 0.9280 - val_loss: 0.3571 - val_tp: 742.0000 - val_fp: 1046.0000 - val_tn: 5403.0000 - val_fn: 104.0000 - val_accuracy: 0.8424 - val_precision: 0.4150 - val_recall: 0.8771 - val_mcc: 0.5321 - val_auc: 0.9231\n",
      "Epoch 230/300\n",
      "116/116 [==============================] - 5s 44ms/step - loss: 0.3379 - tp: 5292.0000 - fp: 8948.0000 - tn: 44035.0000 - fn: 811.0000 - accuracy: 0.8348 - precision: 0.3716 - recall: 0.8671 - mcc: 0.4968 - auc: 0.9279 - val_loss: 0.3613 - val_tp: 741.0000 - val_fp: 1086.0000 - val_tn: 5363.0000 - val_fn: 105.0000 - val_accuracy: 0.8367 - val_precision: 0.4056 - val_recall: 0.8759 - val_mcc: 0.5228 - val_auc: 0.9238\n",
      "Epoch 231/300\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 0.3359 - tp: 5342.0000 - fp: 8889.0000 - tn: 44094.0000 - fn: 761.0000 - accuracy: 0.8367 - precision: 0.3754 - recall: 0.8753 - mcc: 0.5036 - auc: 0.9285 - val_loss: 0.3720 - val_tp: 751.0000 - val_fp: 1123.0000 - val_tn: 5326.0000 - val_fn: 95.0000 - val_accuracy: 0.8330 - val_precision: 0.4007 - val_recall: 0.8877 - val_mcc: 0.5229 - val_auc: 0.9242\n",
      "Epoch 232/300\n",
      "116/116 [==============================] - 5s 42ms/step - loss: 0.3352 - tp: 5330.0000 - fp: 8849.0000 - tn: 44134.0000 - fn: 773.0000 - accuracy: 0.8372 - precision: 0.3759 - recall: 0.8733 - mcc: 0.5033 - auc: 0.9290 - val_loss: 0.3547 - val_tp: 738.0000 - val_fp: 1052.0000 - val_tn: 5397.0000 - val_fn: 108.0000 - val_accuracy: 0.8410 - val_precision: 0.4123 - val_recall: 0.8723 - val_mcc: 0.5277 - val_auc: 0.9243\n",
      "Epoch 233/300\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.3333 - tp: 5234.0000 - fp: 8611.0000 - tn: 43742.0000 - fn: 781.0000 - accuracy: 0.8391 - precision: 0.3780 - recall: 0.8702 - mcc: 0.5044 - auc: 0.9298"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Training\n",
    "\"\"\"\n",
    "# tensorboard_path = os.path.join(model_dir, \"logs\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "#     log_dir=tensorboard_path, write_graph=False, write_images=False, update_freq=\"epoch\"\n",
    "# )\n",
    "\n",
    "# print(f\"tensorboard --logdir={tensorboard_path}\")\n",
    "\n",
    "training = model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=n_batch,\n",
    "    class_weight=class_weight,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    # callbacks=[tensorboard_callback],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "ckpt_save_path = ckpt_manager.save()\n",
    "pprint(f\"    - Saving checkpoint to:\", ckpt_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "\"\"\"\n",
    "    Results\n",
    "\"\"\"\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    pprint(\"Restoring checkpoint from:\", ckpt_manager.latest_checkpoint)\n",
    "\n",
    "print_variables(model.trainable_variables)\n",
    "plot_metrics(training, Y_train, Y_val, save_dir=model_dir)\n",
    "\n",
    "results_train = model.evaluate(X_train, Y_train, batch_size=n_batch, verbose=0)\n",
    "results_val = model.evaluate(X_val, Y_val, batch_size=n_batch, verbose=0)\n",
    "results_test = model.evaluate(X_test, Y_test, batch_size=n_batch, verbose=0)\n",
    "results_test_all = model.evaluate(X_test_all, Y_test_all, batch_size=n_batch, verbose=0)\n",
    "\n",
    "Y_train_pred = model.predict(X_train, batch_size=n_batch)\n",
    "Y_val_pred = model.predict(X_val, batch_size=n_batch)\n",
    "Y_test_pred = model.predict(X_test, batch_size=n_batch)\n",
    "Y_test_all_pred = model.predict(X_test_all, batch_size=n_batch)\n",
    "\n",
    "describe_results(model.metrics_names, results_train, Y_train, name=\"Train\")\n",
    "describe_results(model.metrics_names, results_val, Y_val, name=\"Validation\")\n",
    "describe_results(model.metrics_names, results_test, Y_test, name=\"Test\")\n",
    "describe_results(model.metrics_names, results_test_all, Y_test_all, name=\"Test-all\")\n",
    "\n",
    "plot_cm(Y_train, Y_train_pred, \"Training\", save_dir=model_dir)\n",
    "plot_cm(Y_val, Y_val_pred, \"Validation\", save_dir=model_dir)\n",
    "plot_cm(Y_test, Y_test_pred, \"Test\", save_dir=model_dir)\n",
    "\n",
    "plot_roc(\n",
    "    [\n",
    "        (\"Training\", Y_train, Y_train_pred),\n",
    "        (\"Validation\", Y_val, Y_val_pred),\n",
    "        (\"Test\", Y_test, Y_test_pred),\n",
    "        (\"Test-all\", Y_test_all, Y_test_all_pred),\n",
    "    ],\n",
    "    save_dir=model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.show()\n",
    "\n",
    "with open(os.path.join(model_dir, \"log.txt\"), \"a\") as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bclassification.utils_fcn import create_dataset\n",
    "\n",
    "def plot_preds(t, y, y_pred, rhos, threshold, chronic_idx=None):\n",
    "    fig, ax = plt.subplots(figsize=(Const.FIG_SIZE[0] * 2, Const.FIG_SIZE[1]))\n",
    "\n",
    "    indices_pos = np.equal(y, 1)\n",
    "    # ax.plot(t, y, label=r\"$y$\", color=\"tab:blue\")\n",
    "    ax.bar(t[indices_pos], y[indices_pos], label=r\"$y$\", color=\"tab:blue\", lw=1.5)\n",
    "\n",
    "    # ax.plot(t, y_pred, label=r\"$P(y = 1)$\", color=\"tab:green\")\n",
    "    indices_pos = np.greater(y_pred, threshold)\n",
    "    pos = np.ma.masked_where(np.greater_equal(y_pred, threshold), y_pred)\n",
    "    neg = np.ma.masked_where(np.less_equal(y_pred, threshold), y_pred)\n",
    "    ax.plot(t, pos, \"tab:green\", t, neg, \"tab:red\")\n",
    "\n",
    "    ax.plot(t, np.ones_like(t) * threshold, label=r\"$y$\", color=\"tab:red\")\n",
    "    # ax.plot(t, rhos, label=r\"$y$\")\n",
    "\n",
    "    # ax.legend()\n",
    "    ax.set_xlabel(\"Time step t\")\n",
    "    ax.set_ylabel(r\"$P(y = 1)$\")\n",
    "\n",
    "    if ax.get_xlim()[-1] > 2000:\n",
    "        ax.set_xlim(right=2000, left=-10)\n",
    "    else:\n",
    "        ax.set_xlim(left=-10)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if model_dir and not isinstance(chronic_idx, type(None)):\n",
    "        fig.savefig(os.path.join(model_dir, \"test-y-step-{:04}\".format(chronic_idx)))\n",
    "        \n",
    "    if not isinstance(rhos, type(None)):\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylabel(r\"$\\rho^\\mathrm{max}$\")\n",
    "        ax2.plot(t, rhos, label=r\"$y$\", lw=Const.LW, color=\"tab:orange\")\n",
    "        ax2.set_ylim(*ax.get_ylim())\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if model_dir and not isinstance(chronic_idx, type(None)):\n",
    "        fig.savefig(os.path.join(model_dir, \"test-y-step-{:04}-rhos\".format(chronic_idx)))\n",
    "\n",
    "\n",
    "sample_experience_dir = make_dir(os.path.join(Const.EXPERIENCE_DIR, \"data-aug-sample\"))\n",
    "case, collector = load_experience(case_name, agent_name, sample_experience_dir, env_dc=env_dc)\n",
    "\n",
    "_, _, _, X_all_sample, Y_all_sample = create_dataset(\n",
    "    case,\n",
    "    collector,\n",
    "    input_mode=input_mode,\n",
    "    label_mode=label_mode,\n",
    "    n_window_history=n_window_history,\n",
    "    n_window_targets=n_window_targets,\n",
    "    downsampling_rate=downsampling_rate,\n",
    "    n_window_forecasts=n_window_forecasts,\n",
    "    use_actions=use_actions,\n",
    "    feature_scaling=feature_scaling,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "for chronic_idx, chronic_len in zip(collector.chronic_ids, collector.chronic_lengths):\n",
    "    X_chronic = X_all_sample[start_idx:(start_idx + chronic_len), :]\n",
    "    Y_chronic = Y_all_sample[start_idx:(start_idx + chronic_len)]\n",
    "    Y_chronic_pred = model.predict(X_chronic, batch_size=n_batch).flatten()\n",
    "    \n",
    "    t = np.arange(chronic_len)\n",
    "    rhos = [np.max(obs.rho) for obs in collector.data[chronic_idx][\"obses\"][:-1]]\n",
    "        \n",
    "    plot_preds(t, Y_chronic, Y_chronic_pred, rhos, threshold, chronic_idx)\n",
    "    \n",
    "    start_idx = start_idx + chronic_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def plot_scatter(ax, data, color_label, marker_label=None, x_label=None, y_label=None, ax_title=None):\n",
    "    colors = Const.COLORS\n",
    "    \n",
    "    color_values = sorted(data[color_label].unique())\n",
    "    \n",
    "    for i, color_val in enumerate(color_values):\n",
    "        color_id = i % len(colors)\n",
    "        color = colors[color_id]\n",
    "        \n",
    "        if marker_label:\n",
    "            marker_values = sorted(data[marker_label].unique())\n",
    "            for j, marker_val in enumerate(marker_values):\n",
    "                d = data[np.logical_and(data[color_label] == color_val, data[marker_label] == marker_val)]\n",
    "\n",
    "                if d.shape[0] > 0:\n",
    "                    if marker_val == \"1\":\n",
    "                        ax.scatter(d[x_label], d[y_label], label=str(color_val), s=50, marker=\"+\", facecolors='none', c=color)\n",
    "                    elif marker_val == \"0\":\n",
    "                        ax.scatter(d[x_label], d[y_label], label=str(color_val), s=30, marker=\"o\", facecolors='none', edgecolors=color, alpha=0.5)\n",
    "                    else:\n",
    "                        ax.scatter(d[x_label], d[y_label], label=str(color_val), s=30, marker=\"+\", c=color)                \n",
    "        else:\n",
    "            d = data[data[color_label] == color_val]\n",
    "            ax.scatter(d[x_label], d[y_label], label=str(color_val), s=30, marker=\"+\", c=color)\n",
    "            \n",
    "    if len(color_values) < 4 and not marker_label:\n",
    "        ax.legend(color_values)\n",
    "        \n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    \n",
    "    if ax_title:\n",
    "        ax.set_title(ax_title)\n",
    "\n",
    "\"\"\"\n",
    "    TSNE\n",
    "\n",
    "    Following: https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n",
    "\"\"\"\n",
    "\n",
    "file_name = f\"tsne-d{dr_str}-h{h_str}-f{f_str}{ft_str}-{input_mode}.npz\"\n",
    "file_path = os.path.join(experience_dir, file_name)\n",
    "\n",
    "\n",
    "if file_name in os.listdir(experience_dir):\n",
    "    pprint(\"Loading:\", file_path)\n",
    "    tsne_results = np.load(file_path)[\"tsne_results\"]\n",
    "else:\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=30, n_iter=300)\n",
    "    red = PCA(n_components=100, random_state=random_seed)\n",
    "\n",
    "    X_red = red.fit_transform(X)\n",
    "    pprint(\"    - Explained variance:\", red.explained_variance_ratio_.sum())\n",
    "    tsne_results = tsne.fit_transform(X_red)\n",
    "    np.savez_compressed(\n",
    "        file_path,\n",
    "        tsne_results=tsne_results,\n",
    "    )\n",
    "    pprint(\"Saving:\", file_path)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"tsne-1\"] = tsne_results[:, 0]\n",
    "data[\"tsne-2\"] = tsne_results[:, 1]\n",
    "data[\"y\"] = Y.astype(int).astype(str)\n",
    "\n",
    "data_train, data_val = train_test_split(\n",
    "    data, test_size=val_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "data_train, data_test = train_test_split(\n",
    "    data_train, test_size=test_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "fig_name = \"tsne-X-train\"\n",
    "fig, ax = plt.subplots(figsize=Const.FIG_SIZE)\n",
    "plot_scatter(ax, data_train, color_label=\"y\", x_label=\"tsne-1\", y_label=\"tsne-2\")\n",
    "fig.savefig(os.path.join(model_dir, fig_name))\n",
    "\n",
    "fig_name = \"tsne-X-val\"\n",
    "fig, ax = plt.subplots(figsize=Const.FIG_SIZE)\n",
    "plot_scatter(ax, data_val, color_label=\"y\", x_label=\"tsne-1\", y_label=\"tsne-2\")\n",
    "fig.savefig(os.path.join(model_dir, fig_name))\n",
    "\n",
    "fig_name = \"tsne-X-test\"\n",
    "fig, ax = plt.subplots(figsize=Const.FIG_SIZE)\n",
    "plot_scatter(ax, data_test, color_label=\"y\", x_label=\"tsne-1\", y_label=\"tsne-2\")\n",
    "fig.savefig(os.path.join(model_dir, fig_name))\n",
    "\n",
    "\n",
    "Y_pred = np.greater(model.predict(X, batch_size=n_batch), threshold).astype(int).flatten()\n",
    "data[\"y\"][np.logical_and(np.not_equal(Y, Y_pred), np.equal(Y, 1))] = \"2\"\n",
    "\n",
    "data_train, data_val = train_test_split(\n",
    "    data, test_size=val_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "data_train, data_test = train_test_split(\n",
    "    data_train, test_size=test_frac, random_state=random_seed\n",
    ")\n",
    "\n",
    "fig_name = \"tsne-X-train\"\n",
    "fig, ax = plt.subplots(figsize=Const.FIG_SIZE)\n",
    "plot_scatter(ax, data_train, color_label=\"y\", x_label=\"tsne-1\", y_label=\"tsne-2\")\n",
    "fig.savefig(os.path.join(model_dir, fig_name))\n",
    "\n",
    "fig_name = \"tsne-X-labels-val\"\n",
    "fig, ax = plt.subplots(figsize=Const.FIG_SIZE)\n",
    "plot_scatter(ax, data_val, color_label=\"y\", x_label=\"tsne-1\", y_label=\"tsne-2\")\n",
    "fig.savefig(os.path.join(model_dir, fig_name))\n",
    "\n",
    "fig_name = \"tsne-X-labels-test\"\n",
    "fig, ax = plt.subplots(figsize=Const.FIG_SIZE)\n",
    "plot_scatter(ax, data_test, color_label=\"y\", x_label=\"tsne-1\", y_label=\"tsne-2\")\n",
    "fig.savefig(os.path.join(model_dir, fig_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
