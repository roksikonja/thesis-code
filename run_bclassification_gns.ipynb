{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L2RPN_2019_ART (dc)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "                                        Loading Experience\n",
      "--------------------------------------------------------------------------------\n",
      "    - Loading chronics:                 ./results/performance-aug/l2rpn_2019_art-dc/agent-mip-chronic-****\n",
      "Chronic:                                0\n",
      "        - O A R D:                      6913\t6912\t(6912,)\t(6912,)\n",
      "Chronic:                                1\n",
      "        - O A R D:                      201\t200\t(200,)\t(200,)\n",
      "Chronic:                                3\n",
      "        - O A R D:                      8065\t8064\t(8064,)\t(8064,)\n",
      "Chronic:                                4\n",
      "        - O A R D:                      8065\t8064\t(8064,)\t(8064,)\n",
      "Chronic:                                7\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                10\n",
      "        - O A R D:                      3104\t3103\t(3103,)\t(3103,)\n",
      "Chronic:                                11\n",
      "        - O A R D:                      7489\t7488\t(7488,)\t(7488,)\n",
      "Chronic:                                12\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                13\n",
      "        - O A R D:                      6913\t6912\t(6912,)\t(6912,)\n",
      "Chronic:                                14\n",
      "        - O A R D:                      2537\t2536\t(2536,)\t(2536,)\n",
      "Chronic:                                15\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                16\n",
      "        - O A R D:                      6625\t6624\t(6624,)\t(6624,)\n",
      "Chronic:                                17\n",
      "        - O A R D:                      2232\t2231\t(2231,)\t(2231,)\n",
      "Chronic:                                18\n",
      "        - O A R D:                      8065\t8064\t(8064,)\t(8064,)\n",
      "Chronic:                                19\n",
      "        - O A R D:                      6625\t6624\t(6624,)\t(6624,)\n",
      "Chronic:                                20\n",
      "        - O A R D:                      7489\t7488\t(7488,)\t(7488,)\n",
      "Chronic:                                21\n",
      "        - O A R D:                      4846\t4845\t(4845,)\t(4845,)\n",
      "Chronic:                                22\n",
      "        - O A R D:                      227\t226\t(226,)\t(226,)\n",
      "Chronic:                                23\n",
      "        - O A R D:                      7489\t7488\t(7488,)\t(7488,)\n",
      "Chronic:                                24\n",
      "        - O A R D:                      7201\t7200\t(7200,)\t(7200,)\n",
      "Chronic:                                25\n",
      "        - O A R D:                      8065\t8064\t(8064,)\t(8064,)\n",
      "Chronic:                                26\n",
      "        - O A R D:                      6625\t6624\t(6624,)\t(6624,)\n",
      "Chronic:                                27\n",
      "        - O A R D:                      8065\t8064\t(8064,)\t(8064,)\n",
      "Chronic:                                28\n",
      "        - O A R D:                      3383\t3382\t(3382,)\t(3382,)\n",
      "Chronic:                                29\n",
      "        - O A R D:                      6278\t6277\t(6277,)\t(6277,)\n",
      "Chronic:                                30\n",
      "        - O A R D:                      7201\t7200\t(7200,)\t(7200,)\n",
      "Chronic:                                31\n",
      "        - O A R D:                      3113\t3112\t(3112,)\t(3112,)\n",
      "Chronic:                                32\n",
      "        - O A R D:                      7201\t7200\t(7200,)\t(7200,)\n",
      "Chronic:                                33\n",
      "        - O A R D:                      6913\t6912\t(6912,)\t(6912,)\n",
      "Chronic:                                34\n",
      "        - O A R D:                      1386\t1385\t(1385,)\t(1385,)\n",
      "Chronic:                                35\n",
      "        - O A R D:                      6625\t6624\t(6624,)\t(6624,)\n",
      "Chronic:                                36\n",
      "        - O A R D:                      7489\t7488\t(7488,)\t(7488,)\n",
      "Chronic:                                37\n",
      "        - O A R D:                      1672\t1671\t(1671,)\t(1671,)\n",
      "Chronic:                                38\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                39\n",
      "        - O A R D:                      6913\t6912\t(6912,)\t(6912,)\n",
      "Chronic:                                40\n",
      "        - O A R D:                      6625\t6624\t(6624,)\t(6624,)\n",
      "Chronic:                                41\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                42\n",
      "        - O A R D:                      7489\t7488\t(7488,)\t(7488,)\n",
      "Chronic:                                43\n",
      "        - O A R D:                      6337\t6336\t(6336,)\t(6336,)\n",
      "Chronic:                                44\n",
      "        - O A R D:                      6913\t6912\t(6912,)\t(6912,)\n",
      "Chronic:                                45\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                46\n",
      "        - O A R D:                      8065\t8064\t(8064,)\t(8064,)\n",
      "Chronic:                                47\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                48\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                49\n",
      "        - O A R D:                      7489\t7488\t(7488,)\t(7488,)\n",
      "Chronic:                                50\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                51\n",
      "        - O A R D:                      7201\t7200\t(7200,)\t(7200,)\n",
      "Chronic:                                52\n",
      "        - O A R D:                      3414\t3413\t(3413,)\t(3413,)\n",
      "Chronic:                                53\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                54\n",
      "        - O A R D:                      8065\t8064\t(8064,)\t(8064,)\n",
      "Chronic:                                55\n",
      "        - O A R D:                      7201\t7200\t(7200,)\t(7200,)\n",
      "Chronic:                                56\n",
      "        - O A R D:                      89\t88\t(88,)\t(88,)\n",
      "Chronic:                                57\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                58\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "Chronic:                                59\n",
      "        - O A R D:                      6337\t6336\t(6336,)\t(6336,)\n",
      "Chronic:                                60\n",
      "        - O A R D:                      6625\t6624\t(6624,)\t(6624,)\n",
      "Chronic:                                61\n",
      "        - O A R D:                      516\t515\t(515,)\t(515,)\n",
      "Chronic:                                62\n",
      "        - O A R D:                      7777\t7776\t(7776,)\t(7776,)\n",
      "    - Number of chronics:               58\n",
      "    - Observations:                     358424\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from graph_nets import utils_tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from bclassification.utils_base import print_class_weights\n",
    "from bclassification.utils_gns import (\n",
    "    print_dataset,\n",
    "    plot_metrics,\n",
    "    plot_cm,\n",
    "    plot_roc,\n",
    "    describe_results,\n",
    "    print_graph_dims,\n",
    ")\n",
    "from experience import load_experience\n",
    "from lib.action_space import is_do_nothing_action\n",
    "from lib.constants import Constants as Const\n",
    "from lib.data_utils import make_dir, env_pf, extract_target_windows\n",
    "from lib.dc_opf import TopologyConverter\n",
    "from lib.gns import GraphNetwork\n",
    "from lib.gns import (\n",
    "    obses_to_lgraphs,\n",
    "    lgraphs_to_cgraphs,\n",
    "    get_graph_feature_dimensions\n",
    ")\n",
    "from lib.gns import tf_batched_graph_dataset\n",
    "from lib.run_utils import create_logger\n",
    "from lib.tf_utils import (\n",
    "    ResidulaFCBlock,\n",
    "    MatthewsCorrelationCoefficient,\n",
    ")\n",
    "from lib.visualizer import Visualizer, pprint\n",
    "\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "\n",
    "Visualizer()\n",
    "\n",
    "experience_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"performance-aug\"))\n",
    "results_dir = make_dir(os.path.join(Const.RESULTS_DIR, \"bc-gns\"))\n",
    "\n",
    "agent_name = \"agent-mip\"\n",
    "case_name = \"l2rpn_2019_art\"\n",
    "env_dc = True\n",
    "verbose = False\n",
    "\n",
    "case_results_dir = make_dir(os.path.join(results_dir, f\"{case_name}-{env_pf(env_dc)}\"))\n",
    "create_logger(logger_name=f\"{case_name}-{env_pf(env_dc)}\", save_dir=case_results_dir)\n",
    "\n",
    "case, collector = load_experience(case_name, agent_name, experience_dir, env_dc=env_dc)\n",
    "obses, actions, rewards, dones = collector.aggregate_data()\n",
    "\n",
    "pprint(\"    - Number of chronics:\", dones.sum())\n",
    "pprint(\"    - Observations:\", len(obses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Parameters\n",
    "\"\"\"\n",
    "random_seed = 1\n",
    "\n",
    "model_type = \"gn\"\n",
    "\n",
    "n_window_targets = 0\n",
    "n_window_history = 1\n",
    "threshold = 0.5\n",
    "\n",
    "dropout_rate = 0.1\n",
    "n_hidden = 512\n",
    "n_message_passes = 2\n",
    "\n",
    "n_batch = 256\n",
    "n_epochs = 500\n",
    "\n",
    "downsampling_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    - Labels:                           3642/358424\t1.02 %\n",
      "    - Mask (0):                         17779\t83.04 %\n",
      "    - Mask (1):                         3630\t16.96 %\n",
      "    - Mask:                             21409\n",
      "    - Data:                             X, Y\t            (21409,)\n",
      "        - X: globals                    21409\t(40,)\n",
      "        - X: edges                      21409\t(40, 20)\n",
      "        - X: nodes                      21409\t(14, 66)\n",
      "        - X: senders                    21409\t(40,)\n",
      "        - X: receivers                  21409\t(40,)\n",
      "        - Positive labels:              16.96 %\n",
      "        - Negative labels:              83.04 %\n",
      "\n",
      "    - Train:                            X, Y\t            (17341,)\n",
      "        - X: globals                    17341\t(40,)\n",
      "        - X: edges                      17341\t(40, 20)\n",
      "        - X: nodes                      17341\t(14, 66)\n",
      "        - X: senders                    17341\t(40,)\n",
      "        - X: receivers                  17341\t(40,)\n",
      "        - Positive labels:              16.84 %\n",
      "        - Negative labels:              83.16 %\n",
      "\n",
      "    - Validation:                       X, Y\t             (1927,)\n",
      "        - X: globals                    1927\t(40,)\n",
      "        - X: edges                      1927\t(40, 20)\n",
      "        - X: nodes                      1927\t(14, 66)\n",
      "        - X: senders                    1927\t(40,)\n",
      "        - X: receivers                  1927\t(40,)\n",
      "        - Positive labels:              17.80 %\n",
      "        - Negative labels:              82.20 %\n",
      "\n",
      "    - Test:                             X, Y\t             (2141,)\n",
      "        - X: globals                    2141\t(40,)\n",
      "        - X: edges                      2141\t(40, 20)\n",
      "        - X: nodes                      2141\t(14, 66)\n",
      "        - X: senders                    2141\t(40,)\n",
      "        - X: receivers                  2141\t(40,)\n",
      "        - Positive labels:              17.14 %\n",
      "        - Negative labels:              82.86 %\n",
      "\n",
      "Graph                                   Dimension\n",
      "n_global_features                       40\n",
      "n_node_features                         66\n",
      "n_edge_features                         20\n",
      "n_nodes                                 14\n",
      "n_edges                                 40\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Datasets\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "labels = is_do_nothing_action(actions, case.env).astype(float)\n",
    "pprint(\n",
    "    \"    - Labels:\",\n",
    "    f\"{int(labels.sum())}/{labels.size}\",\n",
    "    \"{:.2f} %\".format(100 * labels.mean()),\n",
    ")\n",
    "\n",
    "mask_positive = extract_target_windows(labels, mask=~dones, n_window=n_window_targets)\n",
    "mask_negative = np.logical_and(np.random.binomial(1, downsampling_rate, len(labels)), ~mask_positive)\n",
    "mask_targets = np.logical_or(mask_positive, mask_negative)\n",
    "\n",
    "pprint(\n",
    "    \"    - Mask (0):\",\n",
    "    mask_negative.sum(),\n",
    "    \"{:.2f} %\".format(100 * mask_negative.sum() / mask_targets.sum()),\n",
    ")\n",
    "pprint(\n",
    "    \"    - Mask (1):\",\n",
    "    mask_positive.sum(),\n",
    "    \"{:.2f} %\".format(100 * mask_positive.sum() / mask_targets.sum()),\n",
    ")\n",
    "pprint(\"    - Mask:\", mask_targets.sum())\n",
    "\n",
    "tc = TopologyConverter(case.env)\n",
    "lgraphs_all = obses_to_lgraphs(obses, tc, n_window=n_window_history)\n",
    "X_all = lgraphs_to_cgraphs(lgraphs_all)\n",
    "Y_all = np.array(labels)\n",
    "\n",
    "lgraphs = [lgraph for i, lgraph in enumerate(lgraphs_all) if mask_targets[i]]\n",
    "X = lgraphs_to_cgraphs(lgraphs)\n",
    "Y = Y_all[mask_targets]\n",
    "\n",
    "lgraphs_train, lgraphs_test, Y_train, Y_test = train_test_split(\n",
    "    lgraphs, Y, test_size=0.10, random_state=random_seed\n",
    ")\n",
    "lgraphs_train, lgraphs_val, Y_train, Y_val = train_test_split(\n",
    "    lgraphs_train, Y_train, test_size=0.10, random_state=random_seed\n",
    ")\n",
    "\n",
    "X_train = lgraphs_to_cgraphs(lgraphs_train)\n",
    "X_val = lgraphs_to_cgraphs(lgraphs_val)\n",
    "X_test = lgraphs_to_cgraphs(lgraphs_test)\n",
    "\n",
    "graph_dims = get_graph_feature_dimensions(lgraphs=lgraphs)\n",
    "cgraph_dims = {**graph_dims, \"n_nodes\": tc.n_sub, \"n_edges\": 2 * tc.n_line}\n",
    "\n",
    "print_dataset(X, Y, \"Data\")\n",
    "print_dataset(X_train, Y_train, \"Train\")\n",
    "print_dataset(X_val, Y_val, \"Validation\")\n",
    "print_dataset(X_test, Y_test, \"Test\")\n",
    "print_graph_dims(cgraph_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Tensorflow datasets\n",
    "\"\"\"\n",
    "\n",
    "X_all_tf = tf_batched_graph_dataset(X_all, n_batch=n_batch, **graph_dims)\n",
    "Y_all_tf = tf.data.Dataset.from_tensor_slices(Y_all).batch(n_batch)\n",
    "\n",
    "X_train_tf = tf_batched_graph_dataset(X_train, n_batch=n_batch, **graph_dims)\n",
    "Y_train_tf = tf.data.Dataset.from_tensor_slices(Y_train).batch(n_batch)\n",
    "\n",
    "X_val_tf = tf_batched_graph_dataset(X_val, n_batch=n_batch, **graph_dims)\n",
    "Y_val_tf = tf.data.Dataset.from_tensor_slices(Y_val).batch(n_batch)\n",
    "\n",
    "X_test_tf = tf_batched_graph_dataset(X_test, n_batch=n_batch, **graph_dims)\n",
    "Y_test_tf = tf.data.Dataset.from_tensor_slices(Y_test).batch(n_batch)\n",
    "\n",
    "\"\"\"\n",
    "    Signatures\n",
    "\"\"\"\n",
    "\n",
    "graphs_sig = utils_tf.specs_from_graphs_tuple(\n",
    "    next(iter(X_train_tf)), dynamic_num_graphs=True\n",
    ")\n",
    "labels_sig = tf.TensorSpec(shape=[None], dtype=tf.dtypes.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model\n",
    "\"\"\"\n",
    "\n",
    "class GraphNetworkBinary(tf.keras.Model):\n",
    "    def __init__(\n",
    "            self,\n",
    "            graph_network,\n",
    "            output_network,\n",
    "            class_weight=None,\n",
    "            metrics=(),\n",
    "    ):\n",
    "        super(GraphNetworkBinary, self).__init__()\n",
    "        self.graph_network = graph_network\n",
    "        self.output_network = output_network\n",
    "\n",
    "        self.class_weight = dict()\n",
    "        for c in class_weight:\n",
    "            self.class_weight[c] = tf.constant(c, dtype=tf.float64)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr=1e-3)\n",
    "        self.loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "        self.metrics_ = metrics\n",
    "\n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics_:\n",
    "            metric.reset_states()\n",
    "\n",
    "    @tf.function(input_signature=[labels_sig, labels_sig])\n",
    "    def update_metrics(self, y_true, y_pred):\n",
    "        for metric in self.metrics_:\n",
    "            if metric.name == \"loss\":\n",
    "                metric.update_state(y_true, y_pred, sample_weight=self.sample_weight(y_true))\n",
    "            else:\n",
    "                metric.update_state(y_true, y_pred)\n",
    "\n",
    "    @tf.function(input_signature=[graphs_sig, tf.TensorSpec(shape=(), dtype=tf.dtypes.bool)])\n",
    "    def call(self, inputs, training=False):\n",
    "        outputs = self.graph_network(inputs)\n",
    "\n",
    "        edges = outputs.edges\n",
    "        edges = tf.reshape(\n",
    "            edges,\n",
    "            shape=[-1, self.graph_network.n_edges, self.graph_network.n_edge_features]\n",
    "        )\n",
    "        edges = tf.math.reduce_max(edges, axis=1)\n",
    "\n",
    "        nodes = outputs.nodes\n",
    "        nodes = tf.reshape(\n",
    "            nodes,\n",
    "            shape=[-1, self.graph_network.n_nodes, self.graph_network.n_node_features]\n",
    "        )\n",
    "        nodes = tf.math.reduce_max(nodes, axis=1)\n",
    "\n",
    "        outputs = tf.concat([nodes, edges, outputs.globals], axis=-1)\n",
    "        outputs = self.output_network(outputs, training=training)\n",
    "\n",
    "        return tf.reshape(outputs, [-1])\n",
    "\n",
    "    @tf.function(input_signature=[graphs_sig, labels_sig])\n",
    "    def train_step(self, x, y):\n",
    "        with tf.GradientTape() as gt:\n",
    "            probabilities = self(x, training=True)\n",
    "            loss = self.compiled_loss_(y, probabilities)\n",
    "\n",
    "        trainable_variables = list(self.graph_network.trainable_variables) + self.output_network.trainable_variables\n",
    "        grads = gt.gradient(loss, trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "        self.update_metrics(y, probabilities)\n",
    "\n",
    "        return loss, probabilities\n",
    "\n",
    "    @tf.function(input_signature=[labels_sig])\n",
    "    def sample_weight(self, y_true):\n",
    "        sample_weight = None\n",
    "        if self.class_weight:\n",
    "            sample_weight = tf.multiply(1.0 - y_true, self.class_weight[0]) + tf.multiply(y_true, self.class_weight[1])\n",
    "            sample_weight = tf.reshape(sample_weight, [1, -1])\n",
    "\n",
    "        return sample_weight\n",
    "\n",
    "    @tf.function(input_signature=[labels_sig, labels_sig])\n",
    "    def compiled_loss_(self, y_true, y_pred):\n",
    "        loss = self.loss(y_true, y_pred, sample_weight=self.sample_weight(y_true))\n",
    "        return loss\n",
    "\n",
    "    def predict(self, x):\n",
    "        predictions = []\n",
    "\n",
    "        for batch in x:\n",
    "            probabilities = self(batch, training=False)\n",
    "            predictions.append(probabilities)\n",
    "\n",
    "        predictions = tf.concat(predictions, axis=0)\n",
    "        return predictions\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        self.reset_metrics()\n",
    "        predictions = self.predict(x)\n",
    "        self.update_metrics(y, predictions)\n",
    "\n",
    "        output = self.metrics_dict()\n",
    "        return output\n",
    "\n",
    "    def metrics_dict(self):\n",
    "        output = dict()\n",
    "        for metric in self.metrics_:\n",
    "            output[metric.name] = metric.result()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_negative, n_positive = np.bincount(Y.astype(int))\n",
    "n = n_negative + n_positive\n",
    "\n",
    "class_weight = {0: n / n_negative / 2.0, 1: n / n_positive / 2.0}\n",
    "initial_bias = np.log([n_positive / n_negative])\n",
    "\n",
    "print_class_weights(class_weight)\n",
    "pprint(\"Initial bias:\", \"{:.4f}\".format(float(initial_bias)))\n",
    "\n",
    "metrics = [\n",
    "    tf.keras.metrics.BinaryCrossentropy(name=\"loss\"),\n",
    "    tf.keras.metrics.TruePositives(thresholds=threshold, name=\"tp\"),\n",
    "    tf.keras.metrics.FalsePositives(thresholds=threshold, name=\"fp\"),\n",
    "    tf.keras.metrics.TrueNegatives(thresholds=threshold, name=\"tn\"),\n",
    "    tf.keras.metrics.FalseNegatives(thresholds=threshold, name=\"fn\"),\n",
    "    tf.keras.metrics.BinaryAccuracy(threshold=threshold, name=\"accuracy\"),\n",
    "    tf.keras.metrics.Precision(thresholds=threshold, name=\"precision\"),\n",
    "    tf.keras.metrics.Recall(thresholds=threshold, name=\"recall\"),\n",
    "    MatthewsCorrelationCoefficient(threshold=threshold, name=\"mcc\"),\n",
    "]\n",
    "\n",
    "gn_model = GraphNetwork(\n",
    "    n_hidden_global=[n_hidden],\n",
    "    n_hidden_node=[n_hidden],\n",
    "    n_hidden_edge=[n_hidden],\n",
    "    dropout_rate=dropout_rate,\n",
    "    n_message_passes=n_message_passes,\n",
    "    **cgraph_dims,\n",
    ")\n",
    "\n",
    "input_dims = gn_model.n_global_features + gn_model.n_node_features + gn_model.n_edge_features\n",
    "out_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(\n",
    "            n_hidden, activation=\"relu\",\n",
    "            input_shape=(input_dims,)\n",
    "        ),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        ResidulaFCBlock(n_hidden, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        ResidulaFCBlock(n_hidden, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(\n",
    "            1,\n",
    "            activation=\"sigmoid\",\n",
    "            bias_initializer=tf.keras.initializers.Constant(initial_bias),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = GraphNetworkBinary(\n",
    "    graph_network=gn_model,\n",
    "    output_network=out_model,\n",
    "    class_weight=class_weight,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "model_dir = make_dir(os.path.join(case_results_dir, f\"model-000-{model_type}\"))\n",
    "checkpoint_path = os.path.join(model_dir, \"ckpts\")\n",
    "ckpt = tf.train.Checkpoint(model=model, optimizer=model.optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "pprint(\"Model directory:\", model_dir)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    pprint(\"Restoring checkpoint from:\", ckpt_manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Training\n",
    "\"\"\"\n",
    "\n",
    "training = {\n",
    "    \"epochs\": [],\n",
    "}\n",
    "for metric in metrics:\n",
    "    training[metric.name] = []\n",
    "    training[\"val_\" + metric.name] = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for batch, (graph_batch, label_batch) in enumerate(tf.data.Dataset.zip((X_train_tf, Y_train_tf))):\n",
    "        loss, batch_predictions = model.train_step(graph_batch, label_batch)\n",
    "\n",
    "    train_metrics = model.metrics_dict()\n",
    "    val_metrics = model.evaluate(X_val_tf, Y_val)\n",
    "\n",
    "    training[\"epochs\"].append(epoch)\n",
    "    for m_name, m_value in train_metrics.items():\n",
    "        training[m_name].append(m_value)\n",
    "    for m_name, m_value in val_metrics.items():\n",
    "        training[\"val_\" + m_name].append(m_value)\n",
    "\n",
    "    pprint(\"Epoch: {}/{}\".format(epoch, n_epochs), f\"{np.round(time.time() - start, 3)} s\")\n",
    "\n",
    "ckpt_save_path = ckpt_manager.save()\n",
    "pprint(f\"    - Saving checkpoint to:\", ckpt_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(training, Y_train, Y_val, save_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Performance\n",
    "\"\"\"\n",
    "\n",
    "Y_train_pred = model.predict(X_train_tf).numpy()\n",
    "Y_val_pred = model.predict(X_val_tf).numpy()\n",
    "Y_test_pred = model.predict(X_test_tf).numpy()\n",
    "Y_all_pred = model.predict(X_all_tf).numpy()\n",
    "\n",
    "results_train = model.evaluate(X_train_tf, Y_train)\n",
    "results_val = model.evaluate(X_val_tf, Y_val)\n",
    "results_test = model.evaluate(X_test_tf, Y_test)\n",
    "results_all = model.evaluate(X_all_tf, Y_all)\n",
    "\n",
    "describe_results(results_train, Y_train, name=\"Train\")\n",
    "describe_results(results_val, Y_val, name=\"Validation\")\n",
    "describe_results(results_test, Y_test, name=\"Test\")\n",
    "describe_results(results_all, Y_all, name=\"All\")\n",
    "\n",
    "plot_cm(Y_train, Y_train_pred, \"Training\", save_dir=model_dir)\n",
    "plot_cm(Y_val, Y_val_pred, \"Validation\", save_dir=model_dir)\n",
    "plot_cm(Y_test, Y_test_pred, \"Test\", save_dir=model_dir)\n",
    "plot_cm(Y_all, Y_all_pred, \"All\", save_dir=model_dir)\n",
    "\n",
    "plot_roc(\n",
    "    [\n",
    "        (\"Training\", Y_train, Y_train_pred),\n",
    "        (\"Validation\", Y_val, Y_val_pred),\n",
    "        (\"Test\", Y_test, Y_test_pred),\n",
    "        (\"All\", Y_all, Y_all_pred),\n",
    "    ],\n",
    "    save_dir=model_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
